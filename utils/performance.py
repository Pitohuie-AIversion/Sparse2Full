"""æ€§èƒ½åˆ†ææ¨¡å—

æä¾›æ¨¡å‹æ€§èƒ½åˆ†æåŠŸèƒ½ï¼š
- å‚æ•°é‡ç»Ÿè®¡
- FLOPsè®¡ç®—
- æ˜¾å­˜ä½¿ç”¨åˆ†æ
- æ¨ç†å»¶è¿Ÿæµ‹è¯•
- èµ„æºä½¿ç”¨æŠ¥å‘Š
"""

import time
import psutil
import torch
import torch.nn as nn
from typing import Dict, List, Optional, Tuple, Any
import numpy as np
from pathlib import Path
import json
from contextlib import contextmanager
import gc


class PerformanceProfiler:
    """æ€§èƒ½åˆ†æå™¨"""
    
    def __init__(self, device: str = 'cuda'):
        self.device = device
        self.reset()
    
    def reset(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.stats = {
            'memory': [],
            'timing': [],
            'flops': {},
            'params': {}
        }
    
    @contextmanager
    def profile_memory(self, tag: str = "default"):
        """å†…å­˜ä½¿ç”¨åˆ†æä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        if self.device == 'cuda' and torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.reset_peak_memory_stats()
            start_memory = torch.cuda.memory_allocated()
            
            yield
            
            peak_memory = torch.cuda.max_memory_allocated()
            end_memory = torch.cuda.memory_allocated()
            
            self.stats['memory'].append({
                'tag': tag,
                'start_mb': start_memory / 1024**2,
                'peak_mb': peak_memory / 1024**2,
                'end_mb': end_memory / 1024**2,
                'allocated_mb': (end_memory - start_memory) / 1024**2
            })
        else:
            # CPUå†…å­˜ç›‘æ§
            process = psutil.Process()
            start_memory = process.memory_info().rss / 1024**2
            
            yield
            
            end_memory = process.memory_info().rss / 1024**2
            
            self.stats['memory'].append({
                'tag': tag,
                'start_mb': start_memory,
                'peak_mb': end_memory,  # ç®€åŒ–å¤„ç†
                'end_mb': end_memory,
                'allocated_mb': end_memory - start_memory
            })
    
    @contextmanager
    def profile_time(self, tag: str = "default"):
        """æ—¶é—´åˆ†æä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        if self.device == 'cuda' and torch.cuda.is_available():
            torch.cuda.synchronize()
        
        start_time = time.perf_counter()
        
        yield
        
        if self.device == 'cuda' and torch.cuda.is_available():
            torch.cuda.synchronize()
        
        end_time = time.perf_counter()
        
        self.stats['timing'].append({
            'tag': tag,
            'duration_ms': (end_time - start_time) * 1000
        })
    
    def profile_model(self, model: nn.Module, input_shape: Tuple[int, ...],
                     num_runs: int = 100, warmup_runs: int = 10) -> Dict[str, Any]:
        """å…¨é¢çš„æ¨¡å‹æ€§èƒ½åˆ†æ
        
        Args:
            model: å¾…åˆ†æçš„æ¨¡å‹
            input_shape: è¾“å…¥å½¢çŠ¶ (B, C, H, W)
            num_runs: æµ‹è¯•è¿è¡Œæ¬¡æ•°
            warmup_runs: é¢„çƒ­è¿è¡Œæ¬¡æ•°
            
        Returns:
            æ€§èƒ½åˆ†ææŠ¥å‘Š
        """
        model.eval()
        device = next(model.parameters()).device
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        dummy_input = torch.randn(input_shape, device=device)
        
        # å‚æ•°é‡ç»Ÿè®¡
        params_info = self.count_parameters(model)
        
        # FLOPsè®¡ç®—
        flops_info = self.calculate_flops(model, dummy_input)
        
        # å†…å­˜ä½¿ç”¨åˆ†æ
        memory_info = self.analyze_memory_usage(model, dummy_input)
        
        # æ¨ç†å»¶è¿Ÿæµ‹è¯•
        latency_info = self.measure_inference_latency(
            model, dummy_input, num_runs, warmup_runs
        )
        
        return {
            'parameters': params_info,
            'flops': flops_info,
            'memory': memory_info,
            'latency': latency_info,
            'input_shape': input_shape,
            'device': str(device)
        }
    
    def count_parameters(self, model: nn.Module) -> Dict[str, Any]:
        """ç»Ÿè®¡æ¨¡å‹å‚æ•°é‡"""
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        # æŒ‰æ¨¡å—ç»Ÿè®¡
        module_params = {}
        for name, module in model.named_modules():
            if len(list(module.children())) == 0:  # å¶å­æ¨¡å—
                params = sum(p.numel() for p in module.parameters())
                if params > 0:
                    module_params[name] = params
        
        return {
            'total': total_params,
            'trainable': trainable_params,
            'non_trainable': total_params - trainable_params,
            'total_mb': total_params * 4 / 1024**2,  # å‡è®¾float32
            'by_module': module_params
        }
    
    def calculate_flops(self, model: nn.Module, input_tensor: torch.Tensor) -> Dict[str, Any]:
        """è®¡ç®—æ¨¡å‹FLOPs"""
        try:
            from fvcore.nn import FlopCountMode, flop_count
            
            # ä½¿ç”¨fvcoreè®¡ç®—FLOPs
            flops_dict, _ = flop_count(model, (input_tensor,), 
                                     supported_ops=None)
            
            total_flops = sum(flops_dict.values())
            
            return {
                'total': total_flops,
                'total_gflops': total_flops / 1e9,
                'by_operation': flops_dict
            }
        except ImportError:
            # ç®€åŒ–çš„FLOPsä¼°ç®—
            return self._estimate_flops_simple(model, input_tensor)
    
    def _estimate_flops_simple(self, model: nn.Module, input_tensor: torch.Tensor) -> Dict[str, Any]:
        """ç®€åŒ–çš„FLOPsä¼°ç®—"""
        total_flops = 0
        B, C, H, W = input_tensor.shape
        
        for name, module in model.named_modules():
            if isinstance(module, nn.Conv2d):
                # å·ç§¯å±‚FLOPs
                kernel_flops = module.kernel_size[0] * module.kernel_size[1] * module.in_channels
                output_elements = H * W * module.out_channels  # ç®€åŒ–å‡è®¾
                flops = kernel_flops * output_elements * B
                total_flops += flops
            
            elif isinstance(module, nn.Linear):
                # å…¨è¿æ¥å±‚FLOPs
                flops = module.in_features * module.out_features * B
                total_flops += flops
        
        return {
            'total': total_flops,
            'total_gflops': total_flops / 1e9,
            'estimation_method': 'simplified'
        }
    
    def analyze_memory_usage(self, model: nn.Module, input_tensor: torch.Tensor) -> Dict[str, Any]:
        """åˆ†æå†…å­˜ä½¿ç”¨"""
        with self.profile_memory("model_forward"):
            with torch.no_grad():
                _ = model(input_tensor)
        
        memory_stats = self.stats['memory'][-1]
        
        # æ¨¡å‹å‚æ•°å†…å­˜
        param_memory = sum(p.numel() * p.element_size() for p in model.parameters()) / 1024**2
        
        # è¾“å…¥å†…å­˜
        input_memory = input_tensor.numel() * input_tensor.element_size() / 1024**2
        
        return {
            'forward_pass_mb': memory_stats['allocated_mb'],
            'peak_memory_mb': memory_stats['peak_mb'],
            'model_parameters_mb': param_memory,
            'input_tensor_mb': input_memory,
            'total_estimated_mb': param_memory + input_memory + memory_stats['allocated_mb']
        }
    
    def measure_inference_latency(self, model: nn.Module, input_tensor: torch.Tensor,
                                 num_runs: int = 100, warmup_runs: int = 10) -> Dict[str, Any]:
        """æµ‹é‡æ¨ç†å»¶è¿Ÿ"""
        model.eval()
        
        # é¢„çƒ­
        with torch.no_grad():
            for _ in range(warmup_runs):
                _ = model(input_tensor)
        
        # æµ‹é‡å»¶è¿Ÿ
        latencies = []
        with torch.no_grad():
            for _ in range(num_runs):
                with self.profile_time("inference"):
                    _ = model(input_tensor)
                latencies.append(self.stats['timing'][-1]['duration_ms'])
        
        latencies = np.array(latencies)
        
        return {
            'mean_ms': float(np.mean(latencies)),
            'std_ms': float(np.std(latencies)),
            'min_ms': float(np.min(latencies)),
            'max_ms': float(np.max(latencies)),
            'median_ms': float(np.median(latencies)),
            'p95_ms': float(np.percentile(latencies, 95)),
            'p99_ms': float(np.percentile(latencies, 99)),
            'num_runs': num_runs,
            'warmup_runs': warmup_runs
        }
    
    def generate_report(self, results: Dict[str, Any], save_path: Optional[Path] = None) -> str:
        """ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š"""
        report_lines = []
        report_lines.append("=" * 60)
        report_lines.append("MODEL PERFORMANCE ANALYSIS REPORT")
        report_lines.append("=" * 60)
        
        # åŸºæœ¬ä¿¡æ¯
        report_lines.append(f"\nInput Shape: {results['input_shape']}")
        report_lines.append(f"Device: {results['device']}")
        
        # å‚æ•°é‡ä¿¡æ¯
        params = results['parameters']
        report_lines.append(f"\nğŸ“Š PARAMETERS:")
        report_lines.append(f"  Total Parameters: {params['total']:,} ({params['total_mb']:.2f} MB)")
        report_lines.append(f"  Trainable: {params['trainable']:,}")
        report_lines.append(f"  Non-trainable: {params['non_trainable']:,}")
        
        # FLOPsä¿¡æ¯
        flops = results['flops']
        report_lines.append(f"\nâš¡ COMPUTATIONAL COMPLEXITY:")
        report_lines.append(f"  Total FLOPs: {flops['total']:,} ({flops['total_gflops']:.2f} GFLOPs)")
        
        # å†…å­˜ä½¿ç”¨
        memory = results['memory']
        report_lines.append(f"\nğŸ’¾ MEMORY USAGE:")
        report_lines.append(f"  Model Parameters: {memory['model_parameters_mb']:.2f} MB")
        report_lines.append(f"  Forward Pass: {memory['forward_pass_mb']:.2f} MB")
        report_lines.append(f"  Peak Memory: {memory['peak_memory_mb']:.2f} MB")
        report_lines.append(f"  Total Estimated: {memory['total_estimated_mb']:.2f} MB")
        
        # å»¶è¿Ÿä¿¡æ¯
        latency = results['latency']
        report_lines.append(f"\nâ±ï¸  INFERENCE LATENCY:")
        report_lines.append(f"  Mean: {latency['mean_ms']:.2f} Â± {latency['std_ms']:.2f} ms")
        report_lines.append(f"  Median: {latency['median_ms']:.2f} ms")
        report_lines.append(f"  Min/Max: {latency['min_ms']:.2f} / {latency['max_ms']:.2f} ms")
        report_lines.append(f"  P95/P99: {latency['p95_ms']:.2f} / {latency['p99_ms']:.2f} ms")
        report_lines.append(f"  Runs: {latency['num_runs']} (warmup: {latency['warmup_runs']})")
        
        # æ•ˆç‡æŒ‡æ ‡
        throughput = 1000 / latency['mean_ms']  # samples per second
        efficiency = flops['total_gflops'] / latency['mean_ms'] * 1000  # GFLOPs per second
        
        report_lines.append(f"\nğŸ“ˆ EFFICIENCY METRICS:")
        report_lines.append(f"  Throughput: {throughput:.2f} samples/sec")
        report_lines.append(f"  Computational Efficiency: {efficiency:.2f} GFLOPs/sec")
        report_lines.append(f"  Memory Efficiency: {params['total'] / memory['peak_memory_mb'] / 1024**2:.2f} params/MB")
        
        report_lines.append("=" * 60)
        
        report_text = "\n".join(report_lines)
        
        if save_path:
            save_path.parent.mkdir(parents=True, exist_ok=True)
            with open(save_path, 'w', encoding='utf-8') as f:
                f.write(report_text)
        
        return report_text
    
    def save_detailed_results(self, results: Dict[str, Any], save_path: Path):
        """ä¿å­˜è¯¦ç»†çš„æ€§èƒ½åˆ†æç»“æœ"""
        save_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜JSONæ ¼å¼çš„è¯¦ç»†ç»“æœ
        with open(save_path.with_suffix('.json'), 'w') as f:
            json.dump(results, f, indent=2, default=str)
        
        # ä¿å­˜æ–‡æœ¬æŠ¥å‘Š
        report = self.generate_report(results)
        with open(save_path.with_suffix('.txt'), 'w', encoding='utf-8') as f:
            f.write(report)


def benchmark_models(models: Dict[str, nn.Module], input_shape: Tuple[int, ...],
                    save_dir: Path, device: str = 'cuda') -> Dict[str, Dict]:
    """æ‰¹é‡æµ‹è¯•å¤šä¸ªæ¨¡å‹çš„æ€§èƒ½
    
    Args:
        models: æ¨¡å‹å­—å…¸ {name: model}
        input_shape: è¾“å…¥å½¢çŠ¶
        save_dir: ä¿å­˜ç›®å½•
        device: è®¾å¤‡
        
    Returns:
        æ‰€æœ‰æ¨¡å‹çš„æ€§èƒ½ç»“æœ
    """
    save_dir.mkdir(parents=True, exist_ok=True)
    profiler = PerformanceProfiler(device)
    
    all_results = {}
    
    for name, model in models.items():
        print(f"Benchmarking {name}...")
        
        # ç§»åŠ¨æ¨¡å‹åˆ°æŒ‡å®šè®¾å¤‡
        model = model.to(device)
        
        # æ€§èƒ½åˆ†æ
        results = profiler.profile_model(model, input_shape)
        all_results[name] = results
        
        # ä¿å­˜å•ä¸ªæ¨¡å‹ç»“æœ
        model_save_path = save_dir / f"{name}_performance"
        profiler.save_detailed_results(results, model_save_path)
        
        # æ¸…ç†å†…å­˜
        if device == 'cuda':
            torch.cuda.empty_cache()
        gc.collect()
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    comparison_report = generate_comparison_report(all_results)
    with open(save_dir / "comparison_report.txt", 'w', encoding='utf-8') as f:
        f.write(comparison_report)
    
    # ä¿å­˜æ±‡æ€»ç»“æœ
    with open(save_dir / "all_results.json", 'w') as f:
        json.dump(all_results, f, indent=2, default=str)
    
    return all_results


def generate_comparison_report(results: Dict[str, Dict]) -> str:
    """ç”Ÿæˆæ¨¡å‹å¯¹æ¯”æŠ¥å‘Š"""
    report_lines = []
    report_lines.append("=" * 80)
    report_lines.append("MODEL COMPARISON REPORT")
    report_lines.append("=" * 80)
    
    # åˆ›å»ºå¯¹æ¯”è¡¨æ ¼
    models = list(results.keys())
    
    # å‚æ•°é‡å¯¹æ¯”
    report_lines.append(f"\nğŸ“Š PARAMETERS COMPARISON:")
    report_lines.append(f"{'Model':<20} {'Total Params':<15} {'Size (MB)':<12} {'Trainable':<15}")
    report_lines.append("-" * 65)
    
    for model in models:
        params = results[model]['parameters']
        report_lines.append(
            f"{model:<20} {params['total']:>14,} {params['total_mb']:>11.2f} "
            f"{params['trainable']:>14,}"
        )
    
    # FLOPså¯¹æ¯”
    report_lines.append(f"\nâš¡ COMPUTATIONAL COMPLEXITY COMPARISON:")
    report_lines.append(f"{'Model':<20} {'GFLOPs':<12} {'Efficiency':<15}")
    report_lines.append("-" * 50)
    
    for model in models:
        flops = results[model]['flops']
        latency = results[model]['latency']
        efficiency = flops['total_gflops'] / latency['mean_ms'] * 1000
        report_lines.append(
            f"{model:<20} {flops['total_gflops']:>11.2f} {efficiency:>14.2f}"
        )
    
    # å†…å­˜ä½¿ç”¨å¯¹æ¯”
    report_lines.append(f"\nğŸ’¾ MEMORY USAGE COMPARISON:")
    report_lines.append(f"{'Model':<20} {'Peak (MB)':<12} {'Forward (MB)':<15} {'Total (MB)':<12}")
    report_lines.append("-" * 65)
    
    for model in models:
        memory = results[model]['memory']
        report_lines.append(
            f"{model:<20} {memory['peak_memory_mb']:>11.2f} "
            f"{memory['forward_pass_mb']:>14.2f} {memory['total_estimated_mb']:>11.2f}"
        )
    
    # å»¶è¿Ÿå¯¹æ¯”
    report_lines.append(f"\nâ±ï¸  INFERENCE LATENCY COMPARISON:")
    report_lines.append(f"{'Model':<20} {'Mean (ms)':<12} {'Std (ms)':<12} {'Throughput':<15}")
    report_lines.append("-" * 65)
    
    for model in models:
        latency = results[model]['latency']
        throughput = 1000 / latency['mean_ms']
        report_lines.append(
            f"{model:<20} {latency['mean_ms']:>11.2f} {latency['std_ms']:>11.2f} "
            f"{throughput:>14.2f}"
        )
    
    # ç»¼åˆæ’å
    report_lines.append(f"\nğŸ† OVERALL RANKING:")
    
    # è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
    scores = {}
    for model in models:
        params_score = 1 / (results[model]['parameters']['total'] / 1e6)  # å‚æ•°è¶Šå°‘è¶Šå¥½
        flops_score = 1 / results[model]['flops']['total_gflops']  # FLOPsè¶Šå°‘è¶Šå¥½
        latency_score = 1 / results[model]['latency']['mean_ms']  # å»¶è¿Ÿè¶Šä½è¶Šå¥½
        memory_score = 1 / results[model]['memory']['peak_memory_mb']  # å†…å­˜è¶Šå°‘è¶Šå¥½
        
        # åŠ æƒå¹³å‡ï¼ˆå¯è°ƒæ•´æƒé‡ï¼‰
        total_score = (params_score * 0.2 + flops_score * 0.3 + 
                      latency_score * 0.3 + memory_score * 0.2)
        scores[model] = total_score
    
    # æŒ‰å¾—åˆ†æ’åº
    ranked_models = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    
    for i, (model, score) in enumerate(ranked_models, 1):
        report_lines.append(f"  {i}. {model} (Score: {score:.4f})")
    
    report_lines.append("=" * 80)
    
    return "\n".join(report_lines)


def profile_training_step(model: nn.Module, optimizer: torch.optim.Optimizer,
                         loss_fn: callable, input_batch: torch.Tensor,
                         target_batch: torch.Tensor) -> Dict[str, float]:
    """åˆ†æå•ä¸ªè®­ç»ƒæ­¥éª¤çš„æ€§èƒ½"""
    profiler = PerformanceProfiler()
    
    # å‰å‘ä¼ æ’­
    with profiler.profile_time("forward"):
        with profiler.profile_memory("forward"):
            output = model(input_batch)
            loss = loss_fn(output, target_batch)
    
    # åå‘ä¼ æ’­
    with profiler.profile_time("backward"):
        with profiler.profile_memory("backward"):
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
    
    # æ±‡æ€»ç»“æœ
    timing_stats = profiler.stats['timing']
    memory_stats = profiler.stats['memory']
    
    return {
        'forward_time_ms': timing_stats[0]['duration_ms'],
        'backward_time_ms': timing_stats[1]['duration_ms'],
        'total_time_ms': sum(t['duration_ms'] for t in timing_stats),
        'forward_memory_mb': memory_stats[0]['allocated_mb'],
        'backward_memory_mb': memory_stats[1]['allocated_mb'],
        'peak_memory_mb': max(m['peak_mb'] for m in memory_stats),
        'loss_value': loss.item()
    }