#!/usr/bin/env python3
"""
ä½¿ç”¨çœŸå®çš„PDEBenchæ•°æ®ç”Ÿæˆå¯è§†åŒ–ç»“æœ
"""

import os
import sys
import h5py
import numpy as np
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
from pathlib import Path
from omegaconf import OmegaConf
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

def load_model_checkpoint(checkpoint_path):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print(f"åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹: {checkpoint_path}")
    
    try:
        # å¯¼å…¥æ¨¡å‹
        from models.swin_unet import SwinUNet
        
        # åˆ›å»ºæ¨¡å‹å®ä¾‹ - æ ¹æ®é…ç½®åˆ›å»º
        model = SwinUNet(
            in_channels=1,
            out_channels=1, 
            img_size=128,
            patch_size=4,
            embed_dim=96,
            depths=[2, 2, 6, 2],
            num_heads=[3, 6, 12, 24],
            window_size=8,
            mlp_ratio=4.0,
            drop_rate=0.0,
            attn_drop_rate=0.0,
            drop_path_rate=0.1
        )
        
        # åŠ è½½æ£€æŸ¥ç‚¹ - è®¾ç½®weights_only=Falseä»¥å…¼å®¹æ—§ç‰ˆæœ¬
        checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)
        
        model.eval()
        print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
        return model
        
    except Exception as e:
        print(f"âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

def apply_sr_degradation(gt_data, scale_factor=4, sigma=1.0):
    """åº”ç”¨è¶…åˆ†è¾¨ç‡é€€åŒ–æ“ä½œ"""
    # è½¬æ¢ä¸ºtensor
    if isinstance(gt_data, np.ndarray):
        gt_tensor = torch.from_numpy(gt_data).float()
    else:
        gt_tensor = gt_data.float()
    
    # ç¡®ä¿æ˜¯4D tensor [B, C, H, W]
    if len(gt_tensor.shape) == 2:
        gt_tensor = gt_tensor.unsqueeze(0).unsqueeze(0)
    elif len(gt_tensor.shape) == 3:
        gt_tensor = gt_tensor.unsqueeze(0)
    
    # é«˜æ–¯æ¨¡ç³Š
    kernel_size = int(2 * np.ceil(2 * sigma) + 1)
    if kernel_size % 2 == 0:
        kernel_size += 1
    
    # åˆ›å»ºé«˜æ–¯æ ¸
    x = torch.arange(kernel_size, dtype=torch.float32) - kernel_size // 2
    gaussian_1d = torch.exp(-0.5 * (x / sigma) ** 2)
    gaussian_1d = gaussian_1d / gaussian_1d.sum()
    gaussian_2d = gaussian_1d[:, None] * gaussian_1d[None, :]
    gaussian_2d = gaussian_2d.unsqueeze(0).unsqueeze(0)
    
    # åº”ç”¨é«˜æ–¯æ¨¡ç³Š
    padding = kernel_size // 2
    blurred = F.conv2d(gt_tensor, gaussian_2d, padding=padding)
    
    # ä¸‹é‡‡æ ·
    lr_tensor = F.interpolate(blurred, scale_factor=1/scale_factor, mode='area')
    
    return lr_tensor.squeeze().numpy(), gt_tensor.squeeze().numpy()

def load_real_pde_samples(data_path, num_samples=3):
    """åŠ è½½çœŸå®çš„PDEBench DarcyFlowæ ·æœ¬"""
    print(f"åŠ è½½çœŸå®PDEæ•°æ®: {data_path}")
    
    samples = []
    with h5py.File(data_path, 'r') as f:
        tensor_data = f['tensor']
        
        # éšæœºé€‰æ‹©æ ·æœ¬
        indices = np.random.choice(tensor_data.shape[0], num_samples, replace=False)
        
        for i, idx in enumerate(indices):
            sample = tensor_data[idx]  # å½¢çŠ¶: (1, 128, 128)
            
            # æå–2Dæ•°æ®
            if len(sample.shape) == 3 and sample.shape[0] == 1:
                sample_2d = sample[0]  # (128, 128)
            else:
                sample_2d = sample
            
            samples.append({
                'index': idx,
                'data': sample_2d,
                'shape': sample.shape,
                'min_val': np.min(sample_2d),
                'max_val': np.max(sample_2d),
                'mean_val': np.mean(sample_2d)
            })
            
            print(f"  æ ·æœ¬{i} (ç´¢å¼•{idx}): å½¢çŠ¶{sample.shape}, èŒƒå›´[{np.min(sample_2d):.6f}, {np.max(sample_2d):.6f}]")
    
    return samples

def create_pde_visualization(samples, model=None, save_dir="runs/visualization"):
    """åˆ›å»ºPDEæ•°æ®å¯è§†åŒ–"""
    os.makedirs(save_dir, exist_ok=True)
    
    num_samples = len(samples)
    
    # 1. åˆ›å»ºGTæ ·æœ¬å¯è§†åŒ–
    fig, axes = plt.subplots(1, num_samples, figsize=(5*num_samples, 5))
    if num_samples == 1:
        axes = [axes]
    
    for i, sample in enumerate(samples):
        gt_data = sample['data']
        
        # ç»˜åˆ¶GTçƒ­å›¾
        im = axes[i].imshow(gt_data, cmap='viridis', aspect='equal')
        axes[i].set_title(f'DarcyFlow GTæ ·æœ¬ {i}\nç´¢å¼•: {sample["index"]}\nèŒƒå›´: [{sample["min_val"]:.4f}, {sample["max_val"]:.4f}]')
        axes[i].axis('off')
        plt.colorbar(im, ax=axes[i], shrink=0.8)
    
    plt.tight_layout()
    plt.savefig(f'{save_dir}/real_pde_gt_samples.png', dpi=150, bbox_inches='tight')
    plt.close()
    print(f"âœ“ GTæ ·æœ¬å¯è§†åŒ–å·²ä¿å­˜: {save_dir}/real_pde_gt_samples.png")
    
    # 2. å¦‚æœæœ‰æ¨¡å‹ï¼Œåˆ›å»ºé¢„æµ‹å¯¹æ¯”
    if model is not None:
        fig, axes = plt.subplots(4, num_samples, figsize=(5*num_samples, 20))
        if num_samples == 1:
            axes = axes.reshape(-1, 1)
        
        for i, sample in enumerate(samples):
            gt_data = sample['data']
            
            # ç”ŸæˆLRæ•°æ®
            lr_data, gt_full = apply_sr_degradation(gt_data, scale_factor=4, sigma=1.0)
            
            # ä¸Šé‡‡æ ·LRåˆ°æ¨¡å‹è¾“å…¥å°ºå¯¸
            lr_tensor = torch.from_numpy(lr_data).float().unsqueeze(0).unsqueeze(0)
            lr_upsampled = F.interpolate(lr_tensor, size=(128, 128), mode='bilinear', align_corners=False)
            
            # æ¨¡å‹é¢„æµ‹
            with torch.no_grad():
                pred_tensor = model(lr_upsampled)
                pred_data = pred_tensor.squeeze().numpy()
            
            # è®¡ç®—è¯¯å·®
            error_data = np.abs(gt_full - pred_data)
            
            # ç»˜åˆ¶å¯¹æ¯”å›¾
            # GT
            im1 = axes[0, i].imshow(gt_full, cmap='viridis', aspect='equal')
            axes[0, i].set_title(f'GTæ ·æœ¬ {i}')
            axes[0, i].axis('off')
            plt.colorbar(im1, ax=axes[0, i], shrink=0.8)
            
            # LR (æ˜¾ç¤ºä¸Šé‡‡æ ·åçš„ç‰ˆæœ¬)
            lr_display = lr_upsampled.squeeze().numpy()
            im2 = axes[1, i].imshow(lr_display, cmap='viridis', aspect='equal')
            axes[1, i].set_title(f'LRè¾“å…¥ (4xä¸‹é‡‡æ ·åä¸Šé‡‡æ ·)')
            axes[1, i].axis('off')
            plt.colorbar(im2, ax=axes[1, i], shrink=0.8)
            
            # Prediction
            im3 = axes[2, i].imshow(pred_data, cmap='viridis', aspect='equal')
            axes[2, i].set_title(f'SwinUNeté¢„æµ‹')
            axes[2, i].axis('off')
            plt.colorbar(im3, ax=axes[2, i], shrink=0.8)
            
            # Error
            im4 = axes[3, i].imshow(error_data, cmap='hot', aspect='equal')
            axes[3, i].set_title(f'ç»å¯¹è¯¯å·®\nMAE: {np.mean(error_data):.6f}')
            axes[3, i].axis('off')
            plt.colorbar(im4, ax=axes[3, i], shrink=0.8)
        
        plt.tight_layout()
        plt.savefig(f'{save_dir}/real_pde_prediction_comparison.png', dpi=150, bbox_inches='tight')
        plt.close()
        print(f"âœ“ é¢„æµ‹å¯¹æ¯”å¯è§†åŒ–å·²ä¿å­˜: {save_dir}/real_pde_prediction_comparison.png")
    
    # 3. åˆ›å»ºç‰©ç†åœºç‰¹å¾åˆ†æ
    fig, axes = plt.subplots(2, num_samples, figsize=(5*num_samples, 10))
    if num_samples == 1:
        axes = axes.reshape(-1, 1)
    
    for i, sample in enumerate(samples):
        gt_data = sample['data']
        
        # åŸå§‹åœº
        im1 = axes[0, i].imshow(gt_data, cmap='viridis', aspect='equal')
        axes[0, i].set_title(f'DarcyFlowå‹åŠ›åœº {i}')
        axes[0, i].axis('off')
        plt.colorbar(im1, ax=axes[0, i], shrink=0.8)
        
        # æ¢¯åº¦åœº
        grad_y, grad_x = np.gradient(gt_data)
        grad_magnitude = np.sqrt(grad_x**2 + grad_y**2)
        im2 = axes[1, i].imshow(grad_magnitude, cmap='plasma', aspect='equal')
        axes[1, i].set_title(f'å‹åŠ›æ¢¯åº¦å¹…å€¼')
        axes[1, i].axis('off')
        plt.colorbar(im2, ax=axes[1, i], shrink=0.8)
    
    plt.tight_layout()
    plt.savefig(f'{save_dir}/real_pde_physical_analysis.png', dpi=150, bbox_inches='tight')
    plt.close()
    print(f"âœ“ ç‰©ç†åœºåˆ†æå·²ä¿å­˜: {save_dir}/real_pde_physical_analysis.png")

def generate_report(samples, save_dir="runs/visualization"):
    """ç”Ÿæˆæ•°æ®æŠ¥å‘Š"""
    report_path = f"{save_dir}/real_pde_data_report.md"
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("# çœŸå®PDEBench DarcyFlowæ•°æ®å¯è§†åŒ–æŠ¥å‘Š\n\n")
        f.write("## æ•°æ®æ¦‚è§ˆ\n\n")
        f.write(f"- **æ•°æ®æº**: PDEBench DarcyFlowæ•°æ®é›†\n")
        f.write(f"- **æ•°æ®è·¯å¾„**: E:/2D/DarcyFlow/2D_DarcyFlow_beta1.0_Train.hdf5\n")
        f.write(f"- **æ ·æœ¬æ•°é‡**: {len(samples)}\n")
        f.write(f"- **æ•°æ®ç±»å‹**: è¾¾è¥¿æµæ–¹ç¨‹çš„å‹åŠ›åœºè§£\n")
        f.write(f"- **ç©ºé—´åˆ†è¾¨ç‡**: 128Ã—128\n\n")
        
        f.write("## æ ·æœ¬è¯¦æƒ…\n\n")
        for i, sample in enumerate(samples):
            f.write(f"### æ ·æœ¬ {i}\n")
            f.write(f"- **æ•°æ®ç´¢å¼•**: {sample['index']}\n")
            f.write(f"- **æ•°æ®å½¢çŠ¶**: {sample['shape']}\n")
            f.write(f"- **æ•°å€¼èŒƒå›´**: [{sample['min_val']:.6f}, {sample['max_val']:.6f}]\n")
            f.write(f"- **å‡å€¼**: {sample['mean_val']:.6f}\n\n")
        
        f.write("## ç‰©ç†æ„ä¹‰\n\n")
        f.write("DarcyFlowæ•°æ®é›†åŒ…å«è¾¾è¥¿æµæ–¹ç¨‹çš„æ•°å€¼è§£ï¼Œæè¿°äº†å¤šå­”ä»‹è´¨ä¸­çš„æµä½“æµåŠ¨ã€‚\n")
        f.write("- **å‹åŠ›åœº**: æ˜¾ç¤ºæµä½“åœ¨å¤šå­”ä»‹è´¨ä¸­çš„å‹åŠ›åˆ†å¸ƒ\n")
        f.write("- **è¾¹ç•Œæ¡ä»¶**: åæ˜ ä¸åŒçš„æµåŠ¨è¾¹ç•Œè®¾ç½®\n")
        f.write("- **ç‰©ç†å‚æ•°**: æ¸—é€ç‡åœºå½±å“æµåŠ¨æ¨¡å¼\n\n")
        
        f.write("## ç”Ÿæˆçš„å¯è§†åŒ–æ–‡ä»¶\n\n")
        f.write("1. `real_pde_gt_samples.png` - GTæ ·æœ¬çƒ­å›¾\n")
        f.write("2. `real_pde_prediction_comparison.png` - æ¨¡å‹é¢„æµ‹å¯¹æ¯”\n")
        f.write("3. `real_pde_physical_analysis.png` - ç‰©ç†åœºç‰¹å¾åˆ†æ\n")
        f.write("4. `real_pde_data_report.md` - æœ¬æŠ¥å‘Š\n\n")
        
        f.write("## æ•°æ®éªŒè¯\n\n")
        f.write("âœ“ ç¡®è®¤ä½¿ç”¨çœŸå®çš„PDEBench DarcyFlowæ•°æ®\n")
        f.write("âœ“ æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡ (tensoré”®ï¼Œå½¢çŠ¶10000Ã—1Ã—128Ã—128)\n")
        f.write("âœ“ ç‰©ç†åœºç‰¹å¾ç¬¦åˆè¾¾è¥¿æµæ–¹ç¨‹è§£çš„é¢„æœŸ\n")
    
    print(f"âœ“ æ•°æ®æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹ç”ŸæˆçœŸå®PDEBenchæ•°æ®å¯è§†åŒ–...")
    
    # æ•°æ®è·¯å¾„
    data_path = "E:/2D/DarcyFlow/2D_DarcyFlow_beta1.0_Train.hdf5"
    
    if not Path(data_path).exists():
        print(f"âœ— æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
        return
    
    # åŠ è½½çœŸå®PDEæ ·æœ¬
    samples = load_real_pde_samples(data_path, num_samples=3)
    
    # å°è¯•åŠ è½½æ¨¡å‹
    checkpoint_path = "runs/checkpoints/best.pth"
    model = None
    if Path(checkpoint_path).exists():
        model = load_model_checkpoint(checkpoint_path)
    else:
        print(f"âš  æœªæ‰¾åˆ°æ¨¡å‹æ£€æŸ¥ç‚¹: {checkpoint_path}")
        print("  å°†åªç”ŸæˆGTæ•°æ®å¯è§†åŒ–")
    
    # åˆ›å»ºå¯è§†åŒ–
    create_pde_visualization(samples, model)
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_report(samples)
    
    # å¤åˆ¶åˆ°paper_package
    paper_figs_dir = "paper_package/figs"
    os.makedirs(paper_figs_dir, exist_ok=True)
    
    import shutil
    viz_files = [
        "runs/visualization/real_pde_gt_samples.png",
        "runs/visualization/real_pde_prediction_comparison.png", 
        "runs/visualization/real_pde_physical_analysis.png"
    ]
    
    for file_path in viz_files:
        if Path(file_path).exists():
            shutil.copy(file_path, paper_figs_dir)
            print(f"âœ“ å·²å¤åˆ¶åˆ°paper_package: {Path(file_path).name}")
    
    print("\nğŸ‰ çœŸå®PDEBenchæ•°æ®å¯è§†åŒ–å®Œæˆ!")
    print("ğŸ“ æŸ¥çœ‹ç»“æœ: runs/visualization/")
    print("ğŸ“Š è®ºæ–‡å›¾è¡¨: paper_package/figs/")

if __name__ == "__main__":
    main()