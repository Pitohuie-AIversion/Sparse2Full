import json
import pandas as pd
import os

# åŠ è½½èµ„æºæ•°æ®
with open("paper_package/metrics/model_resources.json", 'r') as f:
    resources = json.load(f)

# åŠ è½½åŸå§‹æ’åæ•°æ®
ranking_df = pd.read_csv("paper_package/metrics/original_model_ranking.csv")

print(f"åŠ è½½äº† {len(ranking_df)} ä¸ªæ¨¡å‹çš„æ€§èƒ½æ•°æ®")
print(f"åŠ è½½äº† {len(resources)} ä¸ªæ¨¡å‹çš„èµ„æºæ•°æ®")

# åˆå¹¶æ•°æ®
enhanced_data = []

for _, row in ranking_df.iterrows():
    model_name = row['æ¨¡å‹']
    
    # åŸºç¡€æ•°æ®
    base_data = {
        'æ’å': row.name + 1,
        'æ¨¡å‹': model_name,
        'Rel-L2': row['Rel-L2'],
        'MAE': row['MAE'],
        'PSNR': row['PSNR'],
        'SSIM': row['SSIM'],
        'BRMSE': row['BRMSE'],
        'CRMSE': row['CRMSE'],
        'æœ€ä½³éªŒè¯æŸå¤±': row['æœ€ä½³éªŒè¯æŸå¤±'],
        'è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)': row['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)']
    }
    
    # æ·»åŠ èµ„æºæ•°æ®
    if model_name in resources:
        resource_data = resources[model_name]
        base_data.update({
            'å‚æ•°é‡(M)': round(resource_data['total_params_M'], 2),
            'å¯è®­ç»ƒå‚æ•°(M)': round(resource_data['trainable_params_M'], 2),
            'æ¨¡å‹å¤§å°(MB)': round(resource_data['model_size_MB'], 1),
            'FLOPs(G)': round(resource_data['flops_G'], 1),
            'GFLOPS/s': round(resource_data['gflops_per_sec'], 1),
            'è®­ç»ƒæ˜¾å­˜(GB)': round(resource_data['training_memory_GB'], 2),
            'æ¨ç†æ˜¾å­˜(GB)': round(resource_data['inference_memory_GB'], 2),
            'æ¨ç†å»¶è¿Ÿ(ms)': round(resource_data['latency_ms'], 1),
            'å»¶è¿Ÿæ ‡å‡†å·®(ms)': round(resource_data['latency_std_ms'], 2),
            'FPS': round(resource_data['fps'], 1)
        })
    else:
        print(f"è­¦å‘Šï¼šæœªæ‰¾åˆ°æ¨¡å‹ {model_name} çš„èµ„æºæ•°æ®")
        base_data.update({
            'å‚æ•°é‡(M)': 0.0,
            'å¯è®­ç»ƒå‚æ•°(M)': 0.0,
            'æ¨¡å‹å¤§å°(MB)': 0.0,
            'FLOPs(G)': 0.0,
            'GFLOPS/s': 0.0,
            'è®­ç»ƒæ˜¾å­˜(GB)': 0.0,
            'æ¨ç†æ˜¾å­˜(GB)': 0.0,
            'æ¨ç†å»¶è¿Ÿ(ms)': 0.0,
            'å»¶è¿Ÿæ ‡å‡†å·®(ms)': 0.0,
            'FPS': 0.0
        })
    
    enhanced_data.append(base_data)

# åˆ›å»ºDataFrame
enhanced_df = pd.DataFrame(enhanced_data)

# ä¿å­˜å¢å¼ºçš„CSV
csv_file = "paper_package/metrics/enhanced_model_comparison_with_resources.csv"
enhanced_df.to_csv(csv_file, index=False, encoding='utf-8')
print(f"å¢å¼ºCSVå·²ä¿å­˜: {csv_file}")

# ä¿å­˜Excelæ–‡ä»¶
excel_file = "paper_package/metrics/comprehensive_model_comparison_with_resources.xlsx"
with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
    # ä¸»è¡¨
    enhanced_df.to_excel(writer, sheet_name='å®Œæ•´å¯¹æ¯”', index=False)
    
    # æ€§èƒ½æŒ‡æ ‡è¡¨
    performance_cols = ['æ’å', 'æ¨¡å‹', 'Rel-L2', 'PSNR', 'SSIM', 'è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)']
    enhanced_df[performance_cols].to_excel(writer, sheet_name='æ€§èƒ½æŒ‡æ ‡', index=False)
    
    # èµ„æºæŒ‡æ ‡è¡¨
    resource_cols = ['æ’å', 'æ¨¡å‹', 'å‚æ•°é‡(M)', 'FLOPs(G)', 'æ¨ç†å»¶è¿Ÿ(ms)', 'FPS', 'è®­ç»ƒæ˜¾å­˜(GB)', 'æ¨ç†æ˜¾å­˜(GB)']
    enhanced_df[resource_cols].to_excel(writer, sheet_name='èµ„æºæŒ‡æ ‡', index=False)

print(f"Excelæ–‡ä»¶å·²ä¿å­˜: {excel_file}")

# åˆ›å»ºMarkdownè¡¨æ ¼
markdown_file = "paper_package/metrics/enhanced_model_comparison_with_resources.md"

with open(markdown_file, 'w', encoding='utf-8') as f:
    f.write("# ğŸš€ Sparse2Full å¢å¼ºæ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨ï¼ˆå«èµ„æºç»Ÿè®¡ï¼‰\n\n")
    f.write(f"**ç”Ÿæˆæ—¶é—´**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
    
    # ä¸»è¦å¯¹æ¯”è¡¨
    f.write("## ğŸ“Š ç»¼åˆæ€§èƒ½å¯¹æ¯”ï¼ˆå«èµ„æºç»Ÿè®¡ï¼‰\n\n")
    
    # é€‰æ‹©ä¸»è¦åˆ—æ˜¾ç¤º
    display_cols = [
        'æ’å', 'æ¨¡å‹', 'Rel-L2', 'PSNR', 'SSIM', 
        'å‚æ•°é‡(M)', 'FLOPs(G)', 'æ¨ç†å»¶è¿Ÿ(ms)', 'FPS',
        'è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)'
    ]
    
    display_df = enhanced_df[display_cols].copy()
    f.write(display_df.to_markdown(index=False))
    f.write("\n\n")
    
    # èµ„æºç»Ÿè®¡åˆ†æ
    f.write("## ğŸ“ˆ èµ„æºç»Ÿè®¡åˆ†æ\n\n")
    
    # å‚æ•°é‡ç»Ÿè®¡
    f.write("### ğŸ”¢ å‚æ•°é‡ç»Ÿè®¡\n\n")
    f.write(f"- æœ€å°‘å‚æ•°: {enhanced_df['å‚æ•°é‡(M)'].min():.2f}M ({enhanced_df.loc[enhanced_df['å‚æ•°é‡(M)'].idxmin(), 'æ¨¡å‹']})\n")
    f.write(f"- æœ€å¤šå‚æ•°: {enhanced_df['å‚æ•°é‡(M)'].max():.2f}M ({enhanced_df.loc[enhanced_df['å‚æ•°é‡(M)'].idxmax(), 'æ¨¡å‹']})\n")
    f.write(f"- å¹³å‡å‚æ•°: {enhanced_df['å‚æ•°é‡(M)'].mean():.2f}M\n\n")
    
    # FLOPsç»Ÿè®¡
    f.write("### âš¡ FLOPsç»Ÿè®¡\n\n")
    f.write(f"- æœ€å°‘FLOPs: {enhanced_df['FLOPs(G)'].min():.1f}G ({enhanced_df.loc[enhanced_df['FLOPs(G)'].idxmin(), 'æ¨¡å‹']})\n")
    f.write(f"- æœ€å¤šFLOPs: {enhanced_df['FLOPs(G)'].max():.1f}G ({enhanced_df.loc[enhanced_df['FLOPs(G)'].idxmax(), 'æ¨¡å‹']})\n")
    f.write(f"- å¹³å‡FLOPs: {enhanced_df['FLOPs(G)'].mean():.1f}G\n\n")
    
    # æ¨ç†æ€§èƒ½ç»Ÿè®¡
    f.write("### ğŸš€ æ¨ç†æ€§èƒ½ç»Ÿè®¡\n\n")
    valid_latency = enhanced_df[enhanced_df['æ¨ç†å»¶è¿Ÿ(ms)'] > 0]
    if not valid_latency.empty:
        f.write(f"- æœ€å¿«æ¨ç†: {valid_latency['æ¨ç†å»¶è¿Ÿ(ms)'].min():.1f}ms ({valid_latency.loc[valid_latency['æ¨ç†å»¶è¿Ÿ(ms)'].idxmin(), 'æ¨¡å‹']})\n")
        f.write(f"- æœ€æ…¢æ¨ç†: {valid_latency['æ¨ç†å»¶è¿Ÿ(ms)'].max():.1f}ms ({valid_latency.loc[valid_latency['æ¨ç†å»¶è¿Ÿ(ms)'].idxmax(), 'æ¨¡å‹']})\n")
        f.write(f"- å¹³å‡å»¶è¿Ÿ: {valid_latency['æ¨ç†å»¶è¿Ÿ(ms)'].mean():.1f}ms\n\n")
    
    # æœ€ä½³æ¨¡å‹æ¨è
    f.write("## ğŸ† æœ€ä½³æ¨¡å‹æ¨è\n\n")
    
    top3 = enhanced_df.head(3)
    for i, (_, row) in enumerate(top3.iterrows(), 1):
        medal = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"][i-1]
        f.write(f"{medal} **{row['æ¨¡å‹']}**\n")
        f.write(f"   - Rel-L2: {row['Rel-L2']:.4f}\n")
        f.write(f"   - PSNR: {row['PSNR']:.2f} dB\n")
        f.write(f"   - å‚æ•°é‡: {row['å‚æ•°é‡(M)']:.2f}M\n")
        f.write(f"   - FLOPs: {row['FLOPs(G)']:.1f}G\n")
        f.write(f"   - æ¨ç†å»¶è¿Ÿ: {row['æ¨ç†å»¶è¿Ÿ(ms)']:.1f}ms\n\n")
    
    # ä½¿ç”¨å»ºè®®
    f.write("## ğŸ’¡ ä½¿ç”¨å»ºè®®\n\n")
    f.write("### ğŸ¯ æŒ‰åº”ç”¨åœºæ™¯é€‰æ‹©\n\n")
    
    best_accuracy = enhanced_df.iloc[0]
    fastest_model = enhanced_df.loc[enhanced_df['æ¨ç†å»¶è¿Ÿ(ms)'].idxmin()] if enhanced_df['æ¨ç†å»¶è¿Ÿ(ms)'].max() > 0 else None
    smallest_model = enhanced_df.loc[enhanced_df['å‚æ•°é‡(M)'].idxmin()]
    
    f.write(f"- **ğŸ”¬ ç§‘ç ”é¡¹ç›®**: {best_accuracy['æ¨¡å‹']} (æœ€é«˜ç²¾åº¦)\n")
    if fastest_model is not None:
        f.write(f"- **ğŸš€ å®æ—¶åº”ç”¨**: {fastest_model['æ¨¡å‹']} (æœ€å¿«æ¨ç†)\n")
    f.write(f"- **ğŸ“± è¾¹ç¼˜è®¡ç®—**: {smallest_model['æ¨¡å‹']} (æœ€å°‘å‚æ•°)\n\n")
    
    f.write("### ğŸ“Š æŠ€æœ¯æŒ‡æ ‡è¯´æ˜\n\n")
    f.write("- **å‚æ•°é‡(M)**: æ¨¡å‹æ€»å‚æ•°æ•°é‡ï¼ˆç™¾ä¸‡ï¼‰\n")
    f.write("- **FLOPs(G)**: æµ®ç‚¹è¿ç®—æ¬¡æ•°ï¼ŒæŒ‰256Ã—256è¾“å…¥è®¡ç®—ï¼ˆåäº¿æ¬¡ï¼‰\n")
    f.write("- **æ¨ç†å»¶è¿Ÿ(ms)**: å•æ¬¡æ¨ç†æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰\n")
    f.write("- **FPS**: æ¯ç§’å¤„ç†å¸§æ•°\n")
    f.write("- **GFLOPS/s**: è®¡ç®—æ•ˆç‡ï¼ˆæ¯ç§’åäº¿æ¬¡æµ®ç‚¹è¿ç®—ï¼‰\n")
    f.write("- **è®­ç»ƒæ˜¾å­˜(GB)**: è®­ç»ƒæ—¶å³°å€¼æ˜¾å­˜ä½¿ç”¨é‡ä¼°ç®—\n")
    f.write("- **æ¨ç†æ˜¾å­˜(GB)**: æ¨ç†æ—¶æ˜¾å­˜ä½¿ç”¨é‡ä¼°ç®—\n\n")
    
    f.write("---\n\n")
    f.write("*æœ¬æŠ¥å‘Šç”±PDEBenchç¨€ç–è§‚æµ‹é‡å»ºç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆï¼ŒåŒ…å«å®Œæ•´çš„æ€§èƒ½å’Œèµ„æºç»Ÿè®¡æ•°æ®*\n")

print(f"Markdownæ–‡ä»¶å·²ä¿å­˜: {markdown_file}")

print("\n=== å¢å¼ºæ¨¡å‹å¯¹æ¯”è¡¨æ ¼åˆ›å»ºå®Œæˆ ===")
print(f"æ€»å…±å¤„ç†äº† {len(enhanced_df)} ä¸ªæ¨¡å‹")
print("\nç”Ÿæˆçš„æ–‡ä»¶:")
print("- enhanced_model_comparison_with_resources.csv")
print("- comprehensive_model_comparison_with_resources.xlsx")
print("- enhanced_model_comparison_with_resources.md")

# æ˜¾ç¤ºå‰3å
print("\nğŸ† æ€§èƒ½æ’åå‰3:")
for i, (_, row) in enumerate(enhanced_df.head(3).iterrows(), 1):
    medal = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"][i-1]
    print(f"{medal} {row['æ¨¡å‹']}: Rel-L2={row['Rel-L2']:.4f}, å‚æ•°é‡={row['å‚æ•°é‡(M)']:.1f}M, å»¶è¿Ÿ={row['æ¨ç†å»¶è¿Ÿ(ms)']:.1f}ms")