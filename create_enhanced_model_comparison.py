#!/usr/bin/env python3
"""
åˆ›å»ºåŒ…å«å®Œæ•´èµ„æºç»Ÿè®¡çš„å¢å¼ºæ¨¡å‹å¯¹æ¯”è¡¨æ ¼
"""

import os
import json
import pandas as pd
import numpy as np
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

def load_model_resources():
    """åŠ è½½æ¨¡å‹èµ„æºç»Ÿè®¡æ•°æ®"""
    resource_file = "paper_package/metrics/model_resources.json"
    if not os.path.exists(resource_file):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°èµ„æºæ–‡ä»¶ {resource_file}")
        return {}
    
    with open(resource_file, 'r', encoding='utf-8') as f:
        return json.load(f)

def load_original_ranking():
    """åŠ è½½åŸå§‹æ’åæ•°æ®"""
    ranking_file = "paper_package/metrics/original_model_ranking.csv"
    if not os.path.exists(ranking_file):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ’åæ–‡ä»¶ {ranking_file}")
        return pd.DataFrame()
    
    return pd.read_csv(ranking_file)

def create_enhanced_comparison_table():
    """åˆ›å»ºå¢å¼ºçš„æ¨¡å‹å¯¹æ¯”è¡¨æ ¼"""
    
    # åŠ è½½æ•°æ®
    resources = load_model_resources()
    ranking_df = load_original_ranking()
    
    if ranking_df.empty or not resources:
        print("é”™è¯¯ï¼šæ— æ³•åŠ è½½å¿…è¦çš„æ•°æ®æ–‡ä»¶")
        return None
    
    print(f"åŠ è½½äº† {len(ranking_df)} ä¸ªæ¨¡å‹çš„æ€§èƒ½æ•°æ®")
    print(f"åŠ è½½äº† {len(resources)} ä¸ªæ¨¡å‹çš„èµ„æºæ•°æ®")
    
    # åˆå¹¶æ•°æ®
    enhanced_data = []
    
    for _, row in ranking_df.iterrows():
        model_name = row['æ¨¡å‹']
        
        # åŸºç¡€æ€§èƒ½æ•°æ®
        base_data = {
            'æ¨¡å‹': model_name,
            'Rel-L2': row['Rel-L2'],
            'MAE': row['MAE'],
            'PSNR': row['PSNR'],
            'SSIM': row['SSIM'],
            'BRMSE': row['BRMSE'],
            'CRMSE': row['CRMSE'],
            'FRMSE_low': row['FRMSE_low'],
            'FRMSE_high': row['FRMSE_high'],
            'è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)': row['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)']
        }
        
        # æ·»åŠ èµ„æºæ•°æ®
        if model_name in resources:
            resource_data = resources[model_name]
            base_data.update({
                'å‚æ•°é‡(M)': resource_data['total_params_M'],
                'å¯è®­ç»ƒå‚æ•°(M)': resource_data['trainable_params_M'],
                'æ¨¡å‹å¤§å°(MB)': resource_data['model_size_MB'],
                'FLOPs(G)': resource_data['flops_G'],
                'GFLOPS/s': resource_data['gflops_per_sec'],
                'è®­ç»ƒæ˜¾å­˜(GB)': resource_data['training_memory_GB'],
                'æ¨ç†æ˜¾å­˜(GB)': resource_data['inference_memory_GB'],
                'æ¨ç†å»¶è¿Ÿ(ms)': resource_data['latency_ms'],
                'å»¶è¿Ÿæ ‡å‡†å·®(ms)': resource_data['latency_std_ms'],
                'FPS': resource_data['fps']
            })
        else:
            # é»˜è®¤å€¼
            base_data.update({
                'å‚æ•°é‡(M)': 0.0,
                'å¯è®­ç»ƒå‚æ•°(M)': 0.0,
                'æ¨¡å‹å¤§å°(MB)': 0.0,
                'FLOPs(G)': 0.0,
                'GFLOPS/s': 0.0,
                'è®­ç»ƒæ˜¾å­˜(GB)': 0.0,
                'æ¨ç†æ˜¾å­˜(GB)': 0.0,
                'æ¨ç†å»¶è¿Ÿ(ms)': 0.0,
                'å»¶è¿Ÿæ ‡å‡†å·®(ms)': 0.0,
                'FPS': 0.0
            })
        
        enhanced_data.append(base_data)
    
    # åˆ›å»ºDataFrame
    enhanced_df = pd.DataFrame(enhanced_data)
    
    # æŒ‰Rel-L2æ’åº
    enhanced_df = enhanced_df.sort_values('Rel-L2').reset_index(drop=True)
    enhanced_df.index = enhanced_df.index + 1  # ä»1å¼€å§‹æ’å
    
    return enhanced_df

def add_model_categories(df):
    """æ·»åŠ æ¨¡å‹ç±»åˆ«ä¿¡æ¯"""
    model_categories = {
        'FNO2D': 'Fourier Neural Operator',
        'SwinUNet': 'Vision Transformer',
        'UNet': 'Convolutional Network',
        'MLP': 'Multi-Layer Perceptron',
        'MLP_Mixer': 'MLP-based Architecture',
        'Hybrid': 'Hybrid Architecture',
        'UFNO_UNet': 'Hybrid FNO-UNet',
        'UNetPlusPlus': 'Enhanced UNet'
    }
    
    df['æ¨¡å‹ç±»åˆ«'] = df['æ¨¡å‹'].map(model_categories)
    return df

def add_performance_grades(df):
    """æ·»åŠ æ€§èƒ½ç­‰çº§"""
    # Rel-L2æ€§èƒ½ç­‰çº§
    rel_l2_values = df['Rel-L2'].values
    rel_l2_percentiles = np.percentile(rel_l2_values, [25, 50, 75])
    
    def get_performance_grade(rel_l2):
        if rel_l2 <= rel_l2_percentiles[0]:
            return "A+ (ä¼˜ç§€)"
        elif rel_l2 <= rel_l2_percentiles[1]:
            return "A (è‰¯å¥½)"
        elif rel_l2 <= rel_l2_percentiles[2]:
            return "B (ä¸­ç­‰)"
        else:
            return "C (ä¸€èˆ¬)"
    
    df['æ€§èƒ½ç­‰çº§'] = df['Rel-L2'].apply(get_performance_grade)
    
    # æ•ˆç‡ç­‰çº§ï¼ˆåŸºäºæ¨ç†å»¶è¿Ÿï¼‰
    latency_values = df['æ¨ç†å»¶è¿Ÿ(ms)'].values
    latency_percentiles = np.percentile(latency_values[latency_values > 0], [25, 50, 75])
    
    def get_efficiency_grade(latency):
        if latency <= 0:
            return "æœªçŸ¥"
        elif latency <= latency_percentiles[0]:
            return "A+ (æå¿«)"
        elif latency <= latency_percentiles[1]:
            return "A (å¿«é€Ÿ)"
        elif latency <= latency_percentiles[2]:
            return "B (ä¸­ç­‰)"
        else:
            return "C (è¾ƒæ…¢)"
    
    df['æ•ˆç‡ç­‰çº§'] = df['æ¨ç†å»¶è¿Ÿ(ms)'].apply(get_efficiency_grade)
    
    return df

def calculate_composite_score(df):
    """è®¡ç®—ç»¼åˆè¯„åˆ†"""
    # å½’ä¸€åŒ–å„é¡¹æŒ‡æ ‡ï¼ˆ0-100åˆ†ï¼‰
    def normalize_score(values, higher_better=True):
        if higher_better:
            return 100 * (values - values.min()) / (values.max() - values.min())
        else:
            return 100 * (values.max() - values) / (values.max() - values.min())
    
    # æ€§èƒ½æŒ‡æ ‡ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
    rel_l2_score = normalize_score(df['Rel-L2'], higher_better=False)
    psnr_score = normalize_score(df['PSNR'], higher_better=True)
    ssim_score = normalize_score(df['SSIM'], higher_better=True)
    
    # æ•ˆç‡æŒ‡æ ‡ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
    latency_score = normalize_score(df['æ¨ç†å»¶è¿Ÿ(ms)'].replace(0, df['æ¨ç†å»¶è¿Ÿ(ms)'].max()), higher_better=False)
    training_time_score = normalize_score(df['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)'], higher_better=False)
    
    # èµ„æºæŒ‡æ ‡ï¼ˆå‚æ•°é‡é€‚ä¸­æ›´å¥½ï¼‰
    params_score = normalize_score(df['å‚æ•°é‡(M)'], higher_better=False)
    
    # ç»¼åˆè¯„åˆ†ï¼ˆæƒé‡åˆ†é…ï¼‰
    composite_score = (
        0.4 * rel_l2_score +      # 40% é‡å»ºç²¾åº¦
        0.2 * psnr_score +        # 20% å›¾åƒè´¨é‡
        0.1 * ssim_score +        # 10% ç»“æ„ç›¸ä¼¼æ€§
        0.15 * latency_score +    # 15% æ¨ç†é€Ÿåº¦
        0.1 * training_time_score + # 10% è®­ç»ƒæ•ˆç‡
        0.05 * params_score       # 5% æ¨¡å‹å¤æ‚åº¦
    )
    
    df['ç»¼åˆè¯„åˆ†'] = composite_score.round(1)
    return df

def save_enhanced_tables(df):
    """ä¿å­˜å¢å¼ºçš„è¡¨æ ¼"""
    output_dir = Path("paper_package/metrics")
    output_dir.mkdir(exist_ok=True)
    
    # 1. ä¿å­˜å®Œæ•´CSV
    csv_file = output_dir / "enhanced_model_comparison_with_resources.csv"
    df.to_csv(csv_file, index=True, encoding='utf-8')
    print(f"å®Œæ•´CSVå·²ä¿å­˜: {csv_file}")
    
    # 2. åˆ›å»ºExcelæ–‡ä»¶
    excel_file = output_dir / "comprehensive_model_comparison_with_resources.xlsx"
    with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
        # ä¸»è¡¨
        df.to_excel(writer, sheet_name='æ¨¡å‹å¯¹æ¯”', index=True)
        
        # æ€§èƒ½æŒ‡æ ‡è¡¨
        performance_cols = ['æ¨¡å‹', 'æ¨¡å‹ç±»åˆ«', 'Rel-L2', 'PSNR', 'SSIM', 'æ€§èƒ½ç­‰çº§', 'ç»¼åˆè¯„åˆ†']
        df[performance_cols].to_excel(writer, sheet_name='æ€§èƒ½æŒ‡æ ‡', index=True)
        
        # èµ„æºæŒ‡æ ‡è¡¨
        resource_cols = ['æ¨¡å‹', 'å‚æ•°é‡(M)', 'FLOPs(G)', 'æ¨ç†å»¶è¿Ÿ(ms)', 'FPS', 'è®­ç»ƒæ˜¾å­˜(GB)', 'æ¨ç†æ˜¾å­˜(GB)']
        df[resource_cols].to_excel(writer, sheet_name='èµ„æºæŒ‡æ ‡', index=True)
        
        # æ•ˆç‡åˆ†æè¡¨
        efficiency_cols = ['æ¨¡å‹', 'è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)', 'æ¨ç†å»¶è¿Ÿ(ms)', 'GFLOPS/s', 'æ•ˆç‡ç­‰çº§']
        df[efficiency_cols].to_excel(writer, sheet_name='æ•ˆç‡åˆ†æ', index=True)
    
    print(f"Excelæ–‡ä»¶å·²ä¿å­˜: {excel_file}")
    
    # 3. åˆ›å»ºMarkdownè¡¨æ ¼
    markdown_file = output_dir / "enhanced_model_comparison_with_resources.md"
    
    with open(markdown_file, 'w', encoding='utf-8') as f:
        f.write("# ğŸš€ Sparse2Full å¢å¼ºæ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨ï¼ˆå«èµ„æºç»Ÿè®¡ï¼‰\n\n")
        f.write(f"**ç”Ÿæˆæ—¶é—´**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # ä¸»è¦å¯¹æ¯”è¡¨
        f.write("## ğŸ“Š ç»¼åˆæ€§èƒ½å¯¹æ¯”ï¼ˆå«èµ„æºç»Ÿè®¡ï¼‰\n\n")
        
        # é€‰æ‹©ä¸»è¦åˆ—æ˜¾ç¤º
        display_cols = [
            'æ¨¡å‹', 'æ¨¡å‹ç±»åˆ«', 'Rel-L2', 'PSNR', 'SSIM', 
            'å‚æ•°é‡(M)', 'FLOPs(G)', 'æ¨ç†å»¶è¿Ÿ(ms)', 'FPS',
            'è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)', 'ç»¼åˆè¯„åˆ†'
        ]
        
        display_df = df[display_cols].copy()
        
        # æ ¼å¼åŒ–æ•°å€¼
        display_df['Rel-L2'] = display_df['Rel-L2'].apply(lambda x: f"{x:.4f}")
        display_df['PSNR'] = display_df['PSNR'].apply(lambda x: f"{x:.2f}")
        display_df['SSIM'] = display_df['SSIM'].apply(lambda x: f"{x:.4f}")
        display_df['å‚æ•°é‡(M)'] = display_df['å‚æ•°é‡(M)'].apply(lambda x: f"{x:.2f}")
        display_df['FLOPs(G)'] = display_df['FLOPs(G)'].apply(lambda x: f"{x:.1f}")
        display_df['æ¨ç†å»¶è¿Ÿ(ms)'] = display_df['æ¨ç†å»¶è¿Ÿ(ms)'].apply(lambda x: f"{x:.1f}")
        display_df['FPS'] = display_df['FPS'].apply(lambda x: f"{x:.1f}")
        display_df['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)'] = display_df['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)'].apply(lambda x: f"{x:.2f}")
        display_df['ç»¼åˆè¯„åˆ†'] = display_df['ç»¼åˆè¯„åˆ†'].apply(lambda x: f"{x:.1f}")
        
        f.write(display_df.to_markdown(index=True))
        f.write("\n\n")
        
        # èµ„æºç»Ÿè®¡åˆ†æ
        f.write("## ğŸ“ˆ èµ„æºç»Ÿè®¡åˆ†æ\n\n")
        
        # å‚æ•°é‡ç»Ÿè®¡
        f.write("### ğŸ”¢ å‚æ•°é‡ç»Ÿè®¡\n\n")
        params_stats = df.groupby('æ¨¡å‹ç±»åˆ«')['å‚æ•°é‡(M)'].agg(['mean', 'std', 'min', 'max'])
        f.write(params_stats.round(2).to_markdown())
        f.write("\n\n")
        
        # FLOPsç»Ÿè®¡
        f.write("### âš¡ FLOPsç»Ÿè®¡\n\n")
        flops_stats = df.groupby('æ¨¡å‹ç±»åˆ«')['FLOPs(G)'].agg(['mean', 'std', 'min', 'max'])
        f.write(flops_stats.round(1).to_markdown())
        f.write("\n\n")
        
        # æ¨ç†æ€§èƒ½ç»Ÿè®¡
        f.write("### ğŸš€ æ¨ç†æ€§èƒ½ç»Ÿè®¡\n\n")
        inference_stats = df.groupby('æ¨¡å‹ç±»åˆ«')[['æ¨ç†å»¶è¿Ÿ(ms)', 'FPS']].agg(['mean', 'std'])
        f.write(inference_stats.round(2).to_markdown())
        f.write("\n\n")
        
        # æœ€ä½³æ¨¡å‹æ¨è
        f.write("## ğŸ† æœ€ä½³æ¨¡å‹æ¨è\n\n")
        
        top3 = df.head(3)
        for i, (_, row) in enumerate(top3.iterrows(), 1):
            medal = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"][i-1]
            f.write(f"{medal} **{row['æ¨¡å‹']}** ({row['æ¨¡å‹ç±»åˆ«']})\n")
            f.write(f"   - Rel-L2: {row['Rel-L2']:.4f}\n")
            f.write(f"   - PSNR: {row['PSNR']:.2f} dB\n")
            f.write(f"   - å‚æ•°é‡: {row['å‚æ•°é‡(M)']:.2f}M\n")
            f.write(f"   - FLOPs: {row['FLOPs(G)']:.1f}G\n")
            f.write(f"   - æ¨ç†å»¶è¿Ÿ: {row['æ¨ç†å»¶è¿Ÿ(ms)']:.1f}ms\n")
            f.write(f"   - ç»¼åˆè¯„åˆ†: {row['ç»¼åˆè¯„åˆ†']:.1f}/100\n\n")
        
        # æ•ˆç‡åˆ†æ
        f.write("## âš¡ æ•ˆç‡åˆ†æ\n\n")
        
        # æœ€å¿«æ¨ç†
        fastest_inference = df.loc[df['æ¨ç†å»¶è¿Ÿ(ms)'].idxmin()]
        f.write(f"### ğŸš€ æœ€å¿«æ¨ç†: {fastest_inference['æ¨¡å‹']}\n")
        f.write(f"- æ¨ç†å»¶è¿Ÿ: {fastest_inference['æ¨ç†å»¶è¿Ÿ(ms)']:.1f}ms\n")
        f.write(f"- FPS: {fastest_inference['FPS']:.1f}\n")
        f.write(f"- å‚æ•°é‡: {fastest_inference['å‚æ•°é‡(M)']:.2f}M\n\n")
        
        # æœ€å°‘å‚æ•°
        smallest_model = df.loc[df['å‚æ•°é‡(M)'].idxmin()]
        f.write(f"### ğŸ“¦ æœ€å°‘å‚æ•°: {smallest_model['æ¨¡å‹']}\n")
        f.write(f"- å‚æ•°é‡: {smallest_model['å‚æ•°é‡(M)']:.2f}M\n")
        f.write(f"- æ¨¡å‹å¤§å°: {smallest_model['æ¨¡å‹å¤§å°(MB)']:.1f}MB\n")
        f.write(f"- Rel-L2: {smallest_model['Rel-L2']:.4f}\n\n")
        
        # æœ€é«˜æ•ˆç‡
        highest_efficiency = df.loc[df['GFLOPS/s'].idxmax()]
        f.write(f"### âš¡ æœ€é«˜è®¡ç®—æ•ˆç‡: {highest_efficiency['æ¨¡å‹']}\n")
        f.write(f"- è®¡ç®—æ•ˆç‡: {highest_efficiency['GFLOPS/s']:.1f} GFLOPS/s\n")
        f.write(f"- FLOPs: {highest_efficiency['FLOPs(G)']:.1f}G\n")
        f.write(f"- æ¨ç†å»¶è¿Ÿ: {highest_efficiency['æ¨ç†å»¶è¿Ÿ(ms)']:.1f}ms\n\n")
        
        # ä½¿ç”¨å»ºè®®
        f.write("## ğŸ’¡ ä½¿ç”¨å»ºè®®\n\n")
        f.write("### ğŸ¯ æŒ‰åº”ç”¨åœºæ™¯é€‰æ‹©\n\n")
        f.write("- **ğŸ”¬ ç§‘ç ”é¡¹ç›®**: FNO2D (æœ€é«˜ç²¾åº¦ï¼Œåˆç†èµ„æºæ¶ˆè€—)\n")
        f.write("- **ğŸ­ å·¥ä¸šåº”ç”¨**: UNet (ç²¾åº¦ä¸æ•ˆç‡å¹³è¡¡)\n")
        f.write("- **ğŸš€ å®æ—¶åº”ç”¨**: MLP_Mixer (æœ€å¿«æ¨ç†é€Ÿåº¦)\n")
        f.write("- **ğŸ“± è¾¹ç¼˜è®¡ç®—**: MLP (æœ€å°‘å‚æ•°é‡)\n\n")
        
        f.write("### ğŸ“Š æŠ€æœ¯æŒ‡æ ‡è¯´æ˜\n\n")
        f.write("- **å‚æ•°é‡(M)**: æ¨¡å‹æ€»å‚æ•°æ•°é‡ï¼ˆç™¾ä¸‡ï¼‰\n")
        f.write("- **FLOPs(G)**: æµ®ç‚¹è¿ç®—æ¬¡æ•°ï¼ŒæŒ‰256Ã—256è¾“å…¥è®¡ç®—ï¼ˆåäº¿æ¬¡ï¼‰\n")
        f.write("- **æ¨ç†å»¶è¿Ÿ(ms)**: å•æ¬¡æ¨ç†æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰\n")
        f.write("- **FPS**: æ¯ç§’å¤„ç†å¸§æ•°\n")
        f.write("- **GFLOPS/s**: è®¡ç®—æ•ˆç‡ï¼ˆæ¯ç§’åäº¿æ¬¡æµ®ç‚¹è¿ç®—ï¼‰\n")
        f.write("- **è®­ç»ƒæ˜¾å­˜(GB)**: è®­ç»ƒæ—¶å³°å€¼æ˜¾å­˜ä½¿ç”¨é‡ä¼°ç®—\n")
        f.write("- **æ¨ç†æ˜¾å­˜(GB)**: æ¨ç†æ—¶æ˜¾å­˜ä½¿ç”¨é‡ä¼°ç®—\n\n")
        
        f.write("---\n\n")
        f.write("*æœ¬æŠ¥å‘Šç”±PDEBenchç¨€ç–è§‚æµ‹é‡å»ºç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆï¼ŒåŒ…å«å®Œæ•´çš„æ€§èƒ½å’Œèµ„æºç»Ÿè®¡æ•°æ®*\n")
    
    print(f"Markdownæ–‡ä»¶å·²ä¿å­˜: {markdown_file}")
    
    return df

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹åˆ›å»ºå¢å¼ºçš„æ¨¡å‹å¯¹æ¯”è¡¨æ ¼...")
    
    # åˆ›å»ºå¢å¼ºè¡¨æ ¼
    enhanced_df = create_enhanced_comparison_table()
    if enhanced_df is None:
        return
    
    # æ·»åŠ åˆ†ç±»å’Œç­‰çº§
    enhanced_df = add_model_categories(enhanced_df)
    enhanced_df = add_performance_grades(enhanced_df)
    enhanced_df = calculate_composite_score(enhanced_df)
    
    # ä¿å­˜è¡¨æ ¼
    final_df = save_enhanced_tables(enhanced_df)
    
    print("\n=== å¢å¼ºæ¨¡å‹å¯¹æ¯”è¡¨æ ¼åˆ›å»ºå®Œæˆ ===")
    print(f"æ€»å…±å¤„ç†äº† {len(enhanced_df)} ä¸ªæ¨¡å‹")
    print("\nç”Ÿæˆçš„æ–‡ä»¶:")
    print("- enhanced_model_comparison_with_resources.csv")
    print("- comprehensive_model_comparison_with_resources.xlsx")
    print("- enhanced_model_comparison_with_resources.md")
    
    # æ˜¾ç¤ºå‰3å
    print("\nğŸ† æ€§èƒ½æ’åå‰3:")
    for i, (_, row) in enumerate(enhanced_df.head(3).iterrows(), 1):
        medal = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"][i-1]
        print(f"{medal} {row['æ¨¡å‹']}: Rel-L2={row['Rel-L2']:.4f}, å‚æ•°é‡={row['å‚æ•°é‡(M)']:.1f}M, å»¶è¿Ÿ={row['æ¨ç†å»¶è¿Ÿ(ms)']:.1f}ms")

if __name__ == "__main__":
    main()