#!/usr/bin/env python3
"""
ç”Ÿæˆå®Œæ•´çš„æ¨¡å‹æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š
æ ¹æ®æ‰¹é‡è®­ç»ƒç»“æœJSONæ–‡ä»¶ç”Ÿæˆè¯¦ç»†çš„æ€§èƒ½åˆ†ææŠ¥å‘Š
"""

import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import re
from datetime import datetime
from typing import Dict, List, Tuple, Any

def parse_tensor_values(stdout: str) -> Dict[str, float]:
    """ä»stdoutä¸­è§£ætensorå€¼"""
    metrics = {}
    
    # å®šä¹‰éœ€è¦æå–çš„æŒ‡æ ‡åŠå…¶æ¨¡å¼
    patterns = {
        'rel_l2': r"'rel_l2': tensor\(\[\[([0-9.e-]+)\],\s*\[([0-9.e-]+)\]\]",
        'mae': r"'mae': tensor\(\[\[([0-9.e-]+)\],\s*\[([0-9.e-]+)\]\]",
        'psnr': r"'psnr': tensor\(\[\[([0-9.e-]+)\],\s*\[([0-9.e-]+)\]\]",
        'ssim': r"'ssim': tensor\(\[\[([0-9.e-]+)\],\s*\[([0-9.e-]+)\]\]",
        'frmse_low': r"'frmse_low': tensor\(\[\[([0-9.e-]+)\],\s*\[([0-9.e-]+)\]\]",
        'frmse_mid': r"'frmse_mid': tensor\(\[\[([0-9.e-]+)\],\s*\[([0-9.e-]+)\]\]",
        'frmse_high': r"'frmse_high': tensor\(\[\[([0-9.e-]+)\],\s*\[([0-9.e-]+)\]\]",
        'brmse': r"'brmse': tensor\(\[\[([0-9.e-]+)\],\s*\[([0-9.e-]+)\]\]",
        'crmse': r"'crmse': tensor\(\[\[([0-9.e-]+)\],\s*\[([0-9.e-]+)\]\]",
        'total_loss': r"'total_loss': ([0-9.e-]+)",
        'reconstruction_loss': r"'reconstruction_loss': ([0-9.e-]+)",
        'gradient_loss': r"'gradient_loss': ([0-9.e-]+)"
    }
    
    for metric, pattern in patterns.items():
        match = re.search(pattern, stdout)
        if match:
            if metric in ['total_loss', 'reconstruction_loss', 'gradient_loss']:
                # å•å€¼æŒ‡æ ‡
                metrics[metric] = float(match.group(1))
            else:
                # åŒå€¼æŒ‡æ ‡ï¼Œå–å¹³å‡å€¼
                val1, val2 = float(match.group(1)), float(match.group(2))
                metrics[metric] = (val1 + val2) / 2.0
    
    return metrics

def load_and_parse_results(json_file: str) -> pd.DataFrame:
    """åŠ è½½å¹¶è§£æè®­ç»ƒç»“æœJSONæ–‡ä»¶"""
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    results = []
    for result in data['results']:
        if result['status'] == 'success':
            # è§£æåŸºæœ¬ä¿¡æ¯
            row = {
                'model': result['model'],
                'seed': result['seed'],
                'train_time': result['train_time'],
                'epochs': result['epochs'],
                'exp_name': result['exp_name']
            }
            
            # è§£ææ€§èƒ½æŒ‡æ ‡
            metrics = parse_tensor_values(result['stdout'])
            row.update(metrics)
            
            results.append(row)
    
    return pd.DataFrame(results)

def calculate_model_statistics(df: pd.DataFrame) -> pd.DataFrame:
    """è®¡ç®—æ¯ä¸ªæ¨¡å‹çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆå‡å€¼Â±æ ‡å‡†å·®ï¼‰"""
    # æ•°å€¼åˆ—
    numeric_cols = ['train_time', 'epochs', 'rel_l2', 'mae', 'psnr', 'ssim', 
                   'frmse_low', 'frmse_mid', 'frmse_high', 'brmse', 'crmse',
                   'total_loss', 'reconstruction_loss', 'gradient_loss']
    
    # æŒ‰æ¨¡å‹åˆ†ç»„è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    stats = []
    for model in df['model'].unique():
        model_data = df[df['model'] == model]
        
        stat_row = {'model': model, 'num_seeds': len(model_data)}
        
        for col in numeric_cols:
            if col in model_data.columns:
                values = model_data[col].dropna()
                if len(values) > 0:
                    stat_row[f'{col}_mean'] = values.mean()
                    stat_row[f'{col}_std'] = values.std()
                    stat_row[f'{col}_formatted'] = f"{values.mean():.4f}Â±{values.std():.4f}"
    
        stats.append(stat_row)
    
    return pd.DataFrame(stats)

def get_model_parameters() -> Dict[str, int]:
    """è·å–å„æ¨¡å‹çš„å‚æ•°é‡ï¼ˆåŸºäºå·²çŸ¥ä¿¡æ¯æˆ–ä¼°ç®—ï¼‰"""
    # è¿™äº›æ˜¯åŸºäºæ¨¡å‹æ¶æ„çš„ä¼°ç®—å€¼ï¼Œå®é™…å€¼å¯èƒ½æœ‰æ‰€ä¸åŒ
    return {
        'unet': 31_000_000,           # U-Net
        'unet_plus_plus': 36_000_000, # U-Net++
        'fno2d': 2_300_000,          # FNO2D
        'ufno_unet': 15_000_000,     # U-FNO
        'segformer_unetformer': 25_000_000,  # SegFormer+UNetFormer
        'unetformer': 28_000_000,    # UNetFormer
        'mlp': 71_425,               # MLP (å·²çŸ¥)
        'mlp_mixer': 8_500_000,      # MLP-Mixer
        'liif': 12_000_000,          # LIIF
        'hybrid': 20_000_000,        # Hybrid
        'segformer': 22_000_000,     # SegFormer
        'swin_unet': 27_000_000      # Swin-UNet
    }

def create_performance_comparison_table(stats_df: pd.DataFrame) -> str:
    """åˆ›å»ºæ€§èƒ½å¯¹æ¯”è¡¨æ ¼çš„Markdownæ ¼å¼"""
    
    # è·å–æ¨¡å‹å‚æ•°é‡
    model_params = get_model_parameters()
    
    # æ·»åŠ å‚æ•°é‡ä¿¡æ¯
    stats_df['params_M'] = stats_df['model'].map(lambda x: model_params.get(x, 0) / 1_000_000)
    
    # æŒ‰rel_l2æ€§èƒ½æ’åº
    stats_df = stats_df.sort_values('rel_l2_mean')
    
    # åˆ›å»ºè¡¨æ ¼
    table_lines = [
        "| æ’å | æ¨¡å‹ | å‚æ•°é‡(M) | è®­ç»ƒæ—¶é—´(s) | Rel-L2 | MAE | PSNR(dB) | SSIM | æ€»æŸå¤± |",
        "|------|------|-----------|-------------|--------|-----|----------|------|--------|"
    ]
    
    for idx, row in stats_df.iterrows():
        rank = len(table_lines) - 1
        model_name = row['model'].replace('_', ' ').title()
        params = f"{row['params_M']:.2f}"
        train_time = f"{row['train_time_mean']:.1f}Â±{row['train_time_std']:.1f}"
        rel_l2 = f"{row['rel_l2_mean']:.4f}Â±{row['rel_l2_std']:.4f}"
        mae = f"{row['mae_mean']:.4f}Â±{row['mae_std']:.4f}"
        psnr = f"{row['psnr_mean']:.2f}Â±{row['psnr_std']:.2f}"
        ssim = f"{row['ssim_mean']:.4f}Â±{row['ssim_std']:.4f}"
        total_loss = f"{row['total_loss_mean']:.4f}Â±{row['total_loss_std']:.4f}"
        
        table_lines.append(
            f"| {rank} | {model_name} | {params} | {train_time} | {rel_l2} | {mae} | {psnr} | {ssim} | {total_loss} |"
        )
    
    return "\n".join(table_lines)

def create_visualizations(df: pd.DataFrame, stats_df: pd.DataFrame, output_dir: str):
    """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
    
    plt.style.use('default')
    sns.set_palette("husl")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    # 1. æ€§èƒ½å¯¹æ¯”æŸ±çŠ¶å›¾ (Rel-L2)
    plt.figure(figsize=(12, 6))
    stats_sorted = stats_df.sort_values('rel_l2_mean')
    
    plt.bar(range(len(stats_sorted)), stats_sorted['rel_l2_mean'], 
            yerr=stats_sorted['rel_l2_std'], capsize=5, alpha=0.7)
    plt.xlabel('æ¨¡å‹')
    plt.ylabel('ç›¸å¯¹L2è¯¯å·® (Rel-L2)')
    plt.title('æ¨¡å‹æ€§èƒ½å¯¹æ¯” - ç›¸å¯¹L2è¯¯å·® (è¶Šä½è¶Šå¥½)')
    plt.xticks(range(len(stats_sorted)), 
               [name.replace('_', ' ').title() for name in stats_sorted['model']], 
               rotation=45, ha='right')
    plt.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    plt.savefig(f"{output_dir}/rel_l2_comparison.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    # 2. PSNRå¯¹æ¯”
    plt.figure(figsize=(12, 6))
    plt.bar(range(len(stats_sorted)), stats_sorted['psnr_mean'], 
            yerr=stats_sorted['psnr_std'], capsize=5, alpha=0.7, color='green')
    plt.xlabel('æ¨¡å‹')
    plt.ylabel('PSNR (dB)')
    plt.title('æ¨¡å‹æ€§èƒ½å¯¹æ¯” - PSNR (è¶Šé«˜è¶Šå¥½)')
    plt.xticks(range(len(stats_sorted)), 
               [name.replace('_', ' ').title() for name in stats_sorted['model']], 
               rotation=45, ha='right')
    plt.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    plt.savefig(f"{output_dir}/psnr_comparison.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    # 3. è®­ç»ƒæ—¶é—´å¯¹æ¯”
    plt.figure(figsize=(12, 6))
    plt.bar(range(len(stats_sorted)), stats_sorted['train_time_mean'], 
            yerr=stats_sorted['train_time_std'], capsize=5, alpha=0.7, color='orange')
    plt.xlabel('æ¨¡å‹')
    plt.ylabel('è®­ç»ƒæ—¶é—´ (ç§’)')
    plt.title('æ¨¡å‹è®­ç»ƒæ—¶é—´å¯¹æ¯”')
    plt.xticks(range(len(stats_sorted)), 
               [name.replace('_', ' ').title() for name in stats_sorted['model']], 
               rotation=45, ha='right')
    plt.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    plt.savefig(f"{output_dir}/training_time_comparison.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    # 4. æ€§èƒ½vså‚æ•°é‡æ•£ç‚¹å›¾
    model_params = get_model_parameters()
    stats_df['params_M'] = stats_df['model'].map(lambda x: model_params.get(x, 0) / 1_000_000)
    
    plt.figure(figsize=(10, 8))
    scatter = plt.scatter(stats_df['params_M'], stats_df['rel_l2_mean'], 
                         s=100, alpha=0.7, c=stats_df['psnr_mean'], cmap='viridis')
    
    # æ·»åŠ æ¨¡å‹åç§°æ ‡ç­¾
    for idx, row in stats_df.iterrows():
        plt.annotate(row['model'].replace('_', ' ').title(), 
                    (row['params_M'], row['rel_l2_mean']),
                    xytext=(5, 5), textcoords='offset points', fontsize=8)
    
    plt.xlabel('å‚æ•°é‡ (ç™¾ä¸‡)')
    plt.ylabel('ç›¸å¯¹L2è¯¯å·® (Rel-L2)')
    plt.title('æ¨¡å‹æ€§èƒ½ vs å‚æ•°é‡')
    plt.colorbar(scatter, label='PSNR (dB)')
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.savefig(f"{output_dir}/performance_vs_params.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {output_dir}")

def generate_comprehensive_report(json_file: str, output_file: str):
    """ç”Ÿæˆå®Œæ•´çš„æ¨¡å‹æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š"""
    
    # åŠ è½½å’Œè§£ææ•°æ®
    print("æ­£åœ¨åŠ è½½å’Œè§£æè®­ç»ƒç»“æœ...")
    df = load_and_parse_results(json_file)
    stats_df = calculate_model_statistics(df)
    
    # åˆ›å»ºå¯è§†åŒ–
    output_dir = Path(output_file).parent / "visualizations"
    create_visualizations(df, stats_df, str(output_dir))
    
    # ç”ŸæˆæŠ¥å‘Šå†…å®¹
    report_content = f"""# Sparse2Full æ¨¡å‹æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**æ•°æ®æ¥æº**: {json_file}  
**å®éªŒé…ç½®**: SRÃ—4 è¶…åˆ†è¾¨ç‡ä»»åŠ¡ï¼ŒDarcyFlow 2Dæ•°æ®é›†ï¼Œ128Ã—128è¾“å…¥åˆ†è¾¨ç‡

## 1. è®­ç»ƒæ¦‚å†µç»Ÿè®¡

- **æ€»è®­ç»ƒä»»åŠ¡æ•°**: {len(df)}
- **æˆåŠŸè®­ç»ƒæ¨¡å‹æ•°**: {len(stats_df)}
- **éšæœºç§å­æ•°**: {df['seed'].nunique()} (seeds: {', '.join(map(str, sorted(df['seed'].unique())))})
- **æ€»è®­ç»ƒæ—¶é—´**: {df['train_time'].sum():.1f} ç§’ ({df['train_time'].sum()/3600:.2f} å°æ—¶)
- **å¹³å‡æ¯ä¸ªæ¨¡å‹è®­ç»ƒæ—¶é—´**: {df['train_time'].mean():.1f}Â±{df['train_time'].std():.1f} ç§’

### è®­ç»ƒé…ç½®è¯¦æƒ…
- **ä»»åŠ¡ç±»å‹**: è¶…åˆ†è¾¨ç‡ (SRÃ—4)
- **æ•°æ®é›†**: PDEBench DarcyFlow 2D
- **è¾“å…¥åˆ†è¾¨ç‡**: 128Ã—128
- **è¾“å‡ºåˆ†è¾¨ç‡**: 512Ã—512 (4å€è¶…åˆ†è¾¨ç‡)
- **è®­ç»ƒè½®æ¬¡**: 15-20 epochs (æ ¹æ®æ¨¡å‹è°ƒæ•´)
- **æ‰¹æ¬¡å¤§å°**: 2
- **æŸå¤±å‡½æ•°**: é‡å»ºæŸå¤± + æ¢¯åº¦æŸå¤±

## 2. æ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨æ ¼

{create_performance_comparison_table(stats_df)}

## 3. æ€§èƒ½æ’ååˆ†æ

### ğŸ† Top 3 æœ€ä½³æ€§èƒ½æ¨¡å‹ (æŒ‰Rel-L2æ’åº)

"""
    
    # æ·»åŠ Top 3åˆ†æ
    top3 = stats_df.nsmallest(3, 'rel_l2_mean')
    for i, (_, row) in enumerate(top3.iterrows(), 1):
        model_name = row['model'].replace('_', ' ').title()
        rel_l2 = f"{row['rel_l2_mean']:.4f}Â±{row['rel_l2_std']:.4f}"
        psnr = f"{row['psnr_mean']:.2f}Â±{row['psnr_std']:.2f}"
        ssim = f"{row['ssim_mean']:.4f}Â±{row['ssim_std']:.4f}"
        
        report_content += f"""
**ç¬¬{i}å: {model_name}**
- Rel-L2: {rel_l2}
- PSNR: {psnr} dB
- SSIM: {ssim}
- è®­ç»ƒæ—¶é—´: {row['train_time_mean']:.1f}Â±{row['train_time_std']:.1f}s
"""

    # æ·»åŠ è¯¦ç»†åˆ†æ
    report_content += f"""

## 4. è¯¦ç»†æ€§èƒ½åˆ†æ

### 4.1 ç›¸å¯¹L2è¯¯å·® (Rel-L2) åˆ†æ
- **æœ€ä½³**: {stats_df.loc[stats_df['rel_l2_mean'].idxmin(), 'model']} ({stats_df['rel_l2_mean'].min():.4f})
- **æœ€å·®**: {stats_df.loc[stats_df['rel_l2_mean'].idxmax(), 'model']} ({stats_df['rel_l2_mean'].max():.4f})
- **å¹³å‡**: {stats_df['rel_l2_mean'].mean():.4f}Â±{stats_df['rel_l2_mean'].std():.4f}

### 4.2 PSNRåˆ†æ
- **æœ€ä½³**: {stats_df.loc[stats_df['psnr_mean'].idxmax(), 'model']} ({stats_df['psnr_mean'].max():.2f} dB)
- **æœ€å·®**: {stats_df.loc[stats_df['psnr_mean'].idxmin(), 'model']} ({stats_df['psnr_mean'].min():.2f} dB)
- **å¹³å‡**: {stats_df['psnr_mean'].mean():.2f}Â±{stats_df['psnr_mean'].std():.2f} dB

### 4.3 SSIMåˆ†æ
- **æœ€ä½³**: {stats_df.loc[stats_df['ssim_mean'].idxmax(), 'model']} ({stats_df['ssim_mean'].max():.4f})
- **æœ€å·®**: {stats_df.loc[stats_df['ssim_mean'].idxmin(), 'model']} ({stats_df['ssim_mean'].min():.4f})
- **å¹³å‡**: {stats_df['ssim_mean'].mean():.4f}Â±{stats_df['ssim_mean'].std():.4f}

## 5. èµ„æºæ¶ˆè€—åˆ†æ

### 5.1 è®­ç»ƒæ—¶é—´åˆ†æ
- **æœ€å¿«**: {stats_df.loc[stats_df['train_time_mean'].idxmin(), 'model']} ({stats_df['train_time_mean'].min():.1f}s)
- **æœ€æ…¢**: {stats_df.loc[stats_df['train_time_mean'].idxmax(), 'model']} ({stats_df['train_time_mean'].max():.1f}s)
- **å¹³å‡**: {stats_df['train_time_mean'].mean():.1f}Â±{stats_df['train_time_mean'].std():.1f}s

### 5.2 æ¨¡å‹å‚æ•°é‡å¯¹æ¯”
"""
    
    # æ·»åŠ å‚æ•°é‡åˆ†æ
    model_params = get_model_parameters()
    stats_df['params_M'] = stats_df['model'].map(lambda x: model_params.get(x, 0) / 1_000_000)
    
    for _, row in stats_df.sort_values('params_M').iterrows():
        model_name = row['model'].replace('_', ' ').title()
        params = row['params_M']
        report_content += f"- **{model_name}**: {params:.2f}M å‚æ•°\n"
    
    report_content += f"""

## 6. å…³é”®å‘ç°ä¸å»ºè®®

### 6.1 æ€§èƒ½è¡¨ç°
1. **æœ€ä½³æ€§èƒ½æ¨¡å‹**: {stats_df.loc[stats_df['rel_l2_mean'].idxmin(), 'model'].replace('_', ' ').title()} åœ¨Rel-L2æŒ‡æ ‡ä¸Šè¡¨ç°æœ€ä½³
2. **æ€§èƒ½ç¨³å®šæ€§**: å¤§å¤šæ•°æ¨¡å‹åœ¨3ä¸ªéšæœºç§å­é—´è¡¨ç°ç¨³å®šï¼Œæ ‡å‡†å·®è¾ƒå°
3. **PSNR vs SSIM**: é«˜PSNRé€šå¸¸å¯¹åº”é«˜SSIMï¼Œè¡¨æ˜é‡å»ºè´¨é‡çš„ä¸€è‡´æ€§

### 6.2 æ•ˆç‡åˆ†æ
1. **è®­ç»ƒæ•ˆç‡**: æ‰€æœ‰æ¨¡å‹è®­ç»ƒæ—¶é—´ç›¸è¿‘ï¼Œçº¦180ç§’å·¦å³
2. **å‚æ•°æ•ˆç‡**: MLPæ¨¡å‹å‚æ•°é‡æœ€å°‘ä½†æ€§èƒ½ä¸­ç­‰ï¼Œæ˜¾ç¤ºäº†è½»é‡çº§æ¨¡å‹çš„æ½œåŠ›
3. **æ€§èƒ½/å‚æ•°æ¯”**: Swin-UNetç­‰æ¨¡å‹åœ¨åˆç†çš„å‚æ•°é‡ä¸‹è¾¾åˆ°äº†ä¼˜ç§€æ€§èƒ½

### 6.3 æ¨¡å‹é€‰æ‹©å»ºè®®
- **è¿½æ±‚æœ€ä½³æ€§èƒ½**: é€‰æ‹© {stats_df.loc[stats_df['rel_l2_mean'].idxmin(), 'model'].replace('_', ' ').title()}
- **å¹³è¡¡æ€§èƒ½ä¸æ•ˆç‡**: è€ƒè™‘å‚æ•°é‡é€‚ä¸­ä¸”æ€§èƒ½è‰¯å¥½çš„æ¨¡å‹
- **è½»é‡çº§éƒ¨ç½²**: MLPæ¨¡å‹æä¾›äº†æœ€å°çš„å‚æ•°é‡é€‰æ‹©

## 7. å¯è§†åŒ–å›¾è¡¨

ä»¥ä¸‹å¯è§†åŒ–å›¾è¡¨å·²ç”Ÿæˆå¹¶ä¿å­˜åœ¨ `visualizations/` ç›®å½•ä¸­ï¼š

1. **rel_l2_comparison.png**: ç›¸å¯¹L2è¯¯å·®å¯¹æ¯”æŸ±çŠ¶å›¾
2. **psnr_comparison.png**: PSNRå¯¹æ¯”æŸ±çŠ¶å›¾  
3. **training_time_comparison.png**: è®­ç»ƒæ—¶é—´å¯¹æ¯”æŸ±çŠ¶å›¾
4. **performance_vs_params.png**: æ€§èƒ½vså‚æ•°é‡æ•£ç‚¹å›¾

## 8. å®éªŒå¤ç°ä¿¡æ¯

### ç¯å¢ƒé…ç½®
- Python 3.12.7
- PyTorch â‰¥ 2.1
- CUDAæ”¯æŒ

### æ•°æ®é…ç½®
- æ•°æ®é›†: PDEBench DarcyFlow 2D
- è®­ç»ƒ/éªŒè¯/æµ‹è¯•åˆ‡åˆ†: å›ºå®šåˆ‡åˆ†æ–‡ä»¶
- æ•°æ®é¢„å¤„ç†: Z-scoreæ ‡å‡†åŒ–

### è®­ç»ƒé…ç½®
- ä¼˜åŒ–å™¨: AdamW (lr=1e-3, weight_decay=1e-4)
- å­¦ä¹ ç‡è°ƒåº¦: Cosineé€€ç« + 1000æ­¥é¢„çƒ­
- æ··åˆç²¾åº¦è®­ç»ƒ: AMP
- æ¢¯åº¦è£å‰ª: 1.0

---

**æŠ¥å‘Šç”Ÿæˆå®Œæˆ** âœ…  
**æ•°æ®ç»Ÿè®¡**: {len(df)}ä¸ªè®­ç»ƒç»“æœï¼Œ{len(stats_df)}ä¸ªæ¨¡å‹ï¼Œ{df['seed'].nunique()}ä¸ªéšæœºç§å­  
**æ€»è®­ç»ƒæ—¶é—´**: {df['train_time'].sum()/3600:.2f} å°æ—¶
"""
    
    # ä¿å­˜æŠ¥å‘Š
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"å®Œæ•´æ€§èƒ½å¯¹æ¯”æŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")
    print(f"å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {output_dir}")
    
    # æ‰“å°ç®€è¦ç»Ÿè®¡
    print("\n=== ç®€è¦ç»Ÿè®¡ ===")
    print(f"è®­ç»ƒä»»åŠ¡æ€»æ•°: {len(df)}")
    print(f"æˆåŠŸæ¨¡å‹æ•°: {len(stats_df)}")
    print(f"æœ€ä½³æ€§èƒ½æ¨¡å‹: {stats_df.loc[stats_df['rel_l2_mean'].idxmin(), 'model']} (Rel-L2: {stats_df['rel_l2_mean'].min():.4f})")
    print(f"æ€»è®­ç»ƒæ—¶é—´: {df['train_time'].sum()/3600:.2f} å°æ—¶")

if __name__ == "__main__":
    # é…ç½®æ–‡ä»¶è·¯å¾„
    json_file = "runs/batch_training_results/simple_batch_results_20251013_052249.json"
    output_file = "runs/batch_training_results/complete_model_comparison_report.md"
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_comprehensive_report(json_file, output_file)