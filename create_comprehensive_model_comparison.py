#!/usr/bin/env python3
"""
åˆ›å»ºå®Œæ•´çš„æ¨¡å‹å¯¹æ¯”è¡¨æ ¼å’ŒæŠ¥å‘Š
åŒ…å«æ‰€æœ‰é‡è¦å‚æ•°å’Œæ€§èƒ½æŒ‡æ ‡
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json
import yaml
from typing import Dict, List, Any, Optional
import logging
from datetime import datetime
import openpyxl
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
from openpyxl.utils.dataframe import dataframe_to_rows
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.offline as pyo

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")

class ComprehensiveModelComparison:
    """ç»¼åˆæ¨¡å‹å¯¹æ¯”åˆ†æå™¨"""
    
    def __init__(self, batch_results_dir: str):
        self.batch_results_dir = Path(batch_results_dir)
        self.output_dir = self.batch_results_dir / "comprehensive_analysis"
        self.output_dir.mkdir(exist_ok=True)
        
        # åŠ è½½ç°æœ‰çš„CSVæ•°æ®
        self.csv_file = self.batch_results_dir / "analysis" / "model_ranking.csv"
        if not self.csv_file.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ°æ¨¡å‹æ’åCSVæ–‡ä»¶: {self.csv_file}")
        
        self.df = pd.read_csv(self.csv_file)
        logger.info(f"åŠ è½½äº† {len(self.df)} ä¸ªæ¨¡å‹çš„æ•°æ®")
        
    def enhance_model_data(self) -> pd.DataFrame:
        """å¢å¼ºæ¨¡å‹æ•°æ®ï¼Œæ·»åŠ æ›´å¤šå‚æ•°ä¿¡æ¯"""
        enhanced_df = self.df.copy()
        
        # æ·»åŠ æ¨¡å‹ç±»åˆ«
        model_categories = {
            'FNO2D': 'Fourier Neural Operator',
            'SwinUNet': 'Vision Transformer',
            'UNet': 'Convolutional Network',
            'MLP': 'Multi-Layer Perceptron',
            'MLP_Mixer': 'MLP-based Architecture',
            'Hybrid': 'Hybrid Architecture',
            'UFNO_UNet': 'Hybrid FNO-UNet',
            'UNetPlusPlus': 'Enhanced UNet'
        }
        
        enhanced_df['æ¨¡å‹ç±»åˆ«'] = enhanced_df['æ¨¡å‹'].map(model_categories)
        
        # æ·»åŠ æ€§èƒ½ç­‰çº§
        def get_performance_grade(rel_l2):
            if rel_l2 <= 0.02:
                return 'A+ (ä¼˜ç§€)'
            elif rel_l2 <= 0.04:
                return 'A (è‰¯å¥½)'
            elif rel_l2 <= 0.08:
                return 'B (ä¸­ç­‰)'
            elif rel_l2 <= 0.15:
                return 'C (ä¸€èˆ¬)'
            else:
                return 'D (è¾ƒå·®)'
        
        enhanced_df['æ€§èƒ½ç­‰çº§'] = enhanced_df['Rel-L2'].apply(get_performance_grade)
        
        # æ·»åŠ æ•ˆç‡ç­‰çº§
        def get_efficiency_grade(time_minutes):
            if time_minutes <= 1:
                return 'A+ (æå¿«)'
            elif time_minutes <= 3:
                return 'A (å¿«é€Ÿ)'
            elif time_minutes <= 10:
                return 'B (ä¸­ç­‰)'
            elif time_minutes <= 30:
                return 'C (è¾ƒæ…¢)'
            else:
                return 'D (å¾ˆæ…¢)'
        
        enhanced_df['æ•ˆç‡ç­‰çº§'] = enhanced_df['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)'].apply(get_efficiency_grade)
        
        # æ·»åŠ ç»¼åˆè¯„åˆ† (åŸºäºå¤šä¸ªæŒ‡æ ‡çš„åŠ æƒå¹³å‡)
        def calculate_composite_score(row):
            # å½’ä¸€åŒ–å„é¡¹æŒ‡æ ‡ (è¶Šå°è¶Šå¥½çš„æŒ‡æ ‡éœ€è¦å–å€’æ•°)
            rel_l2_norm = 1 / (1 + row['Rel-L2'])  # è¶Šå°è¶Šå¥½
            mae_norm = 1 / (1 + row['MAE'])        # è¶Šå°è¶Šå¥½
            psnr_norm = row['PSNR'] / 50           # è¶Šå¤§è¶Šå¥½
            ssim_norm = row['SSIM']                # è¶Šå¤§è¶Šå¥½
            time_norm = 1 / (1 + row['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)'] / 10)  # è¶Šå°è¶Šå¥½
            
            # åŠ æƒå¹³å‡ (å¯ä»¥è°ƒæ•´æƒé‡)
            weights = [0.3, 0.2, 0.2, 0.2, 0.1]  # rel_l2, mae, psnr, ssim, time
            score = (rel_l2_norm * weights[0] + 
                    mae_norm * weights[1] + 
                    psnr_norm * weights[2] + 
                    ssim_norm * weights[3] + 
                    time_norm * weights[4])
            return score * 100  # è½¬æ¢ä¸º0-100åˆ†
        
        enhanced_df['ç»¼åˆè¯„åˆ†'] = enhanced_df.apply(calculate_composite_score, axis=1)
        
        # é‡æ–°æ’åºåˆ—
        column_order = [
            'æ¨¡å‹', 'æ¨¡å‹ç±»åˆ«', 'æ€§èƒ½ç­‰çº§', 'æ•ˆç‡ç­‰çº§', 'ç»¼åˆè¯„åˆ†',
            'Rel-L2', 'MAE', 'PSNR', 'SSIM', 'æœ€ä½³éªŒè¯æŸå¤±',
            'è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)', 'å‚æ•°é‡(M)', 'BRMSE', 'CRMSE'
        ]
        
        enhanced_df = enhanced_df[column_order]
        
        # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
        enhanced_df = enhanced_df.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).reset_index(drop=True)
        enhanced_df.index = enhanced_df.index + 1  # ä»1å¼€å§‹æ’å
        
        return enhanced_df
    
    def create_excel_report(self, enhanced_df: pd.DataFrame) -> Path:
        """åˆ›å»ºExcelæ ¼å¼çš„è¯¦ç»†æŠ¥å‘Š"""
        excel_file = self.output_dir / "comprehensive_model_comparison.xlsx"
        
        with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
            # ä¸»è¦å¯¹æ¯”è¡¨
            enhanced_df.to_excel(writer, sheet_name='æ¨¡å‹å¯¹æ¯”', index_label='æ’å')
            
            # æ€§èƒ½åˆ†æè¡¨
            performance_df = enhanced_df[['æ¨¡å‹', 'Rel-L2', 'MAE', 'PSNR', 'SSIM', 'ç»¼åˆè¯„åˆ†']].copy()
            performance_df.to_excel(writer, sheet_name='æ€§èƒ½åˆ†æ', index=False)
            
            # æ•ˆç‡åˆ†æè¡¨
            efficiency_df = enhanced_df[['æ¨¡å‹', 'è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)', 'å‚æ•°é‡(M)', 'æ•ˆç‡ç­‰çº§']].copy()
            efficiency_df.to_excel(writer, sheet_name='æ•ˆç‡åˆ†æ', index=False)
            
            # ç»Ÿè®¡æ±‡æ€»
            stats_data = {
                'æŒ‡æ ‡': ['å¹³å‡å€¼', 'æ ‡å‡†å·®', 'æœ€å°å€¼', 'æœ€å¤§å€¼', 'ä¸­ä½æ•°'],
                'Rel-L2': [
                    enhanced_df['Rel-L2'].mean(),
                    enhanced_df['Rel-L2'].std(),
                    enhanced_df['Rel-L2'].min(),
                    enhanced_df['Rel-L2'].max(),
                    enhanced_df['Rel-L2'].median()
                ],
                'PSNR': [
                    enhanced_df['PSNR'].mean(),
                    enhanced_df['PSNR'].std(),
                    enhanced_df['PSNR'].min(),
                    enhanced_df['PSNR'].max(),
                    enhanced_df['PSNR'].median()
                ],
                'SSIM': [
                    enhanced_df['SSIM'].mean(),
                    enhanced_df['SSIM'].std(),
                    enhanced_df['SSIM'].min(),
                    enhanced_df['SSIM'].max(),
                    enhanced_df['SSIM'].median()
                ],
                'è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)': [
                    enhanced_df['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)'].mean(),
                    enhanced_df['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)'].std(),
                    enhanced_df['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)'].min(),
                    enhanced_df['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)'].max(),
                    enhanced_df['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)'].median()
                ]
            }
            stats_df = pd.DataFrame(stats_data)
            stats_df.to_excel(writer, sheet_name='ç»Ÿè®¡æ±‡æ€»', index=False)
        
        # ç¾åŒ–Excelæ ¼å¼
        self._format_excel(excel_file)
        
        logger.info(f"ExcelæŠ¥å‘Šå·²ä¿å­˜: {excel_file}")
        return excel_file
    
    def _format_excel(self, excel_file: Path):
        """ç¾åŒ–Excelæ ¼å¼"""
        wb = openpyxl.load_workbook(excel_file)
        
        # å®šä¹‰æ ·å¼
        header_font = Font(bold=True, color="FFFFFF")
        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        center_alignment = Alignment(horizontal="center", vertical="center")
        border = Border(
            left=Side(style='thin'),
            right=Side(style='thin'),
            top=Side(style='thin'),
            bottom=Side(style='thin')
        )
        
        # æ ¼å¼åŒ–æ¯ä¸ªå·¥ä½œè¡¨
        for sheet_name in wb.sheetnames:
            ws = wb[sheet_name]
            
            # è®¾ç½®æ ‡é¢˜è¡Œæ ·å¼
            for cell in ws[1]:
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = center_alignment
                cell.border = border
            
            # è®¾ç½®æ•°æ®è¡Œæ ·å¼
            for row in ws.iter_rows(min_row=2):
                for cell in row:
                    cell.alignment = center_alignment
                    cell.border = border
            
            # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 20)
                ws.column_dimensions[column_letter].width = adjusted_width
        
        wb.save(excel_file)
    
    def create_markdown_table(self, enhanced_df: pd.DataFrame) -> Path:
        """åˆ›å»ºMarkdownæ ¼å¼çš„å¯¹æ¯”è¡¨"""
        md_file = self.output_dir / "model_comparison_table.md"
        
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write("# ğŸš€ Sparse2Full æ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # ä¸»è¦å¯¹æ¯”è¡¨
            f.write("## ğŸ“Š ç»¼åˆæ€§èƒ½å¯¹æ¯”\n\n")
            
            # åˆ›å»ºç®€åŒ–çš„è¡¨æ ¼ç”¨äºMarkdownæ˜¾ç¤º
            display_df = enhanced_df[['æ¨¡å‹', 'æ¨¡å‹ç±»åˆ«', 'æ€§èƒ½ç­‰çº§', 'æ•ˆç‡ç­‰çº§', 
                                    'Rel-L2', 'PSNR', 'SSIM', 'è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)', 'ç»¼åˆè¯„åˆ†']].copy()
            
            # æ ¼å¼åŒ–æ•°å€¼
            display_df['Rel-L2'] = display_df['Rel-L2'].apply(lambda x: f"{x:.4f}")
            display_df['PSNR'] = display_df['PSNR'].apply(lambda x: f"{x:.2f}")
            display_df['SSIM'] = display_df['SSIM'].apply(lambda x: f"{x:.4f}")
            display_df['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)'] = display_df['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)'].apply(lambda x: f"{x:.2f}")
            display_df['ç»¼åˆè¯„åˆ†'] = display_df['ç»¼åˆè¯„åˆ†'].apply(lambda x: f"{x:.1f}")
            
            f.write(display_df.to_markdown(index=True))
            f.write("\n\n")
            
            # æ€§èƒ½åˆ†æ
            f.write("## ğŸ† æ€§èƒ½åˆ†æ\n\n")
            f.write("### æœ€ä½³æ¨¡å‹ (Top 3)\n\n")
            top3 = enhanced_df.head(3)
            for i, (_, row) in enumerate(top3.iterrows(), 1):
                medal = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"][i-1]
                f.write(f"{medal} **{row['æ¨¡å‹']}** ({row['æ¨¡å‹ç±»åˆ«']})\n")
                f.write(f"   - Rel-L2: {row['Rel-L2']:.4f}\n")
                f.write(f"   - PSNR: {row['PSNR']:.2f} dB\n")
                f.write(f"   - SSIM: {row['SSIM']:.4f}\n")
                f.write(f"   - è®­ç»ƒæ—¶é—´: {row['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)']:.2f} åˆ†é’Ÿ\n")
                f.write(f"   - ç»¼åˆè¯„åˆ†: {row['ç»¼åˆè¯„åˆ†']:.1f}/100\n\n")
            
            # æ•ˆç‡åˆ†æ
            f.write("## âš¡ æ•ˆç‡åˆ†æ\n\n")
            fastest_models = enhanced_df.nsmallest(3, 'è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)')
            f.write("### è®­ç»ƒé€Ÿåº¦æœ€å¿« (Top 3)\n\n")
            for _, row in fastest_models.iterrows():
                f.write(f"- **{row['æ¨¡å‹']}**: {row['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)']:.2f} åˆ†é’Ÿ ({row['æ•ˆç‡ç­‰çº§']})\n")
            f.write("\n")
            
            # ç»Ÿè®¡ä¿¡æ¯
            f.write("## ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯\n\n")
            f.write(f"- **æ€»æ¨¡å‹æ•°**: {len(enhanced_df)}\n")
            f.write(f"- **å¹³å‡Rel-L2**: {enhanced_df['Rel-L2'].mean():.4f} Â± {enhanced_df['Rel-L2'].std():.4f}\n")
            f.write(f"- **å¹³å‡PSNR**: {enhanced_df['PSNR'].mean():.2f} Â± {enhanced_df['PSNR'].std():.2f} dB\n")
            f.write(f"- **å¹³å‡SSIM**: {enhanced_df['SSIM'].mean():.4f} Â± {enhanced_df['SSIM'].std():.4f}\n")
            f.write(f"- **å¹³å‡è®­ç»ƒæ—¶é—´**: {enhanced_df['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)'].mean():.2f} Â± {enhanced_df['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)'].std():.2f} åˆ†é’Ÿ\n\n")
            
            # ä½¿ç”¨å»ºè®®
            f.write("## ğŸ’¡ ä½¿ç”¨å»ºè®®\n\n")
            best_model = enhanced_df.iloc[0]
            fastest_model = enhanced_df.loc[enhanced_df['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)'].idxmin()]
            
            f.write(f"### ğŸ¯ æœ€ä½³æ€§èƒ½æ¨è\n")
            f.write(f"**{best_model['æ¨¡å‹']}** - ç»¼åˆè¯„åˆ†æœ€é«˜ ({best_model['ç»¼åˆè¯„åˆ†']:.1f}/100)\n")
            f.write(f"- é€‚ç”¨åœºæ™¯: å¯¹ç²¾åº¦è¦æ±‚æé«˜çš„åº”ç”¨\n")
            f.write(f"- ä¼˜åŠ¿: {best_model['æ€§èƒ½ç­‰çº§']}\n\n")
            
            f.write(f"### âš¡ æœ€ä½³æ•ˆç‡æ¨è\n")
            f.write(f"**{fastest_model['æ¨¡å‹']}** - è®­ç»ƒæ—¶é—´æœ€çŸ­ ({fastest_model['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)']:.2f} åˆ†é’Ÿ)\n")
            f.write(f"- é€‚ç”¨åœºæ™¯: å¿«é€ŸåŸå‹å¼€å‘å’Œå®æ—¶åº”ç”¨\n")
            f.write(f"- ä¼˜åŠ¿: {fastest_model['æ•ˆç‡ç­‰çº§']}\n\n")
        
        logger.info(f"Markdownè¡¨æ ¼å·²ä¿å­˜: {md_file}")
        return md_file
    
    def create_interactive_charts(self, enhanced_df: pd.DataFrame) -> List[Path]:
        """åˆ›å»ºäº¤äº’å¼å›¾è¡¨"""
        chart_files = []
        
        # 1. æ€§èƒ½å¯¹æ¯”é›·è¾¾å›¾
        radar_file = self.output_dir / "performance_radar_chart.html"
        self._create_radar_chart(enhanced_df, radar_file)
        chart_files.append(radar_file)
        
        # 2. æ•£ç‚¹å›¾çŸ©é˜µ
        scatter_file = self.output_dir / "performance_scatter_matrix.html"
        self._create_scatter_matrix(enhanced_df, scatter_file)
        chart_files.append(scatter_file)
        
        # 3. ç»¼åˆè¯„åˆ†æ¡å½¢å›¾
        bar_file = self.output_dir / "composite_score_chart.html"
        self._create_composite_score_chart(enhanced_df, bar_file)
        chart_files.append(bar_file)
        
        return chart_files
    
    def _create_radar_chart(self, df: pd.DataFrame, output_file: Path):
        """åˆ›å»ºé›·è¾¾å›¾"""
        # é€‰æ‹©å‰5ä¸ªæ¨¡å‹
        top5_df = df.head(5)
        
        # å½’ä¸€åŒ–æŒ‡æ ‡ (0-1èŒƒå›´)
        metrics = ['Rel-L2', 'MAE', 'PSNR', 'SSIM', 'è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)']
        normalized_data = {}
        
        for metric in metrics:
            if metric in ['Rel-L2', 'MAE', 'è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)']:
                # è¶Šå°è¶Šå¥½çš„æŒ‡æ ‡ï¼Œå–å€’æ•°åå½’ä¸€åŒ–
                values = 1 / (1 + top5_df[metric])
            else:
                # è¶Šå¤§è¶Šå¥½çš„æŒ‡æ ‡ï¼Œç›´æ¥å½’ä¸€åŒ–
                values = top5_df[metric] / top5_df[metric].max()
            normalized_data[metric] = values
        
        fig = go.Figure()
        
        for i, (_, row) in enumerate(top5_df.iterrows()):
            values = [normalized_data[metric].iloc[i] for metric in metrics]
            values.append(values[0])  # é—­åˆé›·è¾¾å›¾
            
            fig.add_trace(go.Scatterpolar(
                r=values,
                theta=metrics + [metrics[0]],
                fill='toself',
                name=row['æ¨¡å‹'],
                line_color=px.colors.qualitative.Set1[i]
            ))
        
        fig.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[0, 1]
                )),
            showlegend=True,
            title="æ¨¡å‹æ€§èƒ½é›·è¾¾å›¾ (Top 5)",
            font=dict(size=14)
        )
        
        pyo.plot(fig, filename=str(output_file), auto_open=False)
    
    def _create_scatter_matrix(self, df: pd.DataFrame, output_file: Path):
        """åˆ›å»ºæ•£ç‚¹å›¾çŸ©é˜µ"""
        metrics = ['Rel-L2', 'PSNR', 'SSIM', 'è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)']
        
        fig = make_subplots(
            rows=len(metrics), cols=len(metrics),
            subplot_titles=[f"{m1} vs {m2}" for m1 in metrics for m2 in metrics]
        )
        
        for i, metric1 in enumerate(metrics):
            for j, metric2 in enumerate(metrics):
                if i == j:
                    # å¯¹è§’çº¿æ˜¾ç¤ºç›´æ–¹å›¾
                    fig.add_trace(
                        go.Histogram(x=df[metric1], name=metric1, showlegend=False),
                        row=i+1, col=j+1
                    )
                else:
                    # éå¯¹è§’çº¿æ˜¾ç¤ºæ•£ç‚¹å›¾
                    fig.add_trace(
                        go.Scatter(
                            x=df[metric2], y=df[metric1],
                            mode='markers+text',
                            text=df['æ¨¡å‹'],
                            textposition="top center",
                            name=f"{metric1} vs {metric2}",
                            showlegend=False
                        ),
                        row=i+1, col=j+1
                    )
        
        fig.update_layout(
            height=800, width=800,
            title_text="æ¨¡å‹æ€§èƒ½æŒ‡æ ‡æ•£ç‚¹å›¾çŸ©é˜µ"
        )
        
        pyo.plot(fig, filename=str(output_file), auto_open=False)
    
    def _create_composite_score_chart(self, df: pd.DataFrame, output_file: Path):
        """åˆ›å»ºç»¼åˆè¯„åˆ†å›¾è¡¨"""
        fig = go.Figure()
        
        # æ·»åŠ æ¡å½¢å›¾
        fig.add_trace(go.Bar(
            x=df['æ¨¡å‹'],
            y=df['ç»¼åˆè¯„åˆ†'],
            text=[f"{score:.1f}" for score in df['ç»¼åˆè¯„åˆ†']],
            textposition='auto',
            marker_color=px.colors.qualitative.Set3,
            name='ç»¼åˆè¯„åˆ†'
        ))
        
        fig.update_layout(
            title="æ¨¡å‹ç»¼åˆè¯„åˆ†å¯¹æ¯”",
            xaxis_title="æ¨¡å‹",
            yaxis_title="ç»¼åˆè¯„åˆ† (0-100)",
            showlegend=False,
            height=500
        )
        
        pyo.plot(fig, filename=str(output_file), auto_open=False)
    
    def generate_comprehensive_report(self) -> Dict[str, Path]:
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        logger.info("å¼€å§‹ç”Ÿæˆç»¼åˆæ¨¡å‹å¯¹æ¯”æŠ¥å‘Š...")
        
        # 1. å¢å¼ºæ•°æ®
        enhanced_df = self.enhance_model_data()
        
        # 2. ä¿å­˜å¢å¼ºåçš„CSV
        enhanced_csv = self.output_dir / "enhanced_model_comparison.csv"
        enhanced_df.to_csv(enhanced_csv, index_label='æ’å', encoding='utf-8-sig')
        
        # 3. åˆ›å»ºExcelæŠ¥å‘Š
        excel_file = self.create_excel_report(enhanced_df)
        
        # 4. åˆ›å»ºMarkdownè¡¨æ ¼
        markdown_file = self.create_markdown_table(enhanced_df)
        
        # 5. åˆ›å»ºäº¤äº’å¼å›¾è¡¨
        chart_files = self.create_interactive_charts(enhanced_df)
        
        # 6. ç”Ÿæˆæ±‡æ€»ä¿¡æ¯
        summary = {
            'total_models': len(enhanced_df),
            'best_model': enhanced_df.iloc[0]['æ¨¡å‹'],
            'fastest_model': enhanced_df.loc[enhanced_df['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)'].idxmin(), 'æ¨¡å‹'],
            'avg_rel_l2': enhanced_df['Rel-L2'].mean(),
            'avg_psnr': enhanced_df['PSNR'].mean(),
            'avg_ssim': enhanced_df['SSIM'].mean(),
            'avg_training_time': enhanced_df['è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)'].mean()
        }
        
        summary_file = self.output_dir / "comparison_summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        results = {
            'enhanced_csv': enhanced_csv,
            'excel_report': excel_file,
            'markdown_table': markdown_file,
            'summary': summary_file
        }
        
        # æ·»åŠ å›¾è¡¨æ–‡ä»¶
        for i, chart_file in enumerate(chart_files):
            results[f'chart_{i+1}'] = chart_file
        
        logger.info(f"ç»¼åˆæŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œè¾“å‡ºç›®å½•: {self.output_dir}")
        return results


def main():
    """ä¸»å‡½æ•°"""
    batch_results_dir = "f:/Zhaoyang/Sparse2Full/runs/batch_retrain_20251015_032934"
    
    try:
        # åˆ›å»ºå¯¹æ¯”åˆ†æå™¨
        comparator = ComprehensiveModelComparison(batch_results_dir)
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        results = comparator.generate_comprehensive_report()
        
        print("\nğŸ‰ ç»¼åˆæ¨¡å‹å¯¹æ¯”æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {comparator.output_dir}")
        print("\nç”Ÿæˆçš„æ–‡ä»¶:")
        for name, path in results.items():
            print(f"  - {name}: {path.name}")
        
        return results
        
    except Exception as e:
        logger.error(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {e}")
        raise


if __name__ == "__main__":
    main()