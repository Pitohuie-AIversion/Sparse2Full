#!/usr/bin/env python3
"""
å››è”å›¾å¯è§†åŒ–ç”Ÿæˆè„šæœ¬ (é‡æ„ç‰ˆæœ¬)
ä½¿ç”¨ utils/visualization.py ä¸­çš„ç»Ÿä¸€æ¥å£

ç”ŸæˆåŒ…å«è§‚æµ‹ã€çœŸå€¼ã€é¢„æµ‹å’Œè¯¯å·®çš„å››è”å›¾å¯è§†åŒ–
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import h5py
from pathlib import Path
import yaml
from omegaconf import OmegaConf
import random
from typing import List, Tuple, Dict, Any

# å¯¼å…¥é¡¹ç›®æ¨¡å—
import sys
sys.path.append('.')
from models import SwinUNet
from datasets.pdebench import PDEBenchSR
from ops.degradation import SuperResolutionOperator
from utils.config import load_config
from utils.metrics import compute_metrics
from utils.visualization import PDEBenchVisualizer

def load_trained_model(checkpoint_path: str, config: Dict[str, Any], device: str = 'cuda:0') -> nn.Module:
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print(f"ğŸ”„ åŠ è½½æ¨¡å‹ä»: {checkpoint_path}")
    
    # åˆ›å»ºæ¨¡å‹
    model_config = config['model']
    if model_config['name'] == 'SwinUNet':
        model = SwinUNet(**model_config['params'])
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_config['name']}")
    
    # åŠ è½½æƒé‡
    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    
    model = model.to(device)
    model.eval()
    
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œå‚æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")
    return model

def load_validation_dataset(config: Dict[str, Any]) -> torch.utils.data.Dataset:
    """åŠ è½½éªŒè¯æ•°æ®é›†"""
    print("ğŸ”„ åŠ è½½éªŒè¯æ•°æ®é›†...")
    
    # è·å–è§‚æµ‹é…ç½®
    obs_config = config['data']['observation']
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = PDEBenchSR(
        data_path=config['data']['data_path'],
        keys=config['data']['keys'],
        split='val',
        splits_dir=None,  # ä¸ä½¿ç”¨splitsæ–‡ä»¶
        image_size=config['data']['image_size'],
        normalize=False,  # æš‚æ—¶ä¸ä½¿ç”¨å½’ä¸€åŒ–é¿å…è·¯å¾„é—®é¢˜
        scale=obs_config['sr']['scale_factor'],
        sigma=obs_config['sr']['blur_sigma'],
        blur_kernel=obs_config['sr']['blur_kernel_size'],
        boundary=obs_config['sr']['boundary_mode']
    )
    
    print(f"âœ… éªŒè¯æ•°æ®é›†åŠ è½½æˆåŠŸï¼Œæ ·æœ¬æ•°: {len(dataset)}")
    return dataset

def select_representative_samples(dataset: torch.utils.data.Dataset, 
                                model: nn.Module, 
                                degradation_op: Any,
                                device: str,
                                num_samples: int = 5) -> List[int]:
    """é€‰æ‹©ä»£è¡¨æ€§æ ·æœ¬ï¼ˆåŒ…æ‹¬å¥½çš„å’Œå·®çš„é¢„æµ‹ç»“æœï¼‰"""
    print(f"ğŸ”„ ä»{len(dataset)}ä¸ªæ ·æœ¬ä¸­é€‰æ‹©{num_samples}ä¸ªä»£è¡¨æ€§æ ·æœ¬...")
    
    # éšæœºé€‰æ‹©ä¸€äº›æ ·æœ¬è¿›è¡Œè¯„ä¼°
    sample_indices = random.sample(range(len(dataset)), min(50, len(dataset)))
    sample_errors = []
    
    model.eval()
    with torch.no_grad():
        for idx in sample_indices:
            data_dict = dataset[idx]
            gt = data_dict['target'].unsqueeze(0).to(device)  # [1, C, H, W]
            
            # ç”Ÿæˆè§‚æµ‹
            observed = degradation_op(gt)
            
            # å°†è§‚æµ‹æ•°æ®ä¸Šé‡‡æ ·åˆ°æ¨¡å‹æœŸæœ›çš„å°ºå¯¸
            if observed.shape[-2:] != (128, 128):
                observed = F.interpolate(observed, size=(128, 128), mode='bilinear', align_corners=False)
            
            # é¢„æµ‹
            pred = model(observed)
            
            # è®¡ç®—è¯¯å·®
            error = torch.mean((pred - gt) ** 2).item()
            sample_errors.append((idx, error))
    
    # æŒ‰è¯¯å·®æ’åº
    sample_errors.sort(key=lambda x: x[1])
    
    # é€‰æ‹©ä»£è¡¨æ€§æ ·æœ¬ï¼šæœ€å¥½çš„2ä¸ªï¼Œæœ€å·®çš„2ä¸ªï¼Œä¸­ç­‰çš„1ä¸ª
    selected_indices = []
    
    # æœ€å¥½çš„2ä¸ª
    selected_indices.extend([sample_errors[i][0] for i in range(min(2, len(sample_errors)))])
    
    # æœ€å·®çš„2ä¸ª
    selected_indices.extend([sample_errors[i][0] for i in range(max(0, len(sample_errors)-2), len(sample_errors))])
    
    # ä¸­ç­‰çš„1ä¸ª
    if len(sample_errors) > 4:
        mid_idx = len(sample_errors) // 2
        selected_indices.append(sample_errors[mid_idx][0])
    
    # ç¡®ä¿ä¸é‡å¤ä¸”æ•°é‡æ­£ç¡®
    selected_indices = list(set(selected_indices))[:num_samples]
    
    print(f"âœ… é€‰æ‹©äº†{len(selected_indices)}ä¸ªä»£è¡¨æ€§æ ·æœ¬")
    return selected_indices

def generate_predictions(model: nn.Module, 
                        dataset: torch.utils.data.Dataset,
                        sample_indices: List[int],
                        degradation_op: Any,
                        device: str) -> List[Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]]:
    """ç”Ÿæˆé¢„æµ‹ç»“æœï¼Œè¿”å›è§‚æµ‹ã€çœŸå®ã€é¢„æµ‹ã€è¯¯å·®æ•°æ®"""
    print("ğŸ”„ ç”Ÿæˆé¢„æµ‹ç»“æœ...")
    
    results = []
    model.eval()
    
    with torch.no_grad():
        for idx in sample_indices:
            # è·å–çœŸå®æ•°æ®
            data_dict = dataset[idx]
            gt = data_dict['target'].unsqueeze(0).to(device)  # [1, C, H, W]
            
            # ç”Ÿæˆè§‚æµ‹
            observed = degradation_op(gt)
            observed_original = observed.clone()  # ä¿å­˜åŸå§‹è§‚æµ‹æ•°æ®
            
            # å°†è§‚æµ‹æ•°æ®ä¸Šé‡‡æ ·åˆ°æ¨¡å‹æœŸæœ›çš„å°ºå¯¸
            if observed.shape[-2:] != (128, 128):
                observed = F.interpolate(observed, size=(128, 128), mode='bilinear', align_corners=False)
            
            # é¢„æµ‹
            pred = model(observed)
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„ (å–ç¬¬ä¸€ä¸ªé€šé“)
            observed_np = observed_original[0, 0].cpu().numpy()  # åŸå§‹32x32è§‚æµ‹æ•°æ®
            gt_np = gt[0, 0].cpu().numpy()
            pred_np = pred[0, 0].cpu().numpy()
            error_np = np.abs(gt_np - pred_np)
            
            results.append((observed_np, gt_np, pred_np, error_np))
            
            # è®¡ç®—æŒ‡æ ‡
            metrics = compute_metrics(pred, gt)
            rel_l2 = metrics['rel_l2'].item()
            psnr = metrics['psnr'].item()
            ssim = metrics['ssim'].item()
            
            print(f"  æ ·æœ¬ {idx}: Rel-L2={rel_l2:.4f}, PSNR={psnr:.2f}dB, SSIM={ssim:.4f}")
    
    print("âœ… é¢„æµ‹ç»“æœç”Ÿæˆå®Œæˆ")
    return results

def create_individual_quadruplet_visualization(observed_data: np.ndarray,
                                              gt_data: np.ndarray,
                                              pred_data: np.ndarray, 
                                              error_data: np.ndarray,
                                              sample_idx: int,
                                              output_dir: Path,
                                              metrics: Dict[str, float] = None) -> None:
    """åˆ›å»ºå•ä¸ªæ ·æœ¬çš„å››è”å›¾å¯è§†åŒ– - ä½¿ç”¨utilsæ¥å£"""
    
    # ä½¿ç”¨utilsä¸­çš„ç»Ÿä¸€æ¥å£
    save_path = create_quadruplet_visualization(
        observed_data=observed_data,
        gt_data=gt_data,
        pred_data=pred_data,
        error_data=error_data,
        sample_idx=sample_idx,
        metrics=metrics,
        save_dir=str(output_dir),
        output_format='svg'
    )
    
    print(f"âœ… å››è”å›¾å·²ä¿å­˜: {save_path}")

def create_combined_quadruplet_visualization_wrapper(results: List[Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]],
                                                   sample_indices: List[int],
                                                   output_dir: Path,
                                                   all_metrics: List[Dict[str, float]] = None) -> None:
    """åˆ›å»ºç»„åˆçš„å››è”å›¾å¯è§†åŒ– - ä½¿ç”¨utilsæ¥å£"""
    
    # ä½¿ç”¨utilsä¸­çš„ç»Ÿä¸€æ¥å£
    save_path = create_combined_quadruplet_visualization(
        results=results,
        sample_indices=sample_indices,
        all_metrics=all_metrics,
        save_dir=str(output_dir),
        output_format='svg'
    )
    
    print(f"âœ… ç»„åˆå››è”å›¾å·²ä¿å­˜: {save_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç”Ÿæˆå››è”å›¾å¯è§†åŒ–...")
    
    # è®¾ç½®è·¯å¾„
    config_path = Path('configs/train.yaml')
    checkpoint_path = Path('runs/checkpoints/best.pth')
    output_dir = Path('runs/visualization')
    output_dir.mkdir(exist_ok=True)
    
    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
    if not checkpoint_path.exists():
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
        return
    
    if not config_path.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return
    
    # åŠ è½½é…ç½®
    print("ğŸ”„ åŠ è½½é…ç½®æ–‡ä»¶...")
    config = load_config(str(config_path))
    device = config['experiment']['device']
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(config['experiment']['seed'])
    np.random.seed(config['experiment']['seed'])
    random.seed(config['experiment']['seed'])
    
    # åŠ è½½æ¨¡å‹
    model = load_trained_model(str(checkpoint_path), config, device)
    
    # åŠ è½½éªŒè¯æ•°æ®é›†
    dataset = load_validation_dataset(config)
    
    # åˆ›å»ºé€€åŒ–ç®—å­
    print("ğŸ”„ åˆ›å»ºè§‚æµ‹ç®—å­...")
    obs_config = config['data']['observation']['sr']
    degradation_op = SuperResolutionOperator(
        scale=obs_config['scale_factor'],
        sigma=obs_config['blur_sigma'],
        kernel_size=obs_config['blur_kernel_size'],
        boundary=obs_config['boundary_mode']
    )
    
    # é€‰æ‹©ä»£è¡¨æ€§æ ·æœ¬
    sample_indices = select_representative_samples(dataset, model, degradation_op, device, num_samples=5)
    
    # ç”Ÿæˆé¢„æµ‹ç»“æœ
    results = generate_predictions(model, dataset, sample_indices, degradation_op, device)
    
    # è®¡ç®—è¯¦ç»†æŒ‡æ ‡
    print("ğŸ”„ è®¡ç®—è¯¦ç»†æŒ‡æ ‡...")
    all_metrics = []
    model.eval()
    with torch.no_grad():
        for idx in sample_indices:
            data_dict = dataset[idx]
            gt = data_dict['target'].unsqueeze(0).to(device)
            observed = degradation_op(gt)
            # å°†è§‚æµ‹æ•°æ®ä¸Šé‡‡æ ·åˆ°æ¨¡å‹æœŸæœ›çš„å°ºå¯¸
            if observed.shape[-2:] != (128, 128):
                observed = F.interpolate(observed, size=(128, 128), mode='bilinear', align_corners=False)
            pred = model(observed)
            metrics = compute_metrics(pred, gt)
            all_metrics.append({
                'rel_l2': metrics['rel_l2'].item(),
                'psnr': metrics['psnr'].item(),
                'ssim': metrics['ssim'].item()
            })
    
    # ç”Ÿæˆå•ç‹¬çš„å››è”å›¾
    print("ğŸ”„ ç”Ÿæˆå•ç‹¬çš„å››è”å›¾...")
    for i, (result, sample_idx) in enumerate(zip(results, sample_indices)):
        observed_data, gt_data, pred_data, error_data = result
        metrics = all_metrics[i] if i < len(all_metrics) else None
        create_individual_quadruplet_visualization(observed_data, gt_data, pred_data, error_data, sample_idx, output_dir, metrics)
    
    # ç”Ÿæˆç»„åˆå››è”å›¾
    print("ğŸ”„ ç”Ÿæˆç»„åˆå››è”å›¾...")
    create_combined_quadruplet_visualization_wrapper(results, sample_indices, output_dir, all_metrics)
    
    print(f"\nğŸ‰ å››è”å›¾å¯è§†åŒ–å®Œæˆï¼")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")
    print(f"ğŸ“Š ç”Ÿæˆäº† {len(sample_indices)} ä¸ªå•ç‹¬å››è”å›¾ + 1 ä¸ªç»„åˆå›¾")
    
    # æ‰“å°æ ·æœ¬ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“‹ æ ·æœ¬ç»Ÿè®¡ä¿¡æ¯:")
    for i, (sample_idx, metrics) in enumerate(zip(sample_indices, all_metrics)):
        print(f"  æ ·æœ¬ {sample_idx}: Rel-L2={metrics['rel_l2']:.4f}, PSNR={metrics['psnr']:.2f}dB, SSIM={metrics['ssim']:.4f}")

if __name__ == "__main__":
    main()