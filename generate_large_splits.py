#!/usr/bin/env python3
"""
ç”Ÿæˆå¤§è§„æ¨¡æ•°æ®åˆ†å‰²æ–‡ä»¶
å°†Darcy Flowæ•°æ®é›†çš„10000ä¸ªæ ·æœ¬åˆ†å‰²ä¸ºï¼š
- è®­ç»ƒé›†ï¼š1000ä¸ªæ ·æœ¬
- éªŒè¯é›†ï¼š100ä¸ªæ ·æœ¬  
- æµ‹è¯•é›†ï¼š100ä¸ªæ ·æœ¬
"""

import os
import random
import numpy as np
from pathlib import Path

def generate_splits(total_samples=10000, train_size=1000, val_size=100, test_size=100, seed=2025):
    """
    ç”Ÿæˆæ•°æ®åˆ†å‰²
    
    Args:
        total_samples: æ€»æ ·æœ¬æ•°
        train_size: è®­ç»ƒé›†å¤§å°
        val_size: éªŒè¯é›†å¤§å°
        test_size: æµ‹è¯•é›†å¤§å°
        seed: éšæœºç§å­
    """
    # è®¾ç½®éšæœºç§å­
    random.seed(seed)
    np.random.seed(seed)
    
    # ç”Ÿæˆæ‰€æœ‰æ ·æœ¬ç´¢å¼•
    all_indices = list(range(total_samples))
    random.shuffle(all_indices)
    
    # åˆ†å‰²æ•°æ®
    train_indices = all_indices[:train_size]
    val_indices = all_indices[train_size:train_size + val_size]
    test_indices = all_indices[train_size + val_size:train_size + val_size + test_size]
    
    print(f"è®­ç»ƒé›†: {len(train_indices)} ä¸ªæ ·æœ¬")
    print(f"éªŒè¯é›†: {len(val_indices)} ä¸ªæ ·æœ¬")
    print(f"æµ‹è¯•é›†: {len(test_indices)} ä¸ªæ ·æœ¬")
    print(f"æ€»è®¡ä½¿ç”¨: {len(train_indices) + len(val_indices) + len(test_indices)} / {total_samples} ä¸ªæ ·æœ¬")
    
    return train_indices, val_indices, test_indices

def write_split_files(train_indices, val_indices, test_indices, output_dir="data/pdebench/splits"):
    """
    å†™å…¥åˆ†å‰²æ–‡ä»¶
    
    Args:
        train_indices: è®­ç»ƒé›†ç´¢å¼•
        val_indices: éªŒè¯é›†ç´¢å¼•
        test_indices: æµ‹è¯•é›†ç´¢å¼•
        output_dir: è¾“å‡ºç›®å½•
    """
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # å†™å…¥è®­ç»ƒé›†
    train_file = os.path.join(output_dir, "train.txt")
    with open(train_file, 'w') as f:
        for idx in train_indices:
            f.write(f"{idx}\n")
    print(f"âœ… è®­ç»ƒé›†æ–‡ä»¶å·²ä¿å­˜: {train_file}")
    
    # å†™å…¥éªŒè¯é›†
    val_file = os.path.join(output_dir, "val.txt")
    with open(val_file, 'w') as f:
        for idx in val_indices:
            f.write(f"{idx}\n")
    print(f"âœ… éªŒè¯é›†æ–‡ä»¶å·²ä¿å­˜: {val_file}")
    
    # å†™å…¥æµ‹è¯•é›†
    test_file = os.path.join(output_dir, "test.txt")
    with open(test_file, 'w') as f:
        for idx in test_indices:
            f.write(f"{idx}\n")
    print(f"âœ… æµ‹è¯•é›†æ–‡ä»¶å·²ä¿å­˜: {test_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç”Ÿæˆå¤§è§„æ¨¡æ•°æ®åˆ†å‰²...")
    
    # ç”Ÿæˆåˆ†å‰²
    train_indices, val_indices, test_indices = generate_splits(
        total_samples=10000,
        train_size=1000,
        val_size=100,
        test_size=100,
        seed=2025
    )
    
    # å†™å…¥æ–‡ä»¶
    write_split_files(train_indices, val_indices, test_indices)
    
    print("ğŸ‰ æ•°æ®åˆ†å‰²ç”Ÿæˆå®Œæˆï¼")
    
    # éªŒè¯æ–‡ä»¶
    splits_dir = "data/pdebench/splits"
    for split_name in ["train", "val", "test"]:
        split_file = os.path.join(splits_dir, f"{split_name}.txt")
        if os.path.exists(split_file):
            with open(split_file, 'r') as f:
                lines = f.readlines()
            print(f"ğŸ“Š {split_name}.txt: {len(lines)} è¡Œ")
        else:
            print(f"âŒ {split_file} ä¸å­˜åœ¨")

if __name__ == "__main__":
    main()