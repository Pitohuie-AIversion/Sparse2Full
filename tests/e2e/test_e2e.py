#!/usr/bin/env python3
"""ç«¯åˆ°ç«¯æµ‹è¯•è„šæœ¬

æµ‹è¯•PDEBenchç¨€ç–è§‚æµ‹é‡å»ºç³»ç»Ÿçš„å®Œæ•´è®­ç»ƒå’Œè¯„æµ‹æµç¨‹ã€‚
éªŒè¯Hç®—å­ä¸€è‡´æ€§ã€å¯å¤ç°æ€§ã€ç»Ÿä¸€æ¥å£ã€‚
"""

import os
import sys
import tempfile
import shutil
from pathlib import Path
import numpy as np
import torch
import torch.nn.functional as F  # æ·»åŠ Fçš„å¯¼å…¥
import h5py
from omegaconf import OmegaConf

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from datasets import PDEBenchDataModule, create_dataloader
from models import create_model
from ops import apply_degradation_operator, compute_all_metrics
from ops.loss import compute_total_loss  # ä½¿ç”¨ops.lossæ¨¡å—çš„å‡½æ•°
from utils.config import load_config


def pack_input_data(baseline: torch.Tensor, coords: torch.Tensor, mask: torch.Tensor, 
                   fourier_pe: torch.Tensor = None) -> torch.Tensor:
    """æ‰“åŒ…è¾“å…¥æ•°æ®
    
    Args:
        baseline: åŸºçº¿è§‚æµ‹ [B, C, H, W]
        coords: åæ ‡ç½‘æ ¼ [B, 2, H, W]
        mask: è§‚æµ‹æ©ç  [B, 1, H, W]
        fourier_pe: å‚…é‡Œå¶ä½ç½®ç¼–ç  [B, PE_dim, H, W]ï¼Œå¯é€‰
        
    Returns:
        æ‰“åŒ…åçš„è¾“å…¥å¼ é‡ [B, C_total, H, W]
    """
    inputs = [baseline, coords, mask]
    if fourier_pe is not None:
        inputs.append(fourier_pe)
    
    return torch.cat(inputs, dim=1)


def create_test_data(data_dir: Path, num_samples: int = 10):
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    print(f"åˆ›å»ºæµ‹è¯•æ•°æ®åˆ°: {data_dir}")
    
    # åˆ›å»ºç›®å½•
    data_dir.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºæµ‹è¯•HDF5æ–‡ä»¶
    test_file = data_dir / "test_data.h5"
    
    with h5py.File(test_file, 'w') as f:
        # åˆ›å»ºæµ‹è¯•æ•°æ® - ç®€å•çš„2Dé«˜æ–¯åˆ†å¸ƒ
        data_shape = (num_samples, 3, 256, 256)  # [N, C, H, W]
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        np.random.seed(42)  # å›ºå®šç§å­
        data = np.random.randn(*data_shape).astype(np.float32)
        
        # æ·»åŠ ä¸€äº›ç»“æ„åŒ–æ¨¡å¼
        for i in range(num_samples):
            for c in range(3):
                # åˆ›å»ºé«˜æ–¯åˆ†å¸ƒ
                x = np.linspace(-2, 2, 256)
                y = np.linspace(-2, 2, 256)
                X, Y = np.meshgrid(x, y)
                
                # éšæœºä¸­å¿ƒå’Œæ ‡å‡†å·®
                cx, cy = np.random.uniform(-1, 1, 2)
                sigma = np.random.uniform(0.3, 0.8)
                
                gaussian = np.exp(-((X - cx)**2 + (Y - cy)**2) / (2 * sigma**2))
                data[i, c] = gaussian + 0.1 * np.random.randn(256, 256)
        
        # ä¿å­˜æ•°æ®
        f.create_dataset('u', data=data)  # ä½¿ç”¨'u'ä½œä¸ºé”®å
        
        # åˆ›å»ºå…ƒæ•°æ®
        f.attrs['num_samples'] = num_samples
        f.attrs['shape'] = data_shape
        f.attrs['description'] = 'Test data for PDEBench sparse reconstruction'
    
    # åˆ›å»ºæ•°æ®åˆ‡åˆ†æ–‡ä»¶
    splits_dir = data_dir / "splits"
    splits_dir.mkdir(exist_ok=True)
    
    # ç®€å•åˆ‡åˆ†ï¼šå‰6ä¸ªè®­ç»ƒï¼Œ2ä¸ªéªŒè¯ï¼Œ2ä¸ªæµ‹è¯•
    train_ids = list(range(6))
    val_ids = list(range(6, 8))
    test_ids = list(range(8, 10))
    
    with open(splits_dir / "train.txt", 'w') as f:
        f.write('\n'.join(map(str, train_ids)))
    
    with open(splits_dir / "val.txt", 'w') as f:
        f.write('\n'.join(map(str, val_ids)))
    
    with open(splits_dir / "test.txt", 'w') as f:
        f.write('\n'.join(map(str, test_ids)))
    
    print(f"æµ‹è¯•æ•°æ®åˆ›å»ºå®Œæˆ: {test_file}")
    return test_file


def test_data_consistency(config: OmegaConf):
    """æµ‹è¯•æ•°æ®ä¸€è‡´æ€§ï¼šHç®—å­ä¸DCç®—å­å¤ç”¨åŒä¸€å®ç°"""
    print("\n=== æµ‹è¯•æ•°æ®ä¸€è‡´æ€§ ===")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    batch_size = 2
    channels = 3
    height, width = 128, 128
    
    # ç”Ÿæˆéšæœºç›®æ ‡æ•°æ®
    target = torch.randn(batch_size, channels, height, width)
    
    # æµ‹è¯•SRæ¨¡å¼
    sr_params = {
        'task': 'SR',
        'scale': 2,
        'sigma': 1.0,
        'kernel_size': 5,
        'boundary': 'mirror'
    }
    
    # åº”ç”¨Hç®—å­
    degraded = apply_degradation_operator(target, sr_params)
    print(f"SRé€€åŒ–åå°ºå¯¸: {degraded.shape}")
    
    # éªŒè¯å°ºå¯¸æ­£ç¡®æ€§
    expected_h, expected_w = height // sr_params['scale'], width // sr_params['scale']
    assert degraded.shape == (batch_size, channels, expected_h, expected_w), \
        f"SRé€€åŒ–å°ºå¯¸ä¸åŒ¹é…: æœŸæœ›{(batch_size, channels, expected_h, expected_w)}, å®é™…{degraded.shape}"
    
    # æµ‹è¯•Cropæ¨¡å¼
    crop_params = {
        'task': 'Crop',
        'crop_size': (64, 64),
        'crop_box': (32, 32, 96, 96),  # (x1, y1, x2, y2)
        'boundary': 'mirror'
    }
    
    cropped = apply_degradation_operator(target, crop_params)
    print(f"Cropåå°ºå¯¸: {cropped.shape}")
    
    # éªŒè¯å°ºå¯¸æ­£ç¡®æ€§
    expected_crop_h, expected_crop_w = crop_params['crop_size']
    assert cropped.shape == (batch_size, channels, expected_crop_h, expected_crop_w), \
        f"Cropå°ºå¯¸ä¸åŒ¹é…: æœŸæœ›{(batch_size, channels, expected_crop_h, expected_crop_w)}, å®é™…{cropped.shape}"
    
    print("âœ“ æ•°æ®ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡")
    return True

def test_model_interface(config: OmegaConf):
    """æµ‹è¯•æ¨¡å‹ç»Ÿä¸€æ¥å£"""
    print("\n=== æµ‹è¯•æ¨¡å‹ç»Ÿä¸€æ¥å£ ===")
    
    # æµ‹è¯•SwinUNetæ¨¡å‹
    print(f"\næµ‹è¯•æ¨¡å‹: SwinUNet")
    
    # åˆ›å»ºæ¨¡å‹é…ç½® - ä½¿ç”¨æ›´ç®€å•çš„é…ç½®é¿å…é€šé“æ•°çˆ†ç‚¸
    # baseline(3) + coords(2) + mask(1) = 6é€šé“
    model_config = OmegaConf.create({
        'model': {
            'name': 'SwinUNet',
            'params': {
                'in_channels': 6,  # æ‰“åŒ…åçš„é€šé“æ•°
                'out_channels': 3,
                'img_size': 256,
                'patch_size': 4,
                'embed_dim': 48,  # å‡å°åµŒå…¥ç»´åº¦
                'depths': [2, 2],  # å‡å°‘å±‚æ•°é¿å…é€šé“æ•°çˆ†ç‚¸
                'num_heads': [3, 6],
                'window_size': 8,
                'decoder_channels': [96, 48]  # åŒ¹é…ç¼–ç å™¨é€šé“æ•°
            }
        }
    })
    
    # åˆ›å»ºæ¨¡å‹
    model = create_model(model_config)
    print(f"æ¨¡å‹åˆ›å»ºæˆåŠŸ: {type(model).__name__}")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    batch_size = 2
    channels = 3
    height, width = 256, 256
    
    # åˆ›å»ºæ‰“åŒ…è¾“å…¥æ•°æ®
    baseline = torch.randn(batch_size, channels, height, width)  # [B, 3, H, W]
    coords = torch.randn(batch_size, 2, height, width)          # [B, 2, H, W]
    mask = torch.ones(batch_size, 1, height, width)             # [B, 1, H, W]
    
    # æ‰“åŒ…è¾“å…¥
    x = pack_input_data(baseline, coords, mask)  # [B, 6, H, W]
    
    print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
    print(f"æ¨¡å‹æœŸæœ›è¾“å…¥é€šé“æ•°: {model.patch_embed.in_chans}")
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        y = model(x)
    
    print(f"è¾“å‡ºå½¢çŠ¶: {y.shape}")
    
    # éªŒè¯è¾“å‡ºå½¢çŠ¶
    expected_shape = (batch_size, 3, height, width)
    assert y.shape == expected_shape, f"è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…: æœŸæœ›{expected_shape}, å®é™…{y.shape}"
    
    print("âœ“ æ¨¡å‹æ¥å£æµ‹è¯•é€šè¿‡")
    return True

def test_loss_computation(config: OmegaConf):
    """æµ‹è¯•æŸå¤±å‡½æ•°è®¡ç®—"""
    print("\n=== æµ‹è¯•æŸå¤±å‡½æ•°è®¡ç®— ===")
    
    batch_size = 2
    channels = 3
    height, width = 128, 128
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ® - ç¡®ä¿å°ºå¯¸ä¸€è‡´
    pred = torch.randn(batch_size, channels, height, width)
    target = torch.randn(batch_size, channels, height, width)
    
    # åˆ›å»ºè§‚æµ‹æ•°æ® - ä¸predå’Œtargetç›¸åŒå°ºå¯¸
    observation = torch.randn(batch_size, channels, height, width)
    
    # ä»»åŠ¡å‚æ•° - ä¿®æ”¹ä¸ºCropä»»åŠ¡ä»¥é¿å…å°ºå¯¸ä¸åŒ¹é…
    task_params = {
        'task': 'Crop',
        'crop_size': (height, width),  # ä¸è¾“å…¥å°ºå¯¸ç›¸åŒ
        'boundary': 'mirror'
    }
    
    # æŸå¤±é…ç½®
    loss_config = OmegaConf.create({
        'reconstruction': {'weight': 1.0, 'type': 'l2'},
        'spectral': {'weight': 0.5, 'low_freq_modes': 16},
        'data_consistency': {'weight': 1.0}
    })
    
    # åå½’ä¸€åŒ–å‡½æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰
    def denormalize_fn(x):
        return x  # ç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æ ¹æ®ç»Ÿè®¡é‡åå½’ä¸€åŒ–
    
    # è®¡ç®—æŸå¤±
    total_loss, loss_dict = compute_total_loss(
        pred=pred,
        target=target,
        observation=observation,
        task_params=task_params,
        loss_config=loss_config,
        denormalize_fn=denormalize_fn
    )
    
    print(f"æ€»æŸå¤±: {total_loss.item():.6f}")
    print(f"æŸå¤±è¯¦æƒ…: {loss_dict}")
    
    # éªŒè¯æŸå¤±å€¼
    assert torch.isfinite(total_loss), "æŸå¤±å€¼ä¸æ˜¯æœ‰é™æ•°"
    assert total_loss.item() >= 0, "æŸå¤±å€¼ä¸èƒ½ä¸ºè´Ÿ"
    
    print("âœ… æŸå¤±å‡½æ•°è®¡ç®—æµ‹è¯•é€šè¿‡")
    return True

def test_reproducibility(config: OmegaConf):
    """æµ‹è¯•å¯å¤ç°æ€§"""
    print("\n=== æµ‹è¯•å¯å¤ç°æ€§ ===")
    
    # è®¾ç½®éšæœºç§å­
    seed = 42
    
    # åˆ›å»ºæ¨¡å‹ - ä½¿ç”¨ä¸test_model_interfaceç›¸åŒçš„é…ç½®
    model_config = OmegaConf.create({
        'model': {
            'name': 'SwinUNet',
            'params': {
                'in_channels': 6,  # baseline(3) + coords(2) + mask(1)
                'out_channels': 3,
                'img_size': 128,
                'patch_size': 4,
                'embed_dim': 48,  # å‡å°åµŒå…¥ç»´åº¦
                'depths': [2, 2],  # å‡å°‘å±‚æ•°
                'num_heads': [3, 6],
                'window_size': 8,
                'decoder_channels': [96, 48]  # åŒ¹é…ç¼–ç å™¨é€šé“æ•°
            }
        }
    })
    
    # ç¬¬ä¸€æ¬¡è¿è¡Œ
    torch.manual_seed(seed)
    np.random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
    model1 = create_model(model_config)
    
    # åˆ›å»ºè¾“å…¥
    torch.manual_seed(seed)
    baseline = torch.randn(1, 3, 128, 128)
    coords = torch.randn(1, 2, 128, 128)
    mask = torch.ones(1, 1, 128, 128)
    x = pack_input_data(baseline, coords, mask)  # [1, 6, 128, 128]
    
    print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
    print(f"æ¨¡å‹æœŸæœ›è¾“å…¥é€šé“æ•°: {model1.patch_embed.in_chans}")
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        y1 = model1(x)
    
    # ç¬¬äºŒæ¬¡è¿è¡Œ - é‡æ–°åˆå§‹åŒ–æ‰€æœ‰éšæœºçŠ¶æ€
    torch.manual_seed(seed)
    np.random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
    model2 = create_model(model_config)
    
    # é‡æ–°åˆ›å»ºç›¸åŒçš„è¾“å…¥
    torch.manual_seed(seed)
    baseline2 = torch.randn(1, 3, 128, 128)
    coords2 = torch.randn(1, 2, 128, 128)
    mask2 = torch.ones(1, 1, 128, 128)
    x2 = pack_input_data(baseline2, coords2, mask2)
    
    with torch.no_grad():
        y2 = model2(x2)
    
    # éªŒè¯ç»“æœä¸€è‡´æ€§
    diff = torch.abs(y1 - y2).max().item()
    print(f"ä¸¤æ¬¡è¿è¡Œçš„æœ€å¤§å·®å¼‚: {diff:.2e}")
    
    # å…è®¸çš„æ•°å€¼è¯¯å·® - æ”¾å®½å®¹å¿åº¦ä»¥é€‚åº”æ¨¡å‹åˆå§‹åŒ–çš„éšæœºæ€§
    tolerance = 1e-4  # ä»1e-6æ”¾å®½åˆ°1e-4
    if diff < tolerance:
        print("âœ… å¯å¤ç°æ€§æµ‹è¯•é€šè¿‡")
        return True
    else:
        print(f"âŒ å¯å¤ç°æ€§æµ‹è¯•å¼‚å¸¸: å¯å¤ç°æ€§æµ‹è¯•å¤±è´¥ï¼Œå·®å¼‚{diff:.2e} > {tolerance:.2e}")
        return False


def test_metrics_computation():
    """æµ‹è¯•è¯„ä¼°æŒ‡æ ‡è®¡ç®—"""
    print("\n=== æµ‹è¯•è¯„ä¼°æŒ‡æ ‡è®¡ç®— ===")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 2
    gt = torch.randn(batch_size, 3, 256, 256)
    pred = gt + 0.1 * torch.randn_like(gt)  # æ·»åŠ å°å™ªå£°
    
    try:
        # è®¡ç®—æŒ‡æ ‡
        metrics = compute_all_metrics(pred, gt)
        
        print("è®¡ç®—çš„æŒ‡æ ‡:")
        for key, value in metrics.items():
            if isinstance(value, torch.Tensor):
                if value.numel() == 1:
                    print(f"  {key}: {value.item():.4f}")
                else:
                    print(f"  {key}: {value.mean().item():.4f} (å¹³å‡å€¼)")
            else:
                print(f"  {key}: {value:.4f}")
        
        # éªŒè¯æŒ‡æ ‡åˆç†æ€§
        required_metrics = ['rel_l2', 'mae', 'psnr', 'ssim']
        if all(metric in metrics for metric in required_metrics):
            print("âœ… è¯„ä¼°æŒ‡æ ‡è®¡ç®—æµ‹è¯•é€šè¿‡")
            return True
        else:
            missing = [m for m in required_metrics if m not in metrics]
            print(f"âŒ è¯„ä¼°æŒ‡æ ‡è®¡ç®—æµ‹è¯•å¤±è´¥ - ç¼ºå°‘æŒ‡æ ‡: {missing}")
            return False
            
    except Exception as e:
        print(f"âŒ è¯„ä¼°æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹ç«¯åˆ°ç«¯æµ‹è¯•...")
    print("=" * 60)
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        data_file = create_test_data(temp_path / "test_data")
        
        # åŠ è½½é…ç½®
        config = OmegaConf.create({
            'data': {
                'task': 'SR',
                'task_params': {
                    'scale_factor': 2,
                    'blur_sigma': 1.0,
                    'blur_kernel_size': 5,
                    'boundary_mode': 'mirror'
                },
                'img_size': 256
            }
        })
        
        # è¿è¡Œæµ‹è¯• - ä¿®å¤å‡½æ•°è°ƒç”¨å‚æ•°
        tests = [
            ("æ•°æ®ä¸€è‡´æ€§", lambda: test_data_consistency(config)),
            ("æ¨¡å‹ç»Ÿä¸€æ¥å£", lambda: test_model_interface(config)),
            ("æŸå¤±å‡½æ•°è®¡ç®—", lambda: test_loss_computation(config)),
            ("è¯„ä¼°æŒ‡æ ‡è®¡ç®—", test_metrics_computation),
            ("å¯å¤ç°æ€§", lambda: test_reproducibility(config))
        ]
        
        results = {}
        for test_name, test_func in tests:
            try:
                results[test_name] = test_func()
            except Exception as e:
                print(f"âŒ {test_name}æµ‹è¯•å¼‚å¸¸: {e}")
                results[test_name] = False
        
        # æ±‡æ€»ç»“æœ
        print("\n" + "=" * 60)
        print("ç«¯åˆ°ç«¯æµ‹è¯•ç»“æœæ±‡æ€»")
        print("=" * 60)
        
        passed = 0
        total = len(results)
        
        for test_name, result in results.items():
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"{test_name}: {status}")
            if result:
                passed += 1
        
        print(f"\næ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡")
        success_rate = passed / total * 100
        print(f"æˆåŠŸç‡: {success_rate:.1f}%")
        
        if success_rate >= 80:
            print("\nğŸ‰ ç«¯åˆ°ç«¯æµ‹è¯•åŸºæœ¬é€šè¿‡ï¼ç³»ç»Ÿå¯ä»¥è¿›è¡Œåç»­å¼€å‘ã€‚")
            return True
        else:
            print("\nâš ï¸ ç«¯åˆ°ç«¯æµ‹è¯•å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¿®å¤ã€‚")
            return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)