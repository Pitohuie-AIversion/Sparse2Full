#!/usr/bin/env python3
"""
ç®€åŒ–çš„ç«¯åˆ°ç«¯æµ‹è¯•è„šæœ¬
æµ‹è¯•æ ¸å¿ƒåŠŸèƒ½çš„åŸºæœ¬å·¥ä½œæµç¨‹
"""

import os
import sys
import tempfile
import shutil
import torch
import torch.nn as nn
import numpy as np
from pathlib import Path
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)


def test_basic_imports():
    """æµ‹è¯•åŸºæœ¬æ¨¡å—å¯¼å…¥"""
    logger.info("Testing basic imports...")
    
    try:
        from models.swin_unet import SwinUNet
        from losses.combined_loss import CombinedLoss
        from utils.metrics import compute_metrics
        from ops.degradation import GaussianBlurDownsample, CenterCrop
        logger.info("âœ“ Basic imports successful")
        return True
    except Exception as e:
        logger.error(f"âœ— Import failed: {e}")
        return False


def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    logger.info("Testing model creation...")
    
    try:
        from models.swin_unet import SwinUNet
        
        model = SwinUNet(
            in_channels=2,
            out_channels=2,
            img_size=[64, 64],
            patch_size=4,
            window_size=8,
            depths=[2, 2],
            num_heads=[2, 4],
            embed_dim=48
        )
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        x = torch.randn(1, 2, 64, 64)
        with torch.no_grad():
            y = model(x)
        
        assert y.shape == (1, 2, 64, 64)
        logger.info("âœ“ Model creation and forward pass successful")
        return True
        
    except Exception as e:
        logger.error(f"âœ— Model creation failed: {e}")
        return False


def test_loss_computation():
    """æµ‹è¯•æŸå¤±å‡½æ•°"""
    logger.info("Testing loss computation...")
    
    try:
        from losses.combined_loss import CombinedLoss
        
        loss_fn = CombinedLoss(
            rec_weight=1.0,
            spec_weight=0.5,
            dc_weight=1.0
        )
        
        pred = torch.randn(1, 2, 64, 64)
        target = torch.randn(1, 2, 64, 64)
        
        loss = loss_fn(pred, target)
        
        assert isinstance(loss, torch.Tensor)
        assert loss.dim() == 0
        assert loss.item() >= 0
        
        logger.info("âœ“ Loss computation successful")
        return True
        
    except Exception as e:
        logger.error(f"âœ— Loss computation failed: {e}")
        return False


def test_metrics_computation():
    """æµ‹è¯•æŒ‡æ ‡è®¡ç®—"""
    logger.info("Testing metrics computation...")
    
    try:
        from utils.metrics import compute_metrics
        
        pred = torch.randn(1, 2, 64, 64)
        target = torch.randn(1, 2, 64, 64)
        
        metrics = compute_metrics(pred, target)
        
        assert isinstance(metrics, dict)
        assert 'rel_l2' in metrics
        assert 'mae' in metrics
        
        logger.info("âœ“ Metrics computation successful")
        return True
        
    except Exception as e:
        logger.error(f"âœ— Metrics computation failed: {e}")
        return False


def test_degradation_operators():
    """æµ‹è¯•é™è´¨ç®—å­"""
    logger.info("Testing degradation operators...")
    
    try:
        from ops.degradation import GaussianBlurDownsample, CenterCrop
        
        # æµ‹è¯•è¶…åˆ†è¾¨ç‡é™è´¨
        sr_op = GaussianBlurDownsample(scale_factor=2, sigma=1.0, kernel_size=5)
        x = torch.randn(1, 2, 64, 64)
        y_sr = sr_op(x)
        
        assert y_sr.shape == (1, 2, 32, 32)
        
        # æµ‹è¯•è£å‰ªé™è´¨
        crop_op = CenterCrop(crop_size=(32, 32), img_size=(64, 64))
        y_crop = crop_op(x)
        
        assert y_crop.shape == (1, 2, 32, 32)
        
        logger.info("âœ“ Degradation operators successful")
        return True
        
    except Exception as e:
        logger.error(f"âœ— Degradation operators failed: {e}")
        return False


def test_training_step():
    """æµ‹è¯•è®­ç»ƒæ­¥éª¤"""
    logger.info("Testing training step...")
    
    try:
        from models.swin_unet import SwinUNet
        from losses.combined_loss import CombinedLoss
        
        # åˆ›å»ºæ¨¡å‹å’ŒæŸå¤±å‡½æ•°
        model = SwinUNet(
            in_channels=2,
            out_channels=2,
            img_size=[64, 64],
            patch_size=4,
            window_size=8,
            depths=[2, 2],
            num_heads=[2, 4],
            embed_dim=48
        )
        
        loss_fn = CombinedLoss()
        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)
        
        # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
        model.train()
        optimizer.zero_grad()
        
        x = torch.randn(2, 2, 64, 64)
        target = torch.randn(2, 2, 64, 64)
        
        pred = model(x)
        loss = loss_fn(pred, target)
        loss.backward()
        
        # æ£€æŸ¥æ¢¯åº¦
        has_grad = any(p.grad is not None and p.grad.abs().sum() > 0 
                      for p in model.parameters())
        assert has_grad, "No gradients found"
        
        optimizer.step()
        
        logger.info("âœ“ Training step successful")
        return True
        
    except Exception as e:
        logger.error(f"âœ— Training step failed: {e}")
        return False


def test_visualization():
    """æµ‹è¯•å¯è§†åŒ–åŠŸèƒ½"""
    logger.info("Testing visualization...")
    
    try:
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = Path(tempfile.mkdtemp())
        
        try:
            from utils.visualization import PDEBenchVisualizer
            
            visualizer = PDEBenchVisualizer(save_dir=str(temp_dir))
            
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            import numpy as np
            gt = np.random.rand(64, 64)
            pred = np.random.rand(64, 64)
            
            # æµ‹è¯•åŸºæœ¬å¯è§†åŒ–
            visualizer.plot_field_comparison(gt, pred, save_name="test")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ç”Ÿæˆ
            save_path = temp_dir / "test.png"
            assert save_path.exists()
            
            logger.info("âœ“ Visualization successful")
            return True
            
        except Exception as e:
            logger.warning(f"Visualization test failed: {e}")
            return False
            
        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            if temp_dir.exists():
                shutil.rmtree(temp_dir)
        
    except Exception as e:
        logger.error(f"âœ— Visualization failed: {e}")
        return False


def test_checkpoint_operations():
    """æµ‹è¯•æ£€æŸ¥ç‚¹æ“ä½œ"""
    logger.info("Testing checkpoint operations...")
    
    try:
        from models.swin_unet import SwinUNet
        
        model = SwinUNet(
            in_channels=2,
            out_channels=2,
            img_size=[64, 64],
            patch_size=4,
            window_size=8,
            depths=[2, 2],
            num_heads=[2, 4],
            embed_dim=48
        )
        
        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        temp_dir = Path(tempfile.mkdtemp())
        checkpoint_path = temp_dir / "test_checkpoint.pth"
        
        try:
            # ä¿å­˜æ£€æŸ¥ç‚¹
            checkpoint = {
                'epoch': 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': 0.5
            }
            
            torch.save(checkpoint, checkpoint_path)
            assert checkpoint_path.exists()
            
            # åŠ è½½æ£€æŸ¥ç‚¹
            loaded = torch.load(checkpoint_path, map_location='cpu')
            
            assert 'epoch' in loaded
            assert 'model_state_dict' in loaded
            assert 'optimizer_state_dict' in loaded
            
            # åŠ è½½çŠ¶æ€
            model.load_state_dict(loaded['model_state_dict'])
            optimizer.load_state_dict(loaded['optimizer_state_dict'])
            
            logger.info("âœ“ Checkpoint operations successful")
            return True
            
        finally:
            # æ¸…ç†
            if temp_dir.exists():
                shutil.rmtree(temp_dir)
        
    except Exception as e:
        logger.error(f"âœ— Checkpoint operations failed: {e}")
        return False


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("=" * 60)
    logger.info("Running Simple E2E Tests")
    logger.info("=" * 60)
    
    tests = [
        ("Basic Imports", test_basic_imports),
        ("Model Creation", test_model_creation),
        ("Loss Computation", test_loss_computation),
        ("Metrics Computation", test_metrics_computation),
        ("Degradation Operators", test_degradation_operators),
        ("Training Step", test_training_step),
        ("Visualization", test_visualization),
        ("Checkpoint Operations", test_checkpoint_operations),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        logger.info(f"\n[{passed + 1}/{total}] {test_name}")
        logger.info("-" * 40)
        
        try:
            if test_func():
                passed += 1
            else:
                logger.error(f"Test '{test_name}' failed")
        except Exception as e:
            logger.error(f"Test '{test_name}' crashed: {e}")
    
    logger.info("\n" + "=" * 60)
    logger.info(f"Test Results: {passed}/{total} tests passed")
    
    if passed == total:
        logger.info("ğŸ‰ All tests passed!")
    else:
        logger.warning(f"âš ï¸  {total - passed} tests failed")
    
    logger.info("=" * 60)
    
    return passed == total


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)