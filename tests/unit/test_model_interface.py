"""æµ‹è¯•æ¨¡å‹ç»Ÿä¸€æ¥å£

éªŒè¯æ‰€æœ‰æ¨¡å‹æ˜¯å¦éµå¾ªç»Ÿä¸€æ¥å£ï¼šforward(x[B,C,H,W]) â†’ y[B,C,H,W]
"""

import torch
import sys
import traceback
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

def test_model_interface():
    """æµ‹è¯•æ¨¡å‹ç»Ÿä¸€æ¥å£"""
    print("=" * 60)
    print("PDEBench æ¨¡å‹ç»Ÿä¸€æ¥å£éªŒè¯")
    print("=" * 60)
    
    # æµ‹è¯•å‚æ•°
    batch_size = 2
    in_channels = 3
    out_channels = 3
    img_size = 256
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    x = torch.randn(batch_size, in_channels, img_size, img_size)
    print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
    print()
    
    # æµ‹è¯•æ¨¡å‹åˆ—è¡¨
    models_to_test = [
        {
            'name': 'SwinUNet',
            'module': 'models.swin_unet',
            'class': 'SwinUNet',
            'params': {
                'in_channels': in_channels,
                'out_channels': out_channels,
                'img_size': img_size,
                'embed_dim': 96,
                'depths': [2, 2, 2, 2],  # ç®€åŒ–æ·±åº¦
                'num_heads': [3, 6, 12, 24],
                'window_size': 8
            }
        },
        {
            'name': 'HybridModel',
            'module': 'models.hybrid',
            'class': 'HybridModel',
            'params': {
                'in_channels': in_channels,
                'out_channels': out_channels,
                'img_size': img_size,
                'use_attention_branch': True,
                'use_fno_branch': False,  # æš‚æ—¶ç¦ç”¨FNOåˆ†æ”¯
                'use_unet_branch': True
            }
        },
        {
            'name': 'MLPModel',
            'module': 'models.mlp',
            'class': 'MLPModel',
            'params': {
                'in_channels': in_channels,
                'out_channels': out_channels,
                'img_size': img_size,
                'mode': 'patch',
                'patch_size': 16,  # å¢å¤§patch_sizeå‡å°‘è®¡ç®—é‡
                'hidden_dims': [256, 256]  # ç®€åŒ–ç½‘ç»œ
            }
        }
    ]
    
    results = {}
    
    for model_config in models_to_test:
        model_name = model_config['name']
        print(f"æµ‹è¯• {model_name}...")
        
        try:
            # åŠ¨æ€å¯¼å…¥æ¨¡å‹
            module = __import__(model_config['module'], fromlist=[model_config['class']])
            model_class = getattr(module, model_config['class'])
            
            # åˆ›å»ºæ¨¡å‹å®ä¾‹
            model = model_class(**model_config['params'])
            
            # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            model.eval()
            
            # å‰å‘ä¼ æ’­æµ‹è¯•
            with torch.no_grad():
                output = model(x)
            
            # æ£€æŸ¥è¾“å‡ºå½¢çŠ¶
            expected_shape = (batch_size, out_channels, img_size, img_size)
            shape_correct = output.shape == expected_shape
            
            # æ£€æŸ¥è¾“å‡ºæ˜¯å¦ä¸ºæœ‰é™å€¼
            output_finite = torch.isfinite(output).all().item()
            
            # è®¡ç®—å‚æ•°é‡
            param_count = sum(p.numel() for p in model.parameters())
            
            results[model_name] = {
                'success': True,
                'output_shape': output.shape,
                'shape_correct': shape_correct,
                'output_finite': output_finite,
                'param_count': param_count,
                'param_count_M': param_count / 1e6
            }
            
            print(f"  âœ“ å¯¼å…¥æˆåŠŸ")
            print(f"  âœ“ è¾“å‡ºå½¢çŠ¶: {output.shape}")
            print(f"  âœ“ å½¢çŠ¶æ­£ç¡®: {shape_correct}")
            print(f"  âœ“ è¾“å‡ºæœ‰é™: {output_finite}")
            print(f"  âœ“ å‚æ•°é‡: {param_count:,} ({param_count/1e6:.2f}M)")
            
        except Exception as e:
            results[model_name] = {
                'success': False,
                'error': str(e),
                'traceback': traceback.format_exc()
            }
            
            print(f"  âœ— æµ‹è¯•å¤±è´¥: {e}")
            print(f"  è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            print(traceback.format_exc())
        
        print()
    
    # æ±‡æ€»ç»“æœ
    print("=" * 60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    success_count = 0
    total_count = len(models_to_test)
    
    for model_name, result in results.items():
        if result['success']:
            success_count += 1
            print(f"âœ“ {model_name}: é€šè¿‡")
            print(f"  - è¾“å‡ºå½¢çŠ¶: {result['output_shape']}")
            print(f"  - å‚æ•°é‡: {result['param_count_M']:.2f}M")
        else:
            print(f"âœ— {model_name}: å¤±è´¥")
            print(f"  - é”™è¯¯: {result['error']}")
        print()
    
    print(f"æ€»ä½“ç»“æœ: {success_count}/{total_count} æ¨¡å‹é€šè¿‡æµ‹è¯•")
    
    if success_count == total_count:
        print("ğŸ‰ æ‰€æœ‰æ¨¡å‹éƒ½é€šè¿‡äº†ç»Ÿä¸€æ¥å£éªŒè¯ï¼")
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†æ¨¡å‹æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤")
        return False


if __name__ == "__main__":
    success = test_model_interface()
    sys.exit(0 if success else 1)