#!/usr/bin/env python3
"""æµ‹è¯•æ–°çš„å¯¹ç§°Swin-UNetæ¶æ„çš„æ•°å€¼å¥åº·æ€§"""

import torch
import torch.nn as nn
import numpy as np
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.swin_unet import SwinUNet


def test_model_architecture():
    """æµ‹è¯•æ¨¡å‹æ¶æ„çš„åŸºæœ¬åŠŸèƒ½"""
    print("=" * 60)
    print("æµ‹è¯•æ–°çš„å¯¹ç§°Swin-UNetæ¶æ„")
    print("=" * 60)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ¨¡å‹
    model = SwinUNet(
        in_channels=3,
        out_channels=3,
        img_size=256,
        patch_size=4,
        embed_dim=96,
        depths=[2, 2, 6, 2],
        num_heads=[3, 6, 12, 24],
        window_size=8,
        mlp_ratio=4.0,
        drop_rate=0.0,
        attn_drop_rate=0.0,
        drop_path_rate=0.1,
        skip_connections=True,
        use_fno_bottleneck=False,
        final_activation=None
    ).to(device)
    
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    print(f"å¯è®­ç»ƒå‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    batch_size = 2
    input_tensor = torch.randn(batch_size, 3, 256, 256).to(device)
    
    print(f"\nè¾“å…¥å¼ é‡å½¢çŠ¶: {input_tensor.shape}")
    print(f"è¾“å…¥å¼ é‡èŒƒå›´: [{input_tensor.min():.4f}, {input_tensor.max():.4f}]")
    
    # å‰å‘ä¼ æ’­
    try:
        with torch.no_grad():
            output = model(input_tensor)
        
        print(f"è¾“å‡ºå¼ é‡å½¢çŠ¶: {output.shape}")
        print(f"è¾“å‡ºå¼ é‡èŒƒå›´: [{output.min():.4f}, {output.max():.4f}]")
        print(f"è¾“å‡ºå¼ é‡å‡å€¼: {output.mean():.4f}")
        print(f"è¾“å‡ºå¼ é‡æ ‡å‡†å·®: {output.std():.4f}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰NaNæˆ–Inf
        if torch.isnan(output).any():
            print("âŒ è¾“å‡ºåŒ…å«NaNå€¼!")
            return False
        if torch.isinf(output).any():
            print("âŒ è¾“å‡ºåŒ…å«Infå€¼!")
            return False
        
        print("âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼Œæ— NaN/Infå€¼")
        
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True


def test_gradient_flow():
    """æµ‹è¯•æ¢¯åº¦æµåŠ¨"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ¢¯åº¦æµåŠ¨")
    print("=" * 60)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºæ¨¡å‹
    model = SwinUNet(
        in_channels=3,
        out_channels=3,
        img_size=256,
        patch_size=4,
        embed_dim=96,
        depths=[2, 2, 6, 2],
        num_heads=[3, 6, 12, 24],
        window_size=8,
        skip_connections=True,
        use_fno_bottleneck=False
    ).to(device)
    
    # åˆ›å»ºè¾“å…¥å’Œç›®æ ‡
    input_tensor = torch.randn(1, 3, 256, 256).to(device)
    target = torch.randn(1, 3, 256, 256).to(device)
    
    # å‰å‘ä¼ æ’­
    output = model(input_tensor)
    
    # è®¡ç®—æŸå¤±
    loss = nn.MSELoss()(output, target)
    print(f"æŸå¤±å€¼: {loss.item():.6f}")
    
    # åå‘ä¼ æ’­
    try:
        loss.backward()
        
        # æ£€æŸ¥æ¢¯åº¦
        grad_norms = []
        nan_grads = 0
        zero_grads = 0
        
        for name, param in model.named_parameters():
            if param.grad is not None:
                grad_norm = param.grad.norm().item()
                grad_norms.append(grad_norm)
                
                if torch.isnan(param.grad).any():
                    nan_grads += 1
                    print(f"âŒ {name} åŒ…å«NaNæ¢¯åº¦")
                
                if grad_norm == 0:
                    zero_grads += 1
        
        if nan_grads > 0:
            print(f"âŒ å‘ç° {nan_grads} ä¸ªå‚æ•°çš„æ¢¯åº¦ä¸ºNaN")
            return False
        
        print(f"æ¢¯åº¦èŒƒæ•°ç»Ÿè®¡:")
        print(f"  æœ€å°å€¼: {min(grad_norms):.6f}")
        print(f"  æœ€å¤§å€¼: {max(grad_norms):.6f}")
        print(f"  å‡å€¼: {np.mean(grad_norms):.6f}")
        print(f"  æ ‡å‡†å·®: {np.std(grad_norms):.6f}")
        print(f"  é›¶æ¢¯åº¦å‚æ•°æ•°é‡: {zero_grads}")
        
        if max(grad_norms) > 100:
            print("âš ï¸  å‘ç°è¾ƒå¤§çš„æ¢¯åº¦å€¼ï¼Œå¯èƒ½å­˜åœ¨æ¢¯åº¦çˆ†ç‚¸")
        
        print("âœ… æ¢¯åº¦æµåŠ¨æ­£å¸¸")
        
    except Exception as e:
        print(f"âŒ æ¢¯åº¦æµåŠ¨æµ‹è¯• æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True


def test_weight_initialization():
    """æµ‹è¯•æƒé‡åˆå§‹åŒ–"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•æƒé‡åˆå§‹åŒ–")
    print("=" * 60)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºæ¨¡å‹
    model = SwinUNet(
        in_channels=3,
        out_channels=3,
        img_size=256,
        patch_size=4,
        embed_dim=96,
        depths=[2, 2, 6, 2],
        num_heads=[3, 6, 12, 24],
        window_size=8,
        skip_connections=True,
        use_fno_bottleneck=False
    ).to(device)
    
    # æ£€æŸ¥æƒé‡åˆå§‹åŒ–
    linear_weights = []
    conv_weights = []
    
    for name, param in model.named_parameters():
        if 'weight' in name:
            weight_std = param.std().item()
            weight_mean = param.mean().item()
            
            if 'Linear' in str(type(param)) or 'linear' in name.lower():
                linear_weights.append(weight_std)
            elif 'Conv' in str(type(param)) or 'conv' in name.lower():
                conv_weights.append(weight_std)
            
            # æ£€æŸ¥å¼‚å¸¸å€¼
            if weight_std > 1.0:
                print(f"âš ï¸  {name} æƒé‡æ ‡å‡†å·®è¾ƒå¤§: {weight_std:.6f}")
            if abs(weight_mean) > 0.1:
                print(f"âš ï¸  {name} æƒé‡å‡å€¼åç¦»é›¶ç‚¹: {weight_mean:.6f}")
    
    if linear_weights:
        print(f"Linearå±‚æƒé‡æ ‡å‡†å·®: å‡å€¼={np.mean(linear_weights):.6f}, èŒƒå›´=[{min(linear_weights):.6f}, {max(linear_weights):.6f}]")
    
    if conv_weights:
        print(f"Convå±‚æƒé‡æ ‡å‡†å·®: å‡å€¼={np.mean(conv_weights):.6f}, èŒƒå›´=[{min(conv_weights):.6f}, {max(conv_weights):.6f}]")
    
    print("âœ… æƒé‡åˆå§‹åŒ–æ£€æŸ¥å®Œæˆ")
    return True


def test_memory_usage():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•å†…å­˜ä½¿ç”¨")
    print("=" * 60)
    
    if not torch.cuda.is_available():
        print("CUDAä¸å¯ç”¨ï¼Œè·³è¿‡å†…å­˜æµ‹è¯•")
        return True
    
    device = torch.device('cuda')
    
    # æ¸…ç©ºç¼“å­˜
    torch.cuda.empty_cache()
    initial_memory = torch.cuda.memory_allocated()
    
    # åˆ›å»ºæ¨¡å‹
    model = SwinUNet(
        in_channels=3,
        out_channels=3,
        img_size=256,
        patch_size=4,
        embed_dim=96,
        depths=[2, 2, 6, 2],
        num_heads=[3, 6, 12, 24],
        window_size=8,
        skip_connections=True,
        use_fno_bottleneck=False
    ).to(device)
    
    model_memory = torch.cuda.memory_allocated() - initial_memory
    print(f"æ¨¡å‹å†…å­˜ä½¿ç”¨: {model_memory / 1024**2:.2f} MB")
    
    # æµ‹è¯•ä¸åŒæ‰¹æ¬¡å¤§å°
    batch_sizes = [1, 2, 4]
    
    for batch_size in batch_sizes:
        try:
            torch.cuda.empty_cache()
            before_forward = torch.cuda.memory_allocated()
            
            input_tensor = torch.randn(batch_size, 3, 256, 256).to(device)
            
            with torch.no_grad():
                output = model(input_tensor)
            
            after_forward = torch.cuda.memory_allocated()
            forward_memory = after_forward - before_forward
            
            print(f"æ‰¹æ¬¡å¤§å° {batch_size}: å‰å‘ä¼ æ’­å†…å­˜ {forward_memory / 1024**2:.2f} MB")
            
            # æ¸…ç†
            del input_tensor, output
            torch.cuda.empty_cache()
            
        except Exception as e:
            if "out of memory" in str(e):
                print(f"æ‰¹æ¬¡å¤§å° {batch_size}: å†…å­˜ä¸è¶³")
            else:
                print(f"âŒ å†…å­˜ä½¿ç”¨æµ‹è¯• æ‰§è¡Œå¤±è´¥: {e}")
                return False
    
    print("âœ… å†…å­˜ä½¿ç”¨æµ‹è¯•å®Œæˆ")
    return True


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯•æ–°çš„å¯¹ç§°Swin-UNetæ¶æ„...")
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    
    tests = [
        ("æ¶æ„æµ‹è¯•", test_model_architecture),
        ("æ¢¯åº¦æµåŠ¨æµ‹è¯•", test_gradient_flow),
        ("æƒé‡åˆå§‹åŒ–æµ‹è¯•", test_weight_initialization),
        ("å†…å­˜ä½¿ç”¨æµ‹è¯•", test_memory_usage),
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} æ‰§è¡Œå¤±è´¥: {e}")
            results.append((test_name, False))
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    passed = 0
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»è®¡: {passed}/{len(results)} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == len(results):
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ–°æ¶æ„æ•°å€¼å¥åº·æ€§è‰¯å¥½ã€‚")
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•ã€‚")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)