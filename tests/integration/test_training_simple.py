"""ç®€åŒ–çš„è®­ç»ƒæµ‹è¯•è„šæœ¬

ç”¨äºéªŒè¯åŸºæœ¬çš„è®­ç»ƒæµç¨‹æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import torch
import torch.nn as nn
import numpy as np
from pathlib import Path
import sys
sys.path.append('.')

def test_basic_training():
    """æµ‹è¯•åŸºæœ¬è®­ç»ƒæµç¨‹"""
    print("å¼€å§‹åŸºæœ¬è®­ç»ƒæµ‹è¯•...")
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cpu')  # å¼ºåˆ¶ä½¿ç”¨CPUé¿å…è®¾å¤‡é—®é¢˜
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºç®€å•çš„æµ‹è¯•æ•°æ®
    batch_size = 2
    channels = 3
    height, width = 64, 64
    
    # æ¨¡æ‹Ÿè¾“å…¥æ•°æ®
    baseline = torch.randn(batch_size, channels, height, width, device=device)
    target = torch.randn(batch_size, channels, height, width, device=device)
    
    print(f"è¾“å…¥æ•°æ®å½¢çŠ¶: {baseline.shape}")
    print(f"ç›®æ ‡æ•°æ®å½¢çŠ¶: {target.shape}")
    
    # åˆ›å»ºç®€å•æ¨¡å‹
    class SimpleModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.conv1 = nn.Conv2d(channels, 16, 3, padding=1)
            self.conv2 = nn.Conv2d(16, channels, 3, padding=1)
            self.relu = nn.ReLU()
            
        def forward(self, x):
            x = self.relu(self.conv1(x))
            x = self.conv2(x)
            return x
    
    model = SimpleModel().to(device)
    print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters())}")
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    
    # ç®€å•çš„æŸå¤±å‡½æ•°
    criterion = nn.MSELoss()
    
    # è®­ç»ƒå‡ ä¸ªæ­¥éª¤
    model.train()
    for step in range(5):
        optimizer.zero_grad()
        
        # å‰å‘ä¼ æ’­
        pred = model(baseline)
        loss = criterion(pred, target)
        
        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()
        
        print(f"æ­¥éª¤ {step+1}, æŸå¤±: {loss.item():.6f}")
    
    print("âœ“ åŸºæœ¬è®­ç»ƒæµ‹è¯•é€šè¿‡")
    return True

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("\nå¼€å§‹æ•°æ®åŠ è½½æµ‹è¯•...")
    
    try:
        from datasets.pdebench import PDEBenchDataModule
        from omegaconf import OmegaConf
        
        # åˆ›å»ºæœ€å°é…ç½®
        config = OmegaConf.create({
            'data_dir': 'data/pdebench',
            'task': 'sr',
            'scale_factor': 4,
            'image_size': 64,
            'keys': ['u'],
            'dataloader': {
                'batch_size': 2,
                'num_workers': 0,
                'pin_memory': False
            }
        })
        
        # åˆ›å»ºæ•°æ®æ¨¡å—
        data_module = PDEBenchDataModule(config)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®æ–‡ä»¶
        data_dir = Path('data/pdebench')
        if not data_dir.exists():
            print("âš  æ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡æ•°æ®åŠ è½½æµ‹è¯•")
            return True
            
        print("âœ“ æ•°æ®åŠ è½½æ¨¡å—åˆ›å»ºæˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âœ— æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("\nå¼€å§‹æ¨¡å‹åˆ›å»ºæµ‹è¯•...")
    
    try:
        from models.swin_unet import SwinUNet
        
        # åˆ›å»ºæ¨¡å‹é…ç½®
        model_config = {
            'in_channels': 3,
            'out_channels': 3,
            'img_size': 64,
            'patch_size': 4,
            'embed_dim': 48,
            'depths': [1, 1, 1, 1],
            'num_heads': [2, 4, 8, 16],
            'window_size': 8,
            'mlp_ratio': 4.0,
            'drop_rate': 0.0,
            'attn_drop_rate': 0.0,
            'drop_path_rate': 0.1
        }
        
        model = SwinUNet(**model_config)
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        device = torch.device('cpu')
        model = model.to(device)
        
        test_input = torch.randn(1, 3, 64, 64, device=device)
        with torch.no_grad():
            output = model(test_input)
        
        print(f"æ¨¡å‹è¾“å…¥å½¢çŠ¶: {test_input.shape}")
        print(f"æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        
        print("âœ“ æ¨¡å‹åˆ›å»ºæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âœ— æ¨¡å‹åˆ›å»ºæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_loss_function():
    """æµ‹è¯•æŸå¤±å‡½æ•°"""
    print("\nå¼€å§‹æŸå¤±å‡½æ•°æµ‹è¯•...")
    
    try:
        from ops.total_loss import TotalLoss
        from omegaconf import OmegaConf
        
        # åˆ›å»ºæŸå¤±å‡½æ•°é…ç½®
        loss_config = OmegaConf.create({
            'reconstruction_weight': 1.0,
            'spectral_weight': 0.5,
            'data_consistency_weight': 1.0
        })
        
        loss_fn = TotalLoss(loss_config)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        device = torch.device('cpu')
        batch_size = 2
        channels = 3
        height, width = 64, 64
        
        pred = torch.randn(batch_size, channels, height, width, device=device)
        target = torch.randn(batch_size, channels, height, width, device=device)
        
        # åˆ›å»ºè§‚æµ‹æ•°æ®
        obs_data = {
            'baseline': torch.randn(batch_size, channels, height, width, device=device),
            'coords': None,
            'mask': None,
            'observation': torch.randn(batch_size, channels, height//4, width//4, device=device),
            'h_params': {'task': 'sr', 'scale_factor': 4}
        }
        
        # åˆ›å»ºå½’ä¸€åŒ–ç»Ÿè®¡é‡
        norm_stats = {
            'mean': torch.zeros(channels, device=device),
            'std': torch.ones(channels, device=device)
        }
        
        # åˆ›å»ºé…ç½®
        cfg = OmegaConf.create({
            'train': {
                'loss_weights': {
                    'reconstruction': 1.0,
                    'spectral': 0.5,
                    'data_consistency': 1.0
                },
                'spectral_loss': {
                    'low_freq_modes': 16,
                    'use_rfft': True,
                    'normalize': True
                }
            },
            'data': {
                'keys': ['u']  # ç›´æ¥ä½¿ç”¨åˆ—è¡¨ï¼Œä¸æ˜¯æ–¹æ³•
            }
        })
        
        # è®¡ç®—æŸå¤±
        loss_dict = loss_fn(pred, target, obs_data, norm_stats, cfg)
        
        print(f"æŸå¤±ç»„ä»¶: {list(loss_dict.keys())}")
        print(f"æ€»æŸå¤±: {loss_dict['total_loss'].item():.6f}")
        
        print("âœ“ æŸå¤±å‡½æ•°æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âœ— æŸå¤±å‡½æ•°æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 50)
    print("PDEBench ç¨€ç–è§‚æµ‹é‡å»ºç³»ç»Ÿ - åŸºç¡€åŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    tests = [
        ("åŸºæœ¬è®­ç»ƒ", test_basic_training),
        ("æ•°æ®åŠ è½½", test_data_loading),
        ("æ¨¡å‹åˆ›å»º", test_model_creation),
        ("æŸå¤±å‡½æ•°", test_loss_function),
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âœ— {test_name}æµ‹è¯•å¼‚å¸¸: {e}")
            results.append((test_name, False))
    
    print("\n" + "=" * 50)
    print("æµ‹è¯•ç»“æœæ±‡æ€»:")
    print("=" * 50)
    
    passed = 0
    for test_name, result in results:
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»è®¡: {passed}/{len(results)} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == len(results):
        print("ğŸ‰ æ‰€æœ‰åŸºç¡€åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("âš  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")

if __name__ == "__main__":
    main()