"""è®­ç»ƒç»„ä»¶æµ‹è¯•è„šæœ¬

éªŒè¯æ•°æ®åŠ è½½ã€æ¨¡å‹åˆå§‹åŒ–ã€æŸå¤±è®¡ç®—ç­‰æ ¸å¿ƒç»„ä»¶
"""

import os
import sys
import torch
import torch.nn as nn
from pathlib import Path
from omegaconf import OmegaConf

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent))

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("=" * 50)
    print("æµ‹è¯•æ•°æ®åŠ è½½...")
    
    try:
        from datasets import PDEBenchDataModule
        
        # åŠ è½½é…ç½®
        config_path = "configs/data/pdebench.yaml"
        data_config = OmegaConf.load(config_path)
        
        # åˆ›å»ºæ•°æ®æ¨¡å—
        data_module = PDEBenchDataModule(data_config)
        
        # å‡†å¤‡æ•°æ®
        data_module.setup()
        
        # è·å–æ•°æ®åŠ è½½å™¨
        train_loader = data_module.train_dataloader()
        
        # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
        batch = next(iter(train_loader))
        
        print(f"âœ“ æ•°æ®åŠ è½½æˆåŠŸ")
        print(f"  - æ‰¹æ¬¡å¤§å°: {len(batch)}")
        if isinstance(batch, (list, tuple)):
            for i, item in enumerate(batch):
                if torch.is_tensor(item):
                    print(f"  - å¼ é‡ {i}: {item.shape}, dtype: {item.dtype}")
        elif torch.is_tensor(batch):
            print(f"  - å¼ é‡å½¢çŠ¶: {batch.shape}, dtype: {batch.dtype}")
        
        return True, batch
        
    except Exception as e:
        print(f"âœ— æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return False, None

def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("=" * 50)
    print("æµ‹è¯•æ¨¡å‹åˆ›å»º...")
    
    try:
        from models.base import create_model
        from omegaconf import OmegaConf
        
        # åŠ è½½æ¨¡å‹é…ç½®
        model_config = OmegaConf.load("configs/model/swin_unet.yaml")
        
        # ä¿®æ”¹é…ç½®ä»¥åŒ¹é…PDEBenchæ•°æ®
        model_config.params.in_channels = 1  # PDEBenchå•é€šé“
        model_config.params.out_channels = 1
        model_config.params.img_size = 128   # PDEBenchåˆ†è¾¨ç‡
        
        # åˆ›å»ºæ¨¡å‹
        model = create_model(model_config)
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = model.to(device)
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        test_input = torch.randn(2, 1, 128, 128).to(device)
        
        with torch.no_grad():
            output = model(test_input)
        
        print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"  - æ¨¡å‹ç±»å‹: {type(model).__name__}")
        print(f"  - è¾“å…¥å½¢çŠ¶: {test_input.shape}")
        print(f"  - è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"  - å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        print(f"  - è®¾å¤‡: {device}")
        
        return True, model
        
    except Exception as e:
        print(f"âœ— æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, None

def test_loss_computation():
    """æµ‹è¯•æŸå¤±è®¡ç®—"""
    print("=" * 50)
    print("æµ‹è¯•æŸå¤±è®¡ç®—...")
    
    try:
        from ops.losses import compute_total_loss
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        pred = torch.randn(2, 1, 128, 128).to(device)
        target = torch.randn(2, 1, 128, 128).to(device)
        
        # æ¨¡æ‹Ÿè§‚æµ‹æ•°æ®
        observed = torch.randn(2, 1, 32, 32).to(device)  # SR x4ä¸‹é‡‡æ ·
        
        # æ¨¡æ‹Ÿè§‚æµ‹æ•°æ®å­—å…¸
        obs_data = {
            'baseline': observed,
            'mask': torch.ones_like(observed),
            'coords': torch.randn(2, 2, 32, 32).to(device),
            'h_params': {'task': 'SR', 'scale': 4},
            'observation': observed
        }
        
        # æ¨¡æ‹Ÿé…ç½®
        from omegaconf import OmegaConf
        config = OmegaConf.create({
            'train': {
                'loss_weights': {
                    'reconstruction': 1.0,
                    'spectral': 0.5,
                    'data_consistency': 1.0
                }
            }
        })
        
        # è®¡ç®—æŸå¤±
        loss_dict = compute_total_loss(
            pred_z=pred,
            target_z=target,
            obs_data=obs_data,
            norm_stats=None,
            config=config
        )
        
        print(f"âœ“ æŸå¤±è®¡ç®—æˆåŠŸ")
        for loss_name, loss_value in loss_dict.items():
            print(f"  - {loss_name}: {loss_value:.6f}")
        
        return True, loss_dict
        
    except Exception as e:
        print(f"âœ— æŸå¤±è®¡ç®—å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, None

def test_gpu_memory():
    """æµ‹è¯•GPUå†…å­˜ä½¿ç”¨"""
    print("=" * 50)
    print("æµ‹è¯•GPUå†…å­˜...")
    
    if not torch.cuda.is_available():
        print("CPUæ¨¡å¼ï¼Œè·³è¿‡GPUå†…å­˜æµ‹è¯•")
        return True
    
    try:
        device = torch.device("cuda")
        
        # æ¸…ç©ºç¼“å­˜
        torch.cuda.empty_cache()
        
        # è·å–åˆå§‹å†…å­˜
        initial_memory = torch.cuda.memory_allocated(device)
        max_memory = torch.cuda.max_memory_allocated(device)
        
        print(f"âœ“ GPUå†…å­˜çŠ¶æ€")
        print(f"  - è®¾å¤‡: {torch.cuda.get_device_name(device)}")
        print(f"  - æ€»å†…å­˜: {torch.cuda.get_device_properties(device).total_memory / 1024**3:.1f} GB")
        print(f"  - å·²åˆ†é…: {initial_memory / 1024**3:.3f} GB")
        print(f"  - å³°å€¼ä½¿ç”¨: {max_memory / 1024**3:.3f} GB")
        
        return True
        
    except Exception as e:
        print(f"âœ— GPUå†…å­˜æ£€æŸ¥å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("PDEBenchè®­ç»ƒç»„ä»¶æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•ç»“æœ
    results = {}
    
    # 1. æµ‹è¯•æ•°æ®åŠ è½½
    results['data'], batch = test_data_loading()
    
    # 2. æµ‹è¯•æ¨¡å‹åˆ›å»º
    results['model'], model = test_model_creation()
    
    # 3. æµ‹è¯•æŸå¤±è®¡ç®—
    results['loss'], loss_dict = test_loss_computation()
    
    # 4. æµ‹è¯•GPUå†…å­˜
    results['gpu'] = test_gpu_memory()
    
    # æ±‡æ€»ç»“æœ
    print("=" * 50)
    print("æµ‹è¯•ç»“æœæ±‡æ€»:")
    
    all_passed = True
    for test_name, passed in results.items():
        status = "âœ“ é€šè¿‡" if passed else "âœ— å¤±è´¥"
        print(f"  - {test_name}: {status}")
        if not passed:
            all_passed = False
    
    print("=" * 50)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒã€‚")
        return True
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)