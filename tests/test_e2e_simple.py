#!/usr/bin/env python3
"""PDEBenchç¨€ç–è§‚æµ‹é‡å»ºç³»ç»Ÿ - ç®€åŒ–ç«¯åˆ°ç«¯æµ‹è¯•

éªŒè¯ç³»ç»Ÿæ ¸å¿ƒåŠŸèƒ½çš„åŸºç¡€æµ‹è¯•è„šæœ¬ï¼Œç¡®ä¿ä¸»è¦ç»„ä»¶èƒ½å¤Ÿæ­£å¸¸å·¥ä½œã€‚

ä½¿ç”¨æ–¹æ³•:
    python tests/test_e2e_simple.py
    python tests/test_e2e_simple.py --keep-files
"""

import os
import sys
import argparse
import yaml
import numpy as np
import torch
import torch.nn as nn
from pathlib import Path
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

# åŸºç¡€å¯¼å…¥
from datasets.darcy_flow_dataset import DarcyFlowDataset
from models.swin_unet import SwinUNet
from models.hybrid import HybridModel
from models.mlp import MLPModel
from ops.loss import TotalLoss
from utils.metrics import MetricsCalculator as PDEBenchMetrics
from ops.degradation import apply_degradation_operator


class SimpleE2ETest:
    """ç®€åŒ–çš„ç«¯åˆ°ç«¯æµ‹è¯•ç±»"""
    
    def __init__(self, test_dir: str = "test_outputs", keep_files: bool = False):
        self.test_dir = Path(test_dir)
        self.keep_files = keep_files
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # æµ‹è¯•å‚æ•°
        self.img_size = 64  # å°å°ºå¯¸ä»¥åŠ å¿«æµ‹è¯•
        self.batch_size = 2
        self.num_epochs = 2
        
        print(f"æµ‹è¯•è®¾å¤‡: {self.device}")
        print(f"æµ‹è¯•ç›®å½•: {self.test_dir}")
        
        # åˆ›å»ºæµ‹è¯•ç›®å½•
        if not self.keep_files and self.test_dir.exists():
            import shutil
            shutil.rmtree(self.test_dir)
        
        self.test_dir.mkdir(parents=True, exist_ok=True)
        (self.test_dir / 'data').mkdir(exist_ok=True)
        (self.test_dir / 'configs').mkdir(exist_ok=True)
        (self.test_dir / 'runs').mkdir(exist_ok=True)
    
    def setup_test_data(self) -> Dict[str, Any]:
        """è®¾ç½®æµ‹è¯•æ•°æ®"""
        print("è®¾ç½®æµ‹è¯•æ•°æ®...")
        
        data_dir = self.test_dir / 'data'
        
        # åˆ›å»ºæ•°æ®é›†ç›®å½•ç»“æ„
        for split in ['train', 'val', 'test']:
            split_dir = data_dir / split
            split_dir.mkdir(exist_ok=True)
            
            # ç”Ÿæˆå°‘é‡æµ‹è¯•æ•°æ®
            num_samples = 3 if split == 'train' else 2
            for i in range(num_samples):
                # åˆ›å»ºç®€å•çš„2Dåœºæ•°æ®
                x = np.linspace(0, 1, self.img_size)
                y = np.linspace(0, 1, self.img_size)
                X, Y = np.meshgrid(x, y)
                
                # æ¨¡æ‹ŸDarcy Flowè§£
                solution = (np.exp(-((X-0.3)**2 + (Y-0.3)**2) / 0.1) + 
                           0.5 * np.exp(-((X-0.7)**2 + (Y-0.7)**2) / 0.05))
                
                # æ·»åŠ å°‘é‡å™ªå£°
                solution += 0.01 * np.random.randn(*solution.shape)
                
                # ä¿å­˜ä¸ºnumpyæ–‡ä»¶
                np.save(split_dir / f'sample_{i:03d}.npy', solution.astype(np.float32))
        
        dataset_config = {
            'data_dir': str(data_dir),
            'img_size': self.img_size,
            'normalize': True,
            'augment': False
        }
        
        return dataset_config
    
    def test_data_loading(self, dataset_config: Dict[str, Any]) -> bool:
        """æµ‹è¯•æ•°æ®åŠ è½½"""
        print("æµ‹è¯•æ•°æ®åŠ è½½...")
        
        try:
            # åˆ›å»ºç®€å•çš„æµ‹è¯•æ•°æ®é›†ç±»
            class SimpleDarcyDataset(torch.utils.data.Dataset):
                def __init__(self, data_dir, split, img_size, normalize=True):
                    self.data_dir = Path(data_dir)
                    self.split = split
                    self.img_size = img_size
                    self.normalize = normalize
                    
                    # åŠ è½½æ•°æ®æ–‡ä»¶
                    split_dir = self.data_dir / split
                    self.files = list(split_dir.glob('*.npy'))
                
                def __len__(self):
                    return len(self.files)
                
                def __getitem__(self, idx):
                    # åŠ è½½æ•°æ®
                    data = np.load(self.files[idx])
                    
                    # è°ƒæ•´å°ºå¯¸
                    if data.shape != (self.img_size, self.img_size):
                        data = torch.from_numpy(data).unsqueeze(0).unsqueeze(0)
                        data = F.interpolate(data, size=(self.img_size, self.img_size), mode='bilinear', align_corners=False)
                        data = data.squeeze().numpy()
                    
                    # è½¬æ¢ä¸ºå¼ é‡
                    gt = torch.from_numpy(data).unsqueeze(0).float()  # [1, H, W]
                    
                    # åˆ›å»ºåŸºçº¿ï¼ˆæ·»åŠ å™ªå£°ï¼‰
                    baseline = gt + 0.1 * torch.randn_like(gt)
                    
                    return {
                        'gt': gt,
                        'baseline': baseline,
                        'coords': torch.zeros(2, self.img_size, self.img_size),  # å ä½ç¬¦
                        'mask': torch.ones(1, self.img_size, self.img_size)  # å ä½ç¬¦
                    }
            
            train_dataset = SimpleDarcyDataset(
                data_dir=dataset_config['data_dir'],
                split='train',
                img_size=dataset_config['img_size'],
                normalize=dataset_config['normalize']
            )
            
            # åˆ›å»ºæ•°æ®åŠ è½½å™¨
            train_loader = torch.utils.data.DataLoader(
                train_dataset, batch_size=self.batch_size, shuffle=True
            )
            
            # æµ‹è¯•æ•°æ®åŠ è½½
            train_batch = next(iter(train_loader))
            
            # éªŒè¯æ•°æ®å½¢çŠ¶
            assert train_batch['gt'].shape == (self.batch_size, 1, self.img_size, self.img_size)
            assert train_batch['baseline'].shape == (self.batch_size, 1, self.img_size, self.img_size)
            
            print(f"âœ“ æ•°æ®åŠ è½½æµ‹è¯•é€šè¿‡")
            print(f"  è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
            print(f"  æ•°æ®å½¢çŠ¶: {train_batch['gt'].shape}")
            
            return True
            
        except Exception as e:
            print(f"âœ— æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_model_initialization(self) -> Dict[str, bool]:
        """æµ‹è¯•æ¨¡å‹åˆå§‹åŒ–"""
        print("æµ‹è¯•æ¨¡å‹åˆå§‹åŒ–...")
        
        results = {}
        
        # æµ‹è¯•SwinUNetæ¨¡å‹
        try:
            model = SwinUNet(
                in_channels=1,
                out_channels=1,
                img_size=self.img_size,
                patch_size=4,
                window_size=4,
                depths=[2, 2],
                num_heads=[2, 4],
                embed_dim=48
            ).to(self.device)
            
            # æµ‹è¯•å‰å‘ä¼ æ’­
            dummy_input = torch.randn(self.batch_size, 1, self.img_size, self.img_size).to(self.device)
            
            with torch.no_grad():
                output = model(dummy_input)
            
            expected_shape = (self.batch_size, 1, self.img_size, self.img_size)
            assert output.shape == expected_shape, f"è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…: {output.shape} vs {expected_shape}"
            
            # è®¡ç®—å‚æ•°é‡
            num_params = sum(p.numel() for p in model.parameters())
            
            print(f"âœ“ SwinUNetæ¨¡å‹åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")
            print(f"  å‚æ•°é‡: {num_params:,}")
            print(f"  è¾“å‡ºå½¢çŠ¶: {output.shape}")
            
            results['swin_unet'] = True
            
        except Exception as e:
            print(f"âœ— SwinUNetæ¨¡å‹åˆå§‹åŒ–æµ‹è¯•å¤±è´¥: {e}")
            results['swin_unet'] = False
        
        return results
    
    def test_loss_computation(self, dataset_config: Dict[str, Any]) -> bool:
        """æµ‹è¯•æŸå¤±å‡½æ•°è®¡ç®—"""
        print("æµ‹è¯•æŸå¤±å‡½æ•°è®¡ç®—...")
        
        try:
            # åˆ›å»ºç®€å•çš„æµ‹è¯•æ•°æ®é›†ç±»
            class SimpleDarcyDataset(torch.utils.data.Dataset):
                def __init__(self, data_dir, split, img_size, normalize=True):
                    self.data_dir = Path(data_dir)
                    self.split = split
                    self.img_size = img_size
                    self.normalize = normalize
                    
                    # åŠ è½½æ•°æ®æ–‡ä»¶
                    split_dir = self.data_dir / split
                    self.files = list(split_dir.glob('*.npy'))
                
                def __len__(self):
                    return len(self.files)
                
                def __getitem__(self, idx):
                    # åŠ è½½æ•°æ®
                    data = np.load(self.files[idx])
                    
                    # è°ƒæ•´å°ºå¯¸
                    if data.shape != (self.img_size, self.img_size):
                        data = torch.from_numpy(data).unsqueeze(0).unsqueeze(0)
                        data = F.interpolate(data, size=(self.img_size, self.img_size), mode='bilinear', align_corners=False)
                        data = data.squeeze().numpy()
                    
                    # è½¬æ¢ä¸ºå¼ é‡
                    gt = torch.from_numpy(data).unsqueeze(0).float()  # [1, H, W]
                    
                    # åˆ›å»ºåŸºçº¿ï¼ˆæ·»åŠ å™ªå£°ï¼‰
                    baseline = gt + 0.1 * torch.randn_like(gt)
                    
                    return {
                        'gt': gt,
                        'baseline': baseline,
                        'coords': torch.zeros(2, self.img_size, self.img_size),  # å ä½ç¬¦
                        'mask': torch.ones(1, self.img_size, self.img_size)  # å ä½ç¬¦
                    }
            
            dataset = SimpleDarcyDataset(
                data_dir=dataset_config['data_dir'],
                split='train',
                img_size=dataset_config['img_size']
            )
            
            dataloader = torch.utils.data.DataLoader(
                dataset, batch_size=self.batch_size, shuffle=False
            )
            
            # åˆ›å»ºç®€å•æ¨¡å‹ç”¨äºæµ‹è¯•
            model = nn.Conv2d(1, 1, 3, padding=1).to(self.device)
            
            # åˆ›å»ºæŸå¤±å‡½æ•°
            criterion = TotalLoss(
                rec_weight=1.0,
                spec_weight=0.5,
                dc_weight=1.0
            )
            
            # è·å–ä¸€ä¸ªbatch
            batch = next(iter(dataloader))
            baseline = batch['baseline'].to(self.device)
            gt = batch['gt'].to(self.device)
            
            # å‰å‘ä¼ æ’­
            pred = model(baseline)
            
            # è®¡ç®—æŸå¤± - ä½¿ç”¨ç®€åŒ–çš„æŸå¤±è®¡ç®—
            task_params = {'task': 'sr', 'scale': 2}
            total_loss, loss_dict = criterion(pred, gt, baseline, task_params)
            
            # éªŒè¯æŸå¤±ç»„ä»¶
            required_keys = ['total', 'reconstruction', 'spectral', 'data_consistency']
            for key in required_keys:
                assert key in loss_dict, f"ç¼ºå°‘æŸå¤±ç»„ä»¶: {key}"
                assert isinstance(loss_dict[key], torch.Tensor), f"{key}ä¸æ˜¯å¼ é‡"
                assert loss_dict[key].requires_grad, f"{key}ä¸éœ€è¦æ¢¯åº¦"
            
            print(f"âœ“ æŸå¤±å‡½æ•°è®¡ç®—æµ‹è¯•é€šè¿‡")
            print(f"  æ€»æŸå¤±: {loss_dict['total'].item():.6f}")
            print(f"  é‡å»ºæŸå¤±: {loss_dict['reconstruction'].item():.6f}")
            print(f"  é¢‘è°±æŸå¤±: {loss_dict['spectral'].item():.6f}")
            print(f"  æ•°æ®ä¸€è‡´æ€§æŸå¤±: {loss_dict['data_consistency'].item():.6f}")
            
            return True
            
        except Exception as e:
            print(f"âœ— æŸå¤±å‡½æ•°è®¡ç®—æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_training_loop(self, dataset_config: Dict[str, Any]) -> bool:
        """æµ‹è¯•è®­ç»ƒå¾ªç¯"""
        print("æµ‹è¯•è®­ç»ƒå¾ªç¯...")
        
        try:
            # åˆ›å»ºç®€å•çš„æµ‹è¯•æ•°æ®é›†ç±»
            class SimpleDarcyDataset(torch.utils.data.Dataset):
                def __init__(self, data_dir, split, img_size, normalize=True):
                    self.data_dir = Path(data_dir)
                    self.split = split
                    self.img_size = img_size
                    self.normalize = normalize
                    
                    # åŠ è½½æ•°æ®æ–‡ä»¶
                    split_dir = self.data_dir / split
                    self.files = list(split_dir.glob('*.npy'))
                
                def __len__(self):
                    return len(self.files)
                
                def __getitem__(self, idx):
                    # åŠ è½½æ•°æ®
                    data = np.load(self.files[idx])
                    
                    # è°ƒæ•´å°ºå¯¸
                    if data.shape != (self.img_size, self.img_size):
                        data = torch.from_numpy(data).unsqueeze(0).unsqueeze(0)
                        data = F.interpolate(data, size=(self.img_size, self.img_size), mode='bilinear', align_corners=False)
                        data = data.squeeze().numpy()
                    
                    # è½¬æ¢ä¸ºå¼ é‡
                    gt = torch.from_numpy(data).unsqueeze(0).float()  # [1, H, W]
                    
                    # åˆ›å»ºåŸºçº¿ï¼ˆæ·»åŠ å™ªå£°ï¼‰
                    baseline = gt + 0.1 * torch.randn_like(gt)
                    
                    return {
                        'gt': gt,
                        'baseline': baseline,
                        'coords': torch.zeros(2, self.img_size, self.img_size),  # å ä½ç¬¦
                        'mask': torch.ones(1, self.img_size, self.img_size)  # å ä½ç¬¦
                    }
            
            train_dataset = SimpleDarcyDataset(
                data_dir=dataset_config['data_dir'],
                split='train',
                img_size=dataset_config['img_size']
            )
            
            train_loader = torch.utils.data.DataLoader(
                train_dataset, batch_size=self.batch_size, shuffle=True
            )
            
            # åˆ›å»ºæ¨¡å‹
            model = SwinUNet(
                in_channels=1,
                out_channels=1,
                img_size=self.img_size,
                patch_size=4,
                window_size=4,
                depths=[2, 2],
                num_heads=[2, 4],
                embed_dim=48
            ).to(self.device)
            
            # åˆ›å»ºä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
            optimizer = torch.optim.AdamW(
                model.parameters(),
                lr=1e-3,
                weight_decay=1e-4
            )
            
            criterion = TotalLoss(
                rec_weight=1.0,
                spec_weight=0.5,
                dc_weight=1.0
            )
            
            # è®­ç»ƒå¾ªç¯
            model.train()
            epoch_losses = []
            
            for epoch in range(self.num_epochs):
                epoch_loss = 0.0
                num_batches = 0
                
                for batch in train_loader:
                    baseline = batch['baseline'].to(self.device)
                    gt = batch['gt'].to(self.device)
                    
                    # å‰å‘ä¼ æ’­
                    pred = model(baseline)
                    
                    # è®¡ç®—æŸå¤±
                    task_params = {'task': 'sr', 'scale': 2}
                    loss, loss_dict = criterion(pred, gt, baseline, task_params)
                    
                    # åå‘ä¼ æ’­
                    optimizer.zero_grad()
                    loss.backward()
                    
                    # æ¢¯åº¦è£å‰ª
                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                    
                    optimizer.step()
                    
                    epoch_loss += loss.item()
                    num_batches += 1
                
                avg_loss = epoch_loss / num_batches
                epoch_losses.append(avg_loss)
                
                print(f"  Epoch {epoch+1}/{self.num_epochs}, Loss: {avg_loss:.6f}")
            
            print(f"âœ“ è®­ç»ƒå¾ªç¯æµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âœ— è®­ç»ƒå¾ªç¯æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_evaluation_metrics(self, dataset_config: Dict[str, Any]) -> bool:
        """æµ‹è¯•è¯„æµ‹æŒ‡æ ‡è®¡ç®—"""
        print("æµ‹è¯•è¯„æµ‹æŒ‡æ ‡è®¡ç®—...")
        
        try:
            # åˆ›å»ºæŒ‡æ ‡è®¡ç®—å™¨
            metrics_calc = PDEBenchMetrics(
                image_size=(self.img_size, self.img_size),
                boundary_width=8
            )
            
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            gt = torch.randn(self.batch_size, 1, self.img_size, self.img_size)
            pred = gt + 0.1 * torch.randn_like(gt)  # æ·»åŠ å™ªå£°æ¨¡æ‹Ÿé¢„æµ‹
            
            # è®¡ç®—æŒ‡æ ‡
            rel_l2 = metrics_calc.compute_rel_l2(pred, gt).mean().item()
            mae = metrics_calc.compute_mae(pred, gt).mean().item()
            psnr = metrics_calc.compute_psnr(pred, gt).mean().item()
            ssim_val = metrics_calc.compute_ssim(pred, gt).mean().item()
            
            metrics = {
                'rel_l2': rel_l2,
                'mae': mae,
                'psnr': psnr,
                'ssim': ssim_val
            }
            
            # éªŒè¯æŒ‡æ ‡
            required_metrics = ['rel_l2', 'mae', 'psnr', 'ssim']
            for metric in required_metrics:
                assert metric in metrics, f"ç¼ºå°‘æŒ‡æ ‡: {metric}"
                assert isinstance(metrics[metric], (float, torch.Tensor)), f"{metric}ç±»å‹é”™è¯¯"
            
            print(f"âœ“ è¯„æµ‹æŒ‡æ ‡è®¡ç®—æµ‹è¯•é€šè¿‡")
            print(f"  Rel-L2: {metrics['rel_l2']:.6f}")
            print(f"  MAE: {metrics['mae']:.6f}")
            print(f"  PSNR: {metrics['psnr']:.2f}")
            print(f"  SSIM: {metrics['ssim']:.4f}")
            
            return True
            
        except Exception as e:
            print(f"âœ— è¯„æµ‹æŒ‡æ ‡è®¡ç®—æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_degradation_operator(self) -> bool:
        """æµ‹è¯•é€€åŒ–ç®—å­"""
        print("æµ‹è¯•é€€åŒ–ç®—å­...")
        
        try:
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            test_data = torch.randn(1, 1, self.img_size, self.img_size)
            
            # æµ‹è¯•SRé€€åŒ–
            sr_params = {
                'task': 'sr',
                'scale': 2,
                'sigma': 1.0,
                'kernel_size': 5,
                'boundary': 'mirror'
            }
            
            sr_result = apply_degradation_operator(test_data, sr_params)
            expected_size = self.img_size // 2
            assert sr_result.shape == (1, 1, expected_size, expected_size), f"SRè¾“å‡ºå°ºå¯¸é”™è¯¯: {sr_result.shape}"
            
            # æµ‹è¯•Cropé€€åŒ–
            crop_params = {
                'task': 'crop',
                'crop_size': (32, 32),
                'boundary': 'mirror'
            }
            
            crop_result = apply_degradation_operator(test_data, crop_params)
            assert crop_result.shape == (1, 1, 32, 32), f"Cropè¾“å‡ºå°ºå¯¸é”™è¯¯: {crop_result.shape}"
            
            print(f"âœ“ é€€åŒ–ç®—å­æµ‹è¯•é€šè¿‡")
            print(f"  SRè¾“å‡ºå°ºå¯¸: {sr_result.shape}")
            print(f"  Cropè¾“å‡ºå°ºå¯¸: {crop_result.shape}")
            
            return True
            
        except Exception as e:
            print(f"âœ— é€€åŒ–ç®—å­æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def run_all_tests(self) -> Dict[str, bool]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("=" * 60)
        print("å¼€å§‹PDEBenchç¨€ç–è§‚æµ‹é‡å»ºç³»ç»Ÿç®€åŒ–ç«¯åˆ°ç«¯æµ‹è¯•")
        print("=" * 60)
        
        results = {}
        
        try:
            # 1. è®¾ç½®æµ‹è¯•ç¯å¢ƒ
            dataset_config = self.setup_test_data()
            
            # 2. æ•°æ®åŠ è½½æµ‹è¯•
            results['data_loading'] = self.test_data_loading(dataset_config)
            
            # 3. æ¨¡å‹åˆå§‹åŒ–æµ‹è¯•
            model_init_results = self.test_model_initialization()
            results.update({f'model_init_{k}': v for k, v in model_init_results.items()})
            
            # 4. æŸå¤±å‡½æ•°æµ‹è¯•
            results['loss_computation'] = self.test_loss_computation(dataset_config)
            
            # 5. è®­ç»ƒå¾ªç¯æµ‹è¯•
            results['training_loop'] = self.test_training_loop(dataset_config)
            
            # 6. è¯„æµ‹æŒ‡æ ‡æµ‹è¯•
            results['evaluation_metrics'] = self.test_evaluation_metrics(dataset_config)
            
            # 7. é€€åŒ–ç®—å­æµ‹è¯•
            results['degradation_operator'] = self.test_degradation_operator()
            
        except Exception as e:
            print(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            results['overall'] = False
        
        # æ±‡æ€»ç»“æœ
        print("\n" + "=" * 60)
        print("æµ‹è¯•ç»“æœæ±‡æ€»")
        print("=" * 60)
        
        passed_tests = sum(results.values())
        total_tests = len(results)
        
        for test_name, passed in results.items():
            status = "âœ“ é€šè¿‡" if passed else "âœ— å¤±è´¥"
            print(f"{test_name:30s} {status}")
        
        print("-" * 60)
        print(f"æ€»è®¡: {passed_tests}/{total_tests} æµ‹è¯•é€šè¿‡")
        
        overall_success = passed_tests == total_tests
        results['overall'] = overall_success
        
        if overall_success:
            print("ğŸ‰ æ‰€æœ‰ç®€åŒ–ç«¯åˆ°ç«¯æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿæ ¸å¿ƒåŠŸèƒ½æ­£å¸¸ã€‚")
        else:
            print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³ç»„ä»¶ã€‚")
        
        return results


def main():
    parser = argparse.ArgumentParser(description='PDEBenchç¨€ç–è§‚æµ‹é‡å»ºç³»ç»Ÿç®€åŒ–ç«¯åˆ°ç«¯æµ‹è¯•')
    parser.add_argument('--test-dir', type=str, default='test_outputs', help='æµ‹è¯•è¾“å‡ºç›®å½•')
    parser.add_argument('--keep-files', action='store_true', help='ä¿ç•™æµ‹è¯•æ–‡ä»¶')
    
    args = parser.parse_args()
    
    # è¿è¡Œæµ‹è¯•
    tester = SimpleE2ETest(args.test_dir, args.keep_files)
    results = tester.run_all_tests()
    
    # è¿”å›é€€å‡ºç 
    if results.get('overall', False):
        sys.exit(0)
    else:
        sys.exit(1)


if __name__ == '__main__':
    main()