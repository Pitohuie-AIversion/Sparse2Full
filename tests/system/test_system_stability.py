"""
æµ‹è¯•ç³»ç»Ÿç¨³å®šæ€§

éªŒè¯PDEBenchç¨€ç–è§‚æµ‹é‡å»ºç³»ç»Ÿçš„ç¨³å®šæ€§ï¼š
1. å¯å¤ç°æ€§ï¼šç›¸åŒé…ç½®å¤šæ¬¡è¿è¡Œç»“æœä¸€è‡´
2. é”™è¯¯å¤„ç†ï¼šå¼‚å¸¸æƒ…å†µä¸‹çš„é²æ£’æ€§
3. æ–­ç‚¹ç»­è®­ï¼šè®­ç»ƒä¸­æ–­åèƒ½æ­£ç¡®æ¢å¤
4. å†…å­˜ç®¡ç†ï¼šé•¿æ—¶é—´è¿è¡Œä¸ä¼šå†…å­˜æ³„æ¼
5. æ•°å€¼ç¨³å®šæ€§ï¼šé¿å…æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import os
import sys
import json
import time
import random
import gc
import psutil
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass
import tempfile
import shutil
import warnings

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent.parent))

try:
    from utils.metrics import MetricsCalculator, StatisticalAnalyzer
    from test_resource_monitoring import ResourceMonitor
except ImportError as e:
    print(f"è­¦å‘Š: æ— æ³•å¯¼å…¥æŸäº›æ¨¡å—: {e}")
    print("å°†ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬è¿›è¡Œæµ‹è¯•")


class SimpleTestModel(nn.Module):
    """ç®€å•æµ‹è¯•æ¨¡å‹"""
    
    def __init__(self, in_channels=3, out_channels=3, hidden_dim=64):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels, hidden_dim, 3, padding=1)
        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, 3, padding=1)
        self.conv3 = nn.Conv2d(hidden_dim, out_channels, 3, padding=1)
        self.relu = nn.ReLU(inplace=True)
        self.dropout = nn.Dropout(0.1)
    
    def forward(self, x):
        x = self.relu(self.conv1(x))
        x = self.dropout(x)
        x = self.relu(self.conv2(x))
        x = self.dropout(x)
        x = self.conv3(x)
        return x


@dataclass
class TrainingConfig:
    """è®­ç»ƒé…ç½®"""
    batch_size: int = 4
    learning_rate: float = 1e-3
    num_epochs: int = 10
    save_interval: int = 5
    seed: int = 42
    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'


class SystemStabilityTester:
    """ç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.results = {}
        self.temp_dir = None
        
    def setup_temp_dir(self):
        """è®¾ç½®ä¸´æ—¶ç›®å½•"""
        self.temp_dir = tempfile.mkdtemp(prefix="stability_test_")
        return self.temp_dir
    
    def cleanup_temp_dir(self):
        """æ¸…ç†ä¸´æ—¶ç›®å½•"""
        if self.temp_dir and os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)
            self.temp_dir = None
    
    def set_seed(self, seed: int):
        """è®¾ç½®éšæœºç§å­ç¡®ä¿å¯å¤ç°æ€§"""
        torch.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        np.random.seed(seed)
        random.seed(seed)
        
        # ç¡®ä¿ç¡®å®šæ€§
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
    
    def test_reproducibility(self) -> Dict[str, Any]:
        """æµ‹è¯•å¯å¤ç°æ€§"""
        print("æµ‹è¯•ç³»ç»Ÿå¯å¤ç°æ€§...")
        
        results = {
            'passed': True,
            'details': {},
            'errors': []
        }
        
        try:
            config = TrainingConfig()
            
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            input_shape = (config.batch_size, 3, 64, 64)
            target_shape = (config.batch_size, 3, 64, 64)
            
            # å¤šæ¬¡è¿è¡Œç›¸åŒé…ç½®
            num_runs = 3
            final_losses = []
            final_weights = []
            
            for run in range(num_runs):
                print(f"  è¿è¡Œ {run + 1}/{num_runs}...")
                
                # è®¾ç½®ç›¸åŒç§å­
                self.set_seed(config.seed)
                
                # åˆ›å»ºæ¨¡å‹å’Œä¼˜åŒ–å™¨
                model = SimpleTestModel().to(self.device)
                optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)
                criterion = nn.MSELoss()
                
                # è®­ç»ƒå‡ ä¸ªepoch
                model.train()
                for epoch in range(5):
                    # ç”Ÿæˆç›¸åŒçš„éšæœºæ•°æ®ï¼ˆé€šè¿‡ç§å­æ§åˆ¶ï¼‰
                    self.set_seed(config.seed + epoch)
                    x = torch.randn(input_shape).to(self.device)
                    target = torch.randn(target_shape).to(self.device)
                    
                    optimizer.zero_grad()
                    pred = model(x)
                    loss = criterion(pred, target)
                    loss.backward()
                    optimizer.step()
                
                # è®°å½•æœ€ç»ˆæŸå¤±å’Œæƒé‡
                final_losses.append(loss.item())
                
                # è®°å½•ç¬¬ä¸€å±‚æƒé‡çš„å“ˆå¸Œå€¼
                first_layer_weights = model.conv1.weight.data.cpu().numpy()
                weight_hash = hash(first_layer_weights.tobytes())
                final_weights.append(weight_hash)
            
            # æ£€æŸ¥å¯å¤ç°æ€§
            loss_variance = np.var(final_losses)
            weight_consistency = len(set(final_weights)) == 1
            
            results['details']['loss_variance'] = {
                'variance': loss_variance,
                'losses': final_losses,
                'passed': loss_variance < 1e-6
            }
            
            results['details']['weight_consistency'] = {
                'consistent': weight_consistency,
                'weight_hashes': final_weights,
                'passed': weight_consistency
            }
            
            if loss_variance >= 1e-6:
                results['passed'] = False
                results['errors'].append(f"æŸå¤±æ–¹å·®è¿‡å¤§: {loss_variance:.2e}")
            
            if not weight_consistency:
                results['passed'] = False
                results['errors'].append("æƒé‡ä¸ä¸€è‡´ï¼Œå¯å¤ç°æ€§å¤±è´¥")
            
            print(f"âœ“ å¯å¤ç°æ€§æµ‹è¯•: {'é€šè¿‡' if results['passed'] else 'å¤±è´¥'}")
            
        except Exception as e:
            results['passed'] = False
            results['errors'].append(f"å¯å¤ç°æ€§æµ‹è¯•å¼‚å¸¸: {str(e)}")
            print(f"âŒ å¯å¤ç°æ€§æµ‹è¯•å¤±è´¥: {e}")
        
        return results
    
    def test_error_handling(self) -> Dict[str, Any]:
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        print("æµ‹è¯•é”™è¯¯å¤„ç†èƒ½åŠ›...")
        
        results = {
            'passed': True,
            'details': {},
            'errors': []
        }
        
        try:
            # æµ‹è¯•1: è¾“å…¥ç»´åº¦ä¸åŒ¹é…
            print("  æµ‹è¯•è¾“å…¥ç»´åº¦ä¸åŒ¹é…...")
            model = SimpleTestModel(in_channels=3, out_channels=3).to(self.device)
            
            try:
                wrong_input = torch.randn(2, 5, 64, 64).to(self.device)  # é”™è¯¯çš„é€šé“æ•°
                with torch.no_grad():
                    _ = model(wrong_input)
                results['details']['dimension_mismatch'] = {
                    'handled': False,
                    'error': "åº”è¯¥æŠ›å‡ºå¼‚å¸¸ä½†æ²¡æœ‰"
                }
                results['passed'] = False
                results['errors'].append("ç»´åº¦ä¸åŒ¹é…æœªæ­£ç¡®å¤„ç†")
            except RuntimeError as e:
                results['details']['dimension_mismatch'] = {
                    'handled': True,
                    'error_type': type(e).__name__,
                    'error_msg': str(e)
                }
            
            # æµ‹è¯•2: å†…å­˜ä¸è¶³å¤„ç†
            print("  æµ‹è¯•å†…å­˜ä¸è¶³å¤„ç†...")
            try:
                # å°è¯•åˆ›å»ºè¿‡å¤§çš„å¼ é‡
                huge_tensor = torch.randn(10000, 10000, 10000).to(self.device)
                results['details']['memory_overflow'] = {
                    'handled': False,
                    'error': "åº”è¯¥æŠ›å‡ºå†…å­˜å¼‚å¸¸ä½†æ²¡æœ‰"
                }
            except (RuntimeError, torch.cuda.OutOfMemoryError) as e:
                results['details']['memory_overflow'] = {
                    'handled': True,
                    'error_type': type(e).__name__,
                    'error_msg': str(e)
                }
            except Exception as e:
                results['details']['memory_overflow'] = {
                    'handled': True,
                    'error_type': type(e).__name__,
                    'error_msg': str(e)
                }
            
            # æµ‹è¯•3: æ¢¯åº¦å¼‚å¸¸å¤„ç†
            print("  æµ‹è¯•æ¢¯åº¦å¼‚å¸¸å¤„ç†...")
            model = SimpleTestModel().to(self.device)
            optimizer = optim.Adam(model.parameters(), lr=1e10)  # è¿‡å¤§çš„å­¦ä¹ ç‡
            criterion = nn.MSELoss()
            
            x = torch.randn(2, 3, 64, 64).to(self.device)
            target = torch.randn(2, 3, 64, 64).to(self.device)
            
            gradient_norms = []
            for i in range(10):
                optimizer.zero_grad()
                pred = model(x)
                loss = criterion(pred, target)
                loss.backward()
                
                # æ£€æŸ¥æ¢¯åº¦èŒƒæ•°
                total_norm = 0
                for p in model.parameters():
                    if p.grad is not None:
                        param_norm = p.grad.data.norm(2)
                        total_norm += param_norm.item() ** 2
                total_norm = total_norm ** (1. / 2)
                gradient_norms.append(total_norm)
                
                # æ¢¯åº¦è£å‰ª
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
                
                if torch.isnan(loss) or torch.isinf(loss):
                    break
            
            has_gradient_explosion = any(norm > 100 for norm in gradient_norms)
            results['details']['gradient_handling'] = {
                'gradient_norms': gradient_norms[:5],  # åªä¿å­˜å‰5ä¸ª
                'has_explosion': has_gradient_explosion,
                'handled': True  # é€šè¿‡æ¢¯åº¦è£å‰ªå¤„ç†
            }
            
            print(f"âœ“ é”™è¯¯å¤„ç†æµ‹è¯•: {'é€šè¿‡' if results['passed'] else 'å¤±è´¥'}")
            
        except Exception as e:
            results['passed'] = False
            results['errors'].append(f"é”™è¯¯å¤„ç†æµ‹è¯•å¼‚å¸¸: {str(e)}")
            print(f"âŒ é”™è¯¯å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        
        return results
    
    def test_checkpoint_resume(self) -> Dict[str, Any]:
        """æµ‹è¯•æ–­ç‚¹ç»­è®­"""
        print("æµ‹è¯•æ–­ç‚¹ç»­è®­åŠŸèƒ½...")
        
        results = {
            'passed': True,
            'details': {},
            'errors': []
        }
        
        try:
            temp_dir = self.setup_temp_dir()
            checkpoint_path = os.path.join(temp_dir, "checkpoint.pth")
            
            config = TrainingConfig(num_epochs=10)
            
            # ç¬¬ä¸€é˜¶æ®µï¼šè®­ç»ƒå¹¶ä¿å­˜æ£€æŸ¥ç‚¹
            print("  ç¬¬ä¸€é˜¶æ®µï¼šè®­ç»ƒå¹¶ä¿å­˜æ£€æŸ¥ç‚¹...")
            self.set_seed(config.seed)
            
            model1 = SimpleTestModel().to(self.device)
            optimizer1 = optim.Adam(model1.parameters(), lr=config.learning_rate)
            criterion = nn.MSELoss()
            
            # è®­ç»ƒå‰åŠéƒ¨åˆ†
            losses_phase1 = []
            for epoch in range(config.num_epochs // 2):
                x = torch.randn(config.batch_size, 3, 64, 64).to(self.device)
                target = torch.randn(config.batch_size, 3, 64, 64).to(self.device)
                
                optimizer1.zero_grad()
                pred = model1(x)
                loss = criterion(pred, target)
                loss.backward()
                optimizer1.step()
                
                losses_phase1.append(loss.item())
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            checkpoint = {
                'epoch': config.num_epochs // 2,
                'model_state_dict': model1.state_dict(),
                'optimizer_state_dict': optimizer1.state_dict(),
                'loss': losses_phase1[-1],
                'rng_state': torch.get_rng_state().cpu(),  # ç¡®ä¿åœ¨CPUä¸Š
                'cuda_rng_state': torch.cuda.get_rng_state().cpu() if torch.cuda.is_available() else None
            }
            torch.save(checkpoint, checkpoint_path)
            
            # ç¬¬äºŒé˜¶æ®µï¼šä»æ£€æŸ¥ç‚¹æ¢å¤å¹¶ç»§ç»­è®­ç»ƒ
            print("  ç¬¬äºŒé˜¶æ®µï¼šä»æ£€æŸ¥ç‚¹æ¢å¤...")
            
            model2 = SimpleTestModel().to(self.device)
            optimizer2 = optim.Adam(model2.parameters(), lr=config.learning_rate)
            
            # åŠ è½½æ£€æŸ¥ç‚¹
            checkpoint = torch.load(checkpoint_path, map_location=self.device)
            model2.load_state_dict(checkpoint['model_state_dict'])
            optimizer2.load_state_dict(checkpoint['optimizer_state_dict'])
            start_epoch = checkpoint['epoch']
            
            # æ¢å¤éšæœºæ•°çŠ¶æ€
            try:
                if 'rng_state' in checkpoint and checkpoint['rng_state'] is not None:
                    torch.set_rng_state(checkpoint['rng_state'])
            except Exception as e:
                print(f"  è­¦å‘Š: æ— æ³•æ¢å¤RNGçŠ¶æ€: {e}")
            
            try:
                if 'cuda_rng_state' in checkpoint and checkpoint['cuda_rng_state'] is not None and torch.cuda.is_available():
                    torch.cuda.set_rng_state(checkpoint['cuda_rng_state'])
            except Exception as e:
                print(f"  è­¦å‘Š: æ— æ³•æ¢å¤CUDA RNGçŠ¶æ€: {e}")
            
            # ç»§ç»­è®­ç»ƒ
            losses_phase2 = []
            for epoch in range(start_epoch, config.num_epochs):
                x = torch.randn(config.batch_size, 3, 64, 64).to(self.device)
                target = torch.randn(config.batch_size, 3, 64, 64).to(self.device)
                
                optimizer2.zero_grad()
                pred = model2(x)
                loss = criterion(pred, target)
                loss.backward()
                optimizer2.step()
                
                losses_phase2.append(loss.item())
            
            # ç¬¬ä¸‰é˜¶æ®µï¼šå®Œæ•´è®­ç»ƒä½œä¸ºå¯¹æ¯”
            print("  ç¬¬ä¸‰é˜¶æ®µï¼šå®Œæ•´è®­ç»ƒå¯¹æ¯”...")
            self.set_seed(config.seed)
            
            model3 = SimpleTestModel().to(self.device)
            optimizer3 = optim.Adam(model3.parameters(), lr=config.learning_rate)
            
            losses_complete = []
            for epoch in range(config.num_epochs):
                x = torch.randn(config.batch_size, 3, 64, 64).to(self.device)
                target = torch.randn(config.batch_size, 3, 64, 64).to(self.device)
                
                optimizer3.zero_grad()
                pred = model3(x)
                loss = criterion(pred, target)
                loss.backward()
                optimizer3.step()
                
                losses_complete.append(loss.item())
            
            # éªŒè¯æ–­ç‚¹ç»­è®­ç»“æœ
            combined_losses = losses_phase1 + losses_phase2
            
            # æ£€æŸ¥æŸå¤±åºåˆ—æ˜¯å¦ä¸€è‡´
            loss_diff = np.mean(np.abs(np.array(combined_losses) - np.array(losses_complete)))
            
            # æ£€æŸ¥æœ€ç»ˆæ¨¡å‹æƒé‡æ˜¯å¦ä¸€è‡´
            weights_resumed = model2.conv1.weight.data.cpu().numpy()
            weights_complete = model3.conv1.weight.data.cpu().numpy()
            weight_diff = np.mean(np.abs(weights_resumed - weights_complete))
            
            results['details']['checkpoint_resume'] = {
                'loss_difference': loss_diff,
                'weight_difference': weight_diff,
                'losses_phase1': losses_phase1,
                'losses_phase2': losses_phase2,
                'losses_complete': losses_complete,
                'passed': loss_diff < 1e-6 and weight_diff < 1e-6
            }
            
            if loss_diff >= 1e-6 or weight_diff >= 1e-6:
                results['passed'] = False
                results['errors'].append(f"æ–­ç‚¹ç»­è®­ä¸ä¸€è‡´: loss_diff={loss_diff:.2e}, weight_diff={weight_diff:.2e}")
            
            print(f"âœ“ æ–­ç‚¹ç»­è®­æµ‹è¯•: {'é€šè¿‡' if results['passed'] else 'å¤±è´¥'}")
            
        except Exception as e:
            results['passed'] = False
            results['errors'].append(f"æ–­ç‚¹ç»­è®­æµ‹è¯•å¼‚å¸¸: {str(e)}")
            print(f"âŒ æ–­ç‚¹ç»­è®­æµ‹è¯•å¤±è´¥: {e}")
        finally:
            self.cleanup_temp_dir()
        
        return results
    
    def test_memory_management(self) -> Dict[str, Any]:
        """æµ‹è¯•å†…å­˜ç®¡ç†"""
        print("æµ‹è¯•å†…å­˜ç®¡ç†...")
        
        results = {
            'passed': True,
            'details': {},
            'errors': []
        }
        
        try:
            # è·å–åˆå§‹å†…å­˜ä½¿ç”¨
            process = psutil.Process()
            initial_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                initial_gpu_memory = torch.cuda.memory_allocated() / 1024 / 1024  # MB
            else:
                initial_gpu_memory = 0
            
            print(f"  åˆå§‹å†…å­˜: CPU={initial_memory:.1f}MB, GPU={initial_gpu_memory:.1f}MB")
            
            # æ¨¡æ‹Ÿé•¿æ—¶é—´è®­ç»ƒ
            model = SimpleTestModel().to(self.device)
            optimizer = optim.Adam(model.parameters(), lr=1e-3)
            criterion = nn.MSELoss()
            
            memory_usage = []
            gpu_memory_usage = []
            
            for iteration in range(100):
                # åˆ›å»ºæ‰¹æ¬¡æ•°æ®
                x = torch.randn(8, 3, 128, 128).to(self.device)
                target = torch.randn(8, 3, 128, 128).to(self.device)
                
                # å‰å‘ä¼ æ’­
                optimizer.zero_grad()
                pred = model(x)
                loss = criterion(pred, target)
                loss.backward()
                optimizer.step()
                
                # æ¯10æ¬¡è¿­ä»£è®°å½•å†…å­˜ä½¿ç”¨
                if iteration % 10 == 0:
                    current_memory = process.memory_info().rss / 1024 / 1024
                    memory_usage.append(current_memory)
                    
                    if torch.cuda.is_available():
                        current_gpu_memory = torch.cuda.memory_allocated() / 1024 / 1024
                        gpu_memory_usage.append(current_gpu_memory)
                    else:
                        gpu_memory_usage.append(0)
                
                # æ¸…ç†ä¸å¿…è¦çš„å˜é‡
                del x, target, pred, loss
                
                # å®šæœŸåƒåœ¾å›æ”¶
                if iteration % 20 == 0:
                    gc.collect()
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
            
            # åˆ†æå†…å­˜ä½¿ç”¨è¶‹åŠ¿
            memory_growth = memory_usage[-1] - memory_usage[0]
            gpu_memory_growth = gpu_memory_usage[-1] - gpu_memory_usage[0]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å†…å­˜æ³„æ¼ï¼ˆå¢é•¿è¶…è¿‡50MBè®¤ä¸ºæœ‰é—®é¢˜ï¼‰
            memory_leak = memory_growth > 50
            gpu_memory_leak = gpu_memory_growth > 50
            
            results['details']['memory_management'] = {
                'initial_memory_mb': initial_memory,
                'final_memory_mb': memory_usage[-1],
                'memory_growth_mb': memory_growth,
                'initial_gpu_memory_mb': initial_gpu_memory,
                'final_gpu_memory_mb': gpu_memory_usage[-1],
                'gpu_memory_growth_mb': gpu_memory_growth,
                'memory_leak': memory_leak,
                'gpu_memory_leak': gpu_memory_leak,
                'memory_usage_history': memory_usage,
                'gpu_memory_usage_history': gpu_memory_usage
            }
            
            if memory_leak:
                results['passed'] = False
                results['errors'].append(f"CPUå†…å­˜æ³„æ¼: å¢é•¿{memory_growth:.1f}MB")
            
            if gpu_memory_leak:
                results['passed'] = False
                results['errors'].append(f"GPUå†…å­˜æ³„æ¼: å¢é•¿{gpu_memory_growth:.1f}MB")
            
            print(f"  æœ€ç»ˆå†…å­˜: CPU={memory_usage[-1]:.1f}MB (+{memory_growth:.1f}MB), GPU={gpu_memory_usage[-1]:.1f}MB (+{gpu_memory_growth:.1f}MB)")
            print(f"âœ“ å†…å­˜ç®¡ç†æµ‹è¯•: {'é€šè¿‡' if results['passed'] else 'å¤±è´¥'}")
            
        except Exception as e:
            results['passed'] = False
            results['errors'].append(f"å†…å­˜ç®¡ç†æµ‹è¯•å¼‚å¸¸: {str(e)}")
            print(f"âŒ å†…å­˜ç®¡ç†æµ‹è¯•å¤±è´¥: {e}")
        
        return results
    
    def test_numerical_stability(self) -> Dict[str, Any]:
        """æµ‹è¯•æ•°å€¼ç¨³å®šæ€§"""
        print("æµ‹è¯•æ•°å€¼ç¨³å®šæ€§...")
        
        results = {
            'passed': True,
            'details': {},
            'errors': []
        }
        
        try:
            # æµ‹è¯•ä¸åŒå­¦ä¹ ç‡ä¸‹çš„ç¨³å®šæ€§
            learning_rates = [1e-1, 1e-2, 1e-3, 1e-4]
            stability_results = {}
            
            for lr in learning_rates:
                print(f"  æµ‹è¯•å­¦ä¹ ç‡ {lr}...")
                
                model = SimpleTestModel().to(self.device)
                optimizer = optim.Adam(model.parameters(), lr=lr)
                criterion = nn.MSELoss()
                
                losses = []
                gradient_norms = []
                weight_norms = []
                
                stable = True
                
                for epoch in range(20):
                    x = torch.randn(4, 3, 64, 64).to(self.device)
                    target = torch.randn(4, 3, 64, 64).to(self.device)
                    
                    optimizer.zero_grad()
                    pred = model(x)
                    loss = criterion(pred, target)
                    
                    # æ£€æŸ¥æŸå¤±æ˜¯å¦ä¸ºNaNæˆ–Inf
                    if torch.isnan(loss) or torch.isinf(loss):
                        stable = False
                        break
                    
                    loss.backward()
                    
                    # è®¡ç®—æ¢¯åº¦èŒƒæ•°
                    total_norm = 0
                    for p in model.parameters():
                        if p.grad is not None:
                            param_norm = p.grad.data.norm(2)
                            total_norm += param_norm.item() ** 2
                    total_norm = total_norm ** (1. / 2)
                    gradient_norms.append(total_norm)
                    
                    # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦çˆ†ç‚¸
                    if total_norm > 1000:
                        stable = False
                        break
                    
                    optimizer.step()
                    
                    losses.append(loss.item())
                    
                    # è®¡ç®—æƒé‡èŒƒæ•°
                    weight_norm = sum(p.data.norm(2).item() for p in model.parameters())
                    weight_norms.append(weight_norm)
                    
                    # æ£€æŸ¥æƒé‡æ˜¯å¦çˆ†ç‚¸
                    if weight_norm > 1000:
                        stable = False
                        break
                
                stability_results[lr] = {
                    'stable': stable,
                    'final_loss': losses[-1] if losses else float('inf'),
                    'max_gradient_norm': max(gradient_norms) if gradient_norms else 0,
                    'final_weight_norm': weight_norms[-1] if weight_norms else 0,
                    'losses': losses[:10],  # åªä¿å­˜å‰10ä¸ª
                    'gradient_norms': gradient_norms[:10]
                }
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç¨³å®šçš„å­¦ä¹ ç‡
            stable_lrs = [lr for lr, result in stability_results.items() if result['stable']]
            
            results['details']['numerical_stability'] = {
                'stability_results': stability_results,
                'stable_learning_rates': stable_lrs,
                'has_stable_lr': len(stable_lrs) > 0
            }
            
            if len(stable_lrs) == 0:
                results['passed'] = False
                results['errors'].append("æ²¡æœ‰æ‰¾åˆ°æ•°å€¼ç¨³å®šçš„å­¦ä¹ ç‡")
            
            print(f"  ç¨³å®šçš„å­¦ä¹ ç‡: {stable_lrs}")
            print(f"âœ“ æ•°å€¼ç¨³å®šæ€§æµ‹è¯•: {'é€šè¿‡' if results['passed'] else 'å¤±è´¥'}")
            
        except Exception as e:
            results['passed'] = False
            results['errors'].append(f"æ•°å€¼ç¨³å®šæ€§æµ‹è¯•å¼‚å¸¸: {str(e)}")
            print(f"âŒ æ•°å€¼ç¨³å®šæ€§æµ‹è¯•å¤±è´¥: {e}")
        
        return results
    
    def generate_stability_report(self, results: Dict[str, Dict]) -> str:
        """ç”Ÿæˆç¨³å®šæ€§æŠ¥å‘Š"""
        report = []
        report.append("PDEBenchç¨€ç–è§‚æµ‹é‡å»ºç³»ç»Ÿ - ç³»ç»Ÿç¨³å®šæ€§æŠ¥å‘Š")
        report.append("=" * 60)
        report.append("")
        
        # æ€»ä½“çŠ¶æ€
        all_passed = all(result['passed'] for result in results.values())
        report.append(f"æ€»ä½“çŠ¶æ€: {'âœ“ é€šè¿‡' if all_passed else 'âŒ å¤±è´¥'}")
        report.append("")
        
        # å„æµ‹è¯•è¯¦æƒ…
        test_names = {
            'reproducibility': '1. å¯å¤ç°æ€§',
            'error_handling': '2. é”™è¯¯å¤„ç†',
            'checkpoint_resume': '3. æ–­ç‚¹ç»­è®­',
            'memory_management': '4. å†…å­˜ç®¡ç†',
            'numerical_stability': '5. æ•°å€¼ç¨³å®šæ€§'
        }
        
        for test_key, test_name in test_names.items():
            if test_key in results:
                result = results[test_key]
                status = 'âœ“ é€šè¿‡' if result['passed'] else 'âŒ å¤±è´¥'
                report.append(f"{test_name}: {status}")
                
                if result['errors']:
                    for error in result['errors']:
                        report.append(f"  - {error}")
                
                report.append("")
        
        # å»ºè®®
        report.append("æ”¹è¿›å»ºè®®:")
        if not all_passed:
            for test_key, result in results.items():
                if not result['passed']:
                    test_name = test_names.get(test_key, test_key)
                    report.append(f"- {test_name}: éœ€è¦ä¿®å¤ä¸Šè¿°é—®é¢˜")
        else:
            report.append("- ç³»ç»Ÿç¨³å®šæ€§è‰¯å¥½ï¼Œæ‰€æœ‰æµ‹è¯•å‡é€šè¿‡")
        
        return "\n".join(report)
    
    def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰ç¨³å®šæ€§æµ‹è¯•"""
        print("PDEBenchç¨€ç–è§‚æµ‹é‡å»ºç³»ç»Ÿ - ç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•")
        print("=" * 60)
        
        results = {}
        
        # è¿è¡Œå„é¡¹æµ‹è¯•
        results['reproducibility'] = self.test_reproducibility()
        results['error_handling'] = self.test_error_handling()
        results['checkpoint_resume'] = self.test_checkpoint_resume()
        results['memory_management'] = self.test_memory_management()
        results['numerical_stability'] = self.test_numerical_stability()
        
        # ç”ŸæˆæŠ¥å‘Š
        report = self.generate_stability_report(results)
        print("\n" + report)
        
        # ä¿å­˜ç»“æœ
        self.results = results
        
        return results


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    tester = SystemStabilityTester()
    
    try:
        results = tester.run_all_tests()
        
        # æ£€æŸ¥æ€»ä½“ç»“æœ
        all_passed = all(result['passed'] for result in results.values())
        
        if all_passed:
            print("\nğŸ‰ æ‰€æœ‰ç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•é€šè¿‡ï¼")
            return 0
        else:
            print("\nâš ï¸ éƒ¨åˆ†ç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ”¹è¿›ã€‚")
            return 1
            
    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•å¼‚å¸¸: {e}")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)