#!/usr/bin/env python3
"""SwinUNetæ¨¡å‹è¯Šæ–­æµ‹è¯•è„šæœ¬

ç”¨äºè¯Šæ–­SwinUNetæ¨¡å‹çš„é—®é¢˜ï¼ŒåŒ…æ‹¬ï¼š
1. æ¨¡å‹åˆ›å»ºæµ‹è¯•
2. å‰å‘ä¼ æ’­æµ‹è¯•
3. æ¢¯åº¦è®¡ç®—æµ‹è¯•
4. æŸå¤±å‡½æ•°æµ‹è¯•
5. å‚æ•°æ£€æŸ¥
"""

import torch
import torch.nn as nn
import numpy as np
import traceback
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from models.swin_unet import SwinUNet
from models.base import create_model


def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("=" * 60)
    print("1. æµ‹è¯•SwinUNetæ¨¡å‹åˆ›å»º")
    print("=" * 60)
    
    try:
        # æµ‹è¯•åŸºæœ¬å‚æ•°
        model = SwinUNet(
            in_channels=3,
            out_channels=3,
            img_size=256,
            patch_size=4,
            embed_dim=96,
            depths=[2, 2, 6, 2],
            num_heads=[3, 6, 12, 24],
            window_size=8,
            mlp_ratio=4.0,
            drop_rate=0.0,
            attn_drop_rate=0.0,
            drop_path_rate=0.1,
            norm_layer=nn.LayerNorm  # ç¡®ä¿ä¼ å…¥å¯è°ƒç”¨å¯¹è±¡è€Œä¸æ˜¯å­—ç¬¦ä¸²
        )
        
        print("âœ“ SwinUNetæ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"  - æ€»å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        print(f"  - å¯è®­ç»ƒå‚æ•°: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
        
        return model
        
    except Exception as e:
        print(f"âœ— SwinUNetæ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        print(f"é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
        return None


def test_forward_pass(model, device):
    """æµ‹è¯•å‰å‘ä¼ æ’­"""
    print("\n" + "=" * 60)
    print("2. æµ‹è¯•å‰å‘ä¼ æ’­")
    print("=" * 60)
    
    if model is None:
        print("âœ— è·³è¿‡å‰å‘ä¼ æ’­æµ‹è¯•ï¼ˆæ¨¡å‹åˆ›å»ºå¤±è´¥ï¼‰")
        return None
    
    try:
        # åˆ›å»ºæµ‹è¯•è¾“å…¥ï¼Œç¡®ä¿åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
        batch_size = 2
        input_tensor = torch.randn(batch_size, 3, 256, 256).to(device)
        
        print(f"è¾“å…¥å¼ é‡å½¢çŠ¶: {input_tensor.shape}")
        print(f"è¾“å…¥è®¾å¤‡: {input_tensor.device}")
        print(f"æ¨¡å‹è®¾å¤‡: {next(model.parameters()).device}")
        
        # å‰å‘ä¼ æ’­
        model.eval()
        with torch.no_grad():
            output = model(input_tensor)
        
        print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"  - è¾“å‡ºå¼ é‡å½¢çŠ¶: {output.shape}")
        print(f"  - è¾“å‡ºæ•°å€¼èŒƒå›´: [{output.min().item():.6f}, {output.max().item():.6f}]")
        print(f"  - è¾“å‡ºå‡å€¼: {output.mean().item():.6f}")
        print(f"  - è¾“å‡ºæ ‡å‡†å·®: {output.std().item():.6f}")
        
        return output
        
    except Exception as e:
        print(f"âœ— å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        print(f"é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
        return None


def test_gradient_computation(model, device):
    """æµ‹è¯•æ¢¯åº¦è®¡ç®—"""
    print("\n" + "=" * 60)
    print("3. æµ‹è¯•æ¢¯åº¦è®¡ç®—")
    print("=" * 60)
    
    if model is None:
        print("âœ— è·³è¿‡æ¢¯åº¦è®¡ç®—æµ‹è¯•ï¼ˆæ¨¡å‹åˆ›å»ºå¤±è´¥ï¼‰")
        return False
    
    try:
        # åˆ›å»ºæµ‹è¯•è¾“å…¥å’Œç›®æ ‡ï¼Œç¡®ä¿åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
        input_tensor = torch.randn(1, 3, 256, 256, requires_grad=True).to(device)
        target = torch.randn(1, 3, 256, 256).to(device)
        
        # å‰å‘ä¼ æ’­
        model.train()
        output = model(input_tensor)
        
        # è®¡ç®—æŸå¤±
        loss = nn.MSELoss()(output, target)
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        # æ£€æŸ¥æ¢¯åº¦
        grad_norms = []
        for name, param in model.named_parameters():
            if param.grad is not None:
                grad_norm = param.grad.norm().item()
                grad_norms.append(grad_norm)
        
        print(f"âœ“ æ¢¯åº¦è®¡ç®—æˆåŠŸ")
        print(f"  - æŸå¤±å€¼: {loss.item():.6f}")
        print(f"  - æœ‰æ¢¯åº¦çš„å‚æ•°æ•°é‡: {len(grad_norms)}")
        print(f"  - æ¢¯åº¦èŒƒæ•°ç»Ÿè®¡: æœ€å°={min(grad_norms):.6f}, æœ€å¤§={max(grad_norms):.6f}, å¹³å‡={np.mean(grad_norms):.6f}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸æ¢¯åº¦
        if any(np.isnan(g) or np.isinf(g) for g in grad_norms):
            print("âš  è­¦å‘Š: å‘ç°NaNæˆ–Infæ¢¯åº¦")
            return False
        
        if max(grad_norms) > 100:
            print("âš  è­¦å‘Š: å‘ç°è¿‡å¤§çš„æ¢¯åº¦ï¼ˆå¯èƒ½å­˜åœ¨æ¢¯åº¦çˆ†ç‚¸ï¼‰")
        
        return True
        
    except Exception as e:
        print(f"âœ— æ¢¯åº¦è®¡ç®—å¤±è´¥: {e}")
        print(f"é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
        return False


def test_loss_computation(model, device):
    """æµ‹è¯•æŸå¤±å‡½æ•°è®¡ç®—"""
    print("\n" + "=" * 60)
    print("4. æµ‹è¯•æŸå¤±å‡½æ•°è®¡ç®—")
    print("=" * 60)
    
    if model is None:
        print("âœ— è·³è¿‡æŸå¤±å‡½æ•°æµ‹è¯•ï¼ˆæ¨¡å‹åˆ›å»ºå¤±è´¥ï¼‰")
        return False
    
    try:
        # åˆ›å»ºæµ‹è¯•æ•°æ®ï¼Œç¡®ä¿åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
        batch_size = 2
        input_tensor = torch.randn(batch_size, 3, 256, 256).to(device)
        target = torch.randn(batch_size, 3, 256, 256).to(device)
        
        # å‰å‘ä¼ æ’­
        model.eval()
        with torch.no_grad():
            output = model(input_tensor)
        
        # æµ‹è¯•ä¸åŒæŸå¤±å‡½æ•°
        losses = {}
        
        # L2æŸå¤±
        losses['L2'] = nn.MSELoss()(output, target).item()
        
        # L1æŸå¤±
        losses['L1'] = nn.L1Loss()(output, target).item()
        
        # ç›¸å¯¹L2æŸå¤±
        diff = output - target
        rel_l2 = torch.sqrt(torch.sum(diff ** 2, dim=(1,2,3))) / torch.sqrt(torch.sum(target ** 2, dim=(1,2,3)))
        losses['Rel_L2'] = rel_l2.mean().item()
        
        print("âœ“ æŸå¤±å‡½æ•°è®¡ç®—æˆåŠŸ")
        for loss_name, loss_value in losses.items():
            print(f"  - {loss_name}: {loss_value:.6f}")
        
        # æ£€æŸ¥æŸå¤±å€¼æ˜¯å¦åˆç†
        if any(np.isnan(v) or np.isinf(v) for v in losses.values()):
            print("âš  è­¦å‘Š: å‘ç°NaNæˆ–InfæŸå¤±å€¼")
            return False
        
        return True
        
    except Exception as e:
        print(f"âœ— æŸå¤±å‡½æ•°è®¡ç®—å¤±è´¥: {e}")
        print(f"é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
        return False


def test_parameter_analysis(model):
    """æµ‹è¯•å‚æ•°åˆ†æ"""
    print("\n" + "=" * 60)
    print("5. å‚æ•°åˆ†æ")
    print("=" * 60)
    
    if model is None:
        print("âœ— è·³è¿‡å‚æ•°åˆ†æï¼ˆæ¨¡å‹åˆ›å»ºå¤±è´¥ï¼‰")
        return
    
    try:
        # ç»Ÿè®¡å‚æ•°
        total_params = 0
        trainable_params = 0
        param_stats = {}
        
        for name, param in model.named_parameters():
            param_count = param.numel()
            total_params += param_count
            
            if param.requires_grad:
                trainable_params += param_count
            
            # æŒ‰æ¨¡å—åˆ†ç±»ç»Ÿè®¡
            module_name = name.split('.')[0]
            if module_name not in param_stats:
                param_stats[module_name] = 0
            param_stats[module_name] += param_count
        
        print(f"âœ“ å‚æ•°åˆ†æå®Œæˆ")
        print(f"  - æ€»å‚æ•°é‡: {total_params:,}")
        print(f"  - å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        print(f"  - å†»ç»“å‚æ•°: {total_params - trainable_params:,}")
        
        print("\nå„æ¨¡å—å‚æ•°åˆ†å¸ƒ:")
        for module_name, param_count in sorted(param_stats.items(), key=lambda x: x[1], reverse=True):
            percentage = param_count / total_params * 100
            print(f"  - {module_name}: {param_count:,} ({percentage:.1f}%)")
        
        # æ£€æŸ¥å‚æ•°åˆå§‹åŒ–
        param_norms = []
        for name, param in model.named_parameters():
            if param.requires_grad:
                param_norm = param.norm().item()
                param_norms.append(param_norm)
        
        print(f"\nå‚æ•°èŒƒæ•°ç»Ÿè®¡:")
        print(f"  - æœ€å°: {min(param_norms):.6f}")
        print(f"  - æœ€å¤§: {max(param_norms):.6f}")
        print(f"  - å¹³å‡: {np.mean(param_norms):.6f}")
        print(f"  - æ ‡å‡†å·®: {np.std(param_norms):.6f}")
        
    except Exception as e:
        print(f"âœ— å‚æ•°åˆ†æå¤±è´¥: {e}")
        print(f"é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")


def test_config_compatibility(device):
    """æµ‹è¯•é…ç½®å…¼å®¹æ€§"""
    print("\n" + "=" * 60)
    print("6. æµ‹è¯•é…ç½®å…¼å®¹æ€§")
    print("=" * 60)
    
    try:
        # æµ‹è¯•é€šè¿‡create_modelå‡½æ•°åˆ›å»º - ä¿®æ­£å‚æ•°æ ¼å¼
        model = create_model(
            'SwinUNet',  # ç›´æ¥ä¼ å…¥å­—ç¬¦ä¸²
            in_channels=3,
            out_channels=3,
            img_size=256,
            patch_size=4,
            window_size=8,
            depths=[2, 2, 6, 2],
            num_heads=[3, 6, 12, 24],
            embed_dim=96,
            mlp_ratio=4.0,
            drop_rate=0.0,
            attn_drop_rate=0.0,
            drop_path_rate=0.1,
            norm_layer=nn.LayerNorm
        )
        
        model = model.to(device)
        print("âœ“ é€šè¿‡create_modelå‡½æ•°åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        input_tensor = torch.randn(1, 3, 256, 256).to(device)
        with torch.no_grad():
            output = model(input_tensor)
        
        print(f"âœ“ é…ç½®å…¼å®¹æ€§æµ‹è¯•é€šè¿‡")
        print(f"  - è¾“å‡ºå½¢çŠ¶: {output.shape}")
        
        return True
        
    except Exception as e:
        print(f"âœ— é…ç½®å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        print(f"é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("SwinUNetæ¨¡å‹è¯Šæ–­æµ‹è¯•")
    print("=" * 60)
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(2025)
    np.random.seed(2025)
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # è¿è¡Œæµ‹è¯•
    model = test_model_creation()
    
    if model is not None:
        model = model.to(device)
    
    output = test_forward_pass(model, device)
    gradient_ok = test_gradient_computation(model, device)
    loss_ok = test_loss_computation(model, device)
    test_parameter_analysis(model)
    config_ok = test_config_compatibility(device)
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("è¯Šæ–­ç»“æœæ€»ç»“")
    print("=" * 60)
    
    tests = [
        ("æ¨¡å‹åˆ›å»º", model is not None),
        ("å‰å‘ä¼ æ’­", output is not None),
        ("æ¢¯åº¦è®¡ç®—", gradient_ok),
        ("æŸå¤±å‡½æ•°", loss_ok),
        ("é…ç½®å…¼å®¹æ€§", config_ok)
    ]
    
    passed = sum(1 for _, result in tests if result)
    total = len(tests)
    
    for test_name, result in tests:
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        print(f"{test_name}: {status}")
    
    print(f"\næ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼SwinUNetæ¨¡å‹çŠ¶æ€æ­£å¸¸ã€‚")
    else:
        print("âš ï¸  å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•ã€‚")
    
    return passed == total


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)