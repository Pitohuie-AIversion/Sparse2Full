#!/usr/bin/env python3
"""
æ‰¹é‡è®­ç»ƒæ‰€æœ‰æ¨¡å‹è„šæœ¬
åŸºäº train.yaml é…ç½®æ–‡ä»¶è¿è¡Œæ‰€æœ‰12ä¸ªå¯ç”¨æ¨¡å‹çš„å®Œæ•´è®­ç»ƒå’Œè¯„ä¼°

ä½œè€…: PDEBenchç¨€ç–è§‚æµ‹é‡å»ºç³»ç»Ÿ
æ—¥æœŸ: 2025-01-13
"""

import os
import sys
import yaml
import json
import time
import logging
import argparse
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
import pandas as pd
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('batch_training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class BatchModelTrainer:
    """æ‰¹é‡æ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self, base_config_path: str = "configs/train.yaml"):
        """åˆå§‹åŒ–æ‰¹é‡è®­ç»ƒå™¨
        
        Args:
            base_config_path: åŸºç¡€é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.base_config_path = Path(base_config_path)
        self.project_root = Path(__file__).parent
        self.model_configs_dir = self.project_root / "configs" / "model"
        self.results_dir = self.project_root / "runs" / "batch_training_results"
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½åŸºç¡€é…ç½®
        self.base_config = self.load_base_config()
        
        # å®šä¹‰æ‰€æœ‰å¯ç”¨æ¨¡å‹
        self.available_models = [
            "unet",
            "unet_plus_plus", 
            "fno2d",
            "ufno_unet",
            "segformer",
            "unetformer",
            "segformer_unetformer",
            "mlp",
            "mlp_mixer",
            "liif",
            "swin_unet",
            "hybrid",
            "transformer"  # æ–°å¢ç»å…¸Transformeræ¨¡å‹
        ]
        
        # è®­ç»ƒç»“æœå­˜å‚¨
        self.training_results = {}
        self.resource_stats = {}
        
        # è®¾ç½®logger
        self.logger = logger
        
    def load_base_config(self) -> Dict[str, Any]:
        """åŠ è½½åŸºç¡€é…ç½®æ–‡ä»¶"""
        try:
            with open(self.base_config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            logger.info(f"æˆåŠŸåŠ è½½åŸºç¡€é…ç½®: {self.base_config_path}")
            return config
        except Exception as e:
            logger.error(f"åŠ è½½åŸºç¡€é…ç½®å¤±è´¥: {e}")
            raise
    
    def load_model_config(self, model_name: str) -> Dict[str, Any]:
        """åŠ è½½æ¨¡å‹ç‰¹å®šé…ç½®"""
        model_config_path = self.model_configs_dir / f"{model_name}.yaml"
        
        if not model_config_path.exists():
            logger.warning(f"æ¨¡å‹é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {model_config_path}")
            return {}
            
        try:
            with open(model_config_path, 'r', encoding='utf-8') as f:
                model_config = yaml.safe_load(f)
            return model_config
        except Exception as e:
            logger.error(f"åŠ è½½æ¨¡å‹é…ç½®å¤±è´¥ {model_name}: {e}")
            return {}
    
    def create_training_config(self, model_name: str) -> Dict[str, Any]:
        """ä¸ºç‰¹å®šæ¨¡å‹åˆ›å»ºè®­ç»ƒé…ç½®"""
        # å¤åˆ¶åŸºç¡€é…ç½®
        config = self.base_config.copy()
        
        # åŠ è½½æ¨¡å‹ç‰¹å®šé…ç½®
        model_config = self.load_model_config(model_name)
        
        # æ›´æ–°æ¨¡å‹é…ç½®
        if model_config:
            config['model'] = model_config
        else:
            # ä½¿ç”¨é»˜è®¤æ¨¡å‹é…ç½®
            config['model'] = {
                'name': model_name,
                'params': {
                    'in_channels': 1,
                    'out_channels': 1,
                    'img_size': 128
                }
            }
        
        # ç¡®ä¿ä½¿ç”¨æ ‡å‡†åŒ–è®­ç»ƒå‚æ•°ï¼ˆåŸºäºtrain.yamlï¼‰
        config['training']['epochs'] = 200
        config['training']['seed'] = 2025
        config['training']['optimizer']['params']['lr'] = 1.0e-3
        config['training']['optimizer']['params']['weight_decay'] = 1.0e-4
        config['training']['scheduler']['params']['warmup_steps'] = 1000
        
        # ç¡®ä¿æŸå¤±å‡½æ•°ä¸‰ä»¶å¥—æ ‡å‡†é…ç½®
        config['loss']['rec_weight'] = 1.0
        config['loss']['spec_weight'] = 0.5
        config['loss']['dc_weight'] = 1.0
        config['loss']['low_freq_modes'] = 16
        config['loss']['mirror_padding'] = True
        
        # ä¸ºFNOç›¸å…³æ¨¡å‹ç¦ç”¨AMP
        if model_name in ['fno2d', 'hybrid', 'ufno_unet']:
            config['training']['use_amp'] = False
            self.logger.info(f"Disabled AMP for {model_name} (complex operations compatibility)")
        
        # ä¿®å¤UNetFormerçš„num_headsé…ç½®é—®é¢˜
        if model_name == 'unetformer' and 'model' in config and 'params' in config['model']:
            if 'num_heads' in config['model']['params']:
                # ç¡®ä¿num_headsæ˜¯æ•´æ•°è€Œä¸æ˜¯ListConfig
                num_heads = config['model']['params']['num_heads']
                if isinstance(num_heads, (list, tuple)):
                    config['model']['params']['num_heads'] = num_heads[0] if num_heads else 8
                elif not isinstance(num_heads, int):
                    config['model']['params']['num_heads'] = 8
                self.logger.info(f"Fixed num_heads config for {model_name}: {config['model']['params']['num_heads']}")
        
        # æ›´æ–°å®éªŒåç§°
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        config['experiment']['name'] = f"batch_{model_name}_sr_x4_{timestamp}"
        
        return config
    
    def save_training_config(self, model_name: str, config: Dict[str, Any]) -> Path:
        """ä¿å­˜è®­ç»ƒé…ç½®åˆ°æ–‡ä»¶"""
        config_path = self.results_dir / f"config_{model_name}.yaml"
        
        try:
            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
            self.logger.info(f"ä¿å­˜è®­ç»ƒé…ç½®: {config_path}")
            return config_path
        except Exception as e:
            self.logger.error(f"ä¿å­˜é…ç½®å¤±è´¥ {model_name}: {e}")
            raise
    
    def run_single_model_training(self, model_name: str) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªæ¨¡å‹çš„è®­ç»ƒ"""
        self.logger.info(f"å¼€å§‹è®­ç»ƒæ¨¡å‹: {model_name}")
        start_time = time.time()
        
        try:
            # åˆ›å»ºæ¨¡å‹ç‰¹å®šçš„è¾“å‡ºç›®å½•
            model_output_dir = self.results_dir / model_name
            model_output_dir.mkdir(exist_ok=True)
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡
            if self.should_skip_model(model_name, model_output_dir):
                return {
                    'model_name': model_name,
                    'status': 'skipped',
                    'training_time': 0
                }
            
            # åˆ›å»ºè®­ç»ƒé…ç½®
            config = self.create_training_config(model_name)
            config_path = self.save_training_config(model_name, config)
            
            # æ„å»ºè®­ç»ƒå‘½ä»¤ - ä½¿ç”¨æ­£ç¡®çš„Hydraæ ¼å¼
            train_script = self.project_root / "train.py"
            cmd = [
                sys.executable, str(train_script),
                f"--config-path={config_path.parent}",
                f"--config-name={config_path.name}",
                f"hydra.run.dir={model_output_dir}",
                f"experiment.output_dir={model_output_dir}"
            ]
            
            # æ‰§è¡Œè®­ç»ƒ
            self.logger.info(f"æ‰§è¡Œè®­ç»ƒå‘½ä»¤: {' '.join(cmd)}")
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                cwd=str(self.project_root)
            )
            
            training_time = time.time() - start_time
            
            # æ£€æŸ¥è®­ç»ƒç»“æœ
            if result.returncode == 0:
                logger.info(f"æ¨¡å‹ {model_name} è®­ç»ƒæˆåŠŸï¼Œè€—æ—¶: {training_time:.2f}ç§’")
                
                # åˆ›å»ºæˆåŠŸæ ‡å¿—æ–‡ä»¶
                success_file = model_output_dir / "training_completed.txt"
                with open(success_file, 'w') as f:
                    f.write(f"Training completed at {datetime.now()}\n")
                    f.write(f"Training time: {training_time:.2f} seconds\n")
                
                # è§£æè®­ç»ƒç»“æœ
                training_result = self.parse_training_result(model_name, model_output_dir)
                training_result['training_time'] = training_time
                training_result['status'] = 'success'
                
                return training_result
            else:
                logger.error(f"æ¨¡å‹ {model_name} è®­ç»ƒå¤±è´¥:")
                logger.error(f"stdout: {result.stdout}")
                logger.error(f"stderr: {result.stderr}")
                
                # ä¿å­˜é”™è¯¯ä¿¡æ¯åˆ°æ–‡ä»¶
                error_file = model_output_dir / "training_error.txt"
                with open(error_file, 'w', encoding='utf-8') as f:
                    f.write(f"Training failed at {datetime.now()}\n")
                    f.write(f"Return code: {result.returncode}\n")
                    f.write(f"STDOUT:\n{result.stdout}\n")
                    f.write(f"STDERR:\n{result.stderr}\n")
                
                return {
                    'model_name': model_name,
                    'status': 'failed',
                    'error': result.stderr,
                    'training_time': training_time
                }
                
        except Exception as e:
            training_time = time.time() - start_time
            logger.error(f"æ¨¡å‹ {model_name} è®­ç»ƒå¼‚å¸¸: {e}")
            return {
                'model_name': model_name,
                'status': 'error',
                'error': str(e),
                'training_time': training_time
            }
    
    def should_skip_model(self, model_name: str, output_dir: Path) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡å·²å®Œæˆçš„æ¨¡å‹è®­ç»ƒ"""
        if not output_dir.exists():
            return False
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æˆåŠŸå®Œæˆçš„æ ‡å¿—
        success_file = output_dir / "training_completed.txt"
        if success_file.exists():
            logger.info(f"æ¨¡å‹ {model_name} å·²å®Œæˆè®­ç»ƒï¼Œè·³è¿‡")
            return True
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æœ€ä½³æ£€æŸ¥ç‚¹
        best_checkpoint = output_dir / "best.pth"
        if best_checkpoint.exists():
            logger.info(f"æ¨¡å‹ {model_name} å­˜åœ¨æœ€ä½³æ£€æŸ¥ç‚¹ï¼Œè·³è¿‡")
            return True
        
        return False
    
    def parse_training_result(self, model_name: str, output_dir: Path) -> Dict[str, Any]:
        """è§£æè®­ç»ƒç»“æœ"""
        result = {'model_name': model_name}
        
        try:
            # æŸ¥æ‰¾è®­ç»ƒæ—¥å¿—æ–‡ä»¶
            log_files = list(output_dir.glob("*.log"))
            if log_files:
                log_file = log_files[0]
                result['log_file'] = str(log_file)
                
                # è§£ææ—¥å¿—ä¸­çš„æŒ‡æ ‡
                metrics = self.parse_metrics_from_log(log_file)
                result.update(metrics)
            
            # æŸ¥æ‰¾æ£€æŸ¥ç‚¹æ–‡ä»¶
            checkpoint_files = list(output_dir.glob("*.pth"))
            if checkpoint_files:
                result['checkpoint'] = str(checkpoint_files[0])
            
            # æŸ¥æ‰¾é…ç½®æ–‡ä»¶
            config_files = list(output_dir.glob("config_*.yaml"))
            if config_files:
                result['config_file'] = str(config_files[0])
                
        except Exception as e:
            logger.warning(f"è§£æè®­ç»ƒç»“æœå¤±è´¥ {model_name}: {e}")
            
        return result
    
    def parse_metrics_from_log(self, log_file: Path) -> Dict[str, float]:
        """ä»æ—¥å¿—æ–‡ä»¶è§£ææŒ‡æ ‡"""
        metrics = {}
        
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # æŸ¥æ‰¾æœ€ç»ˆéªŒè¯æŒ‡æ ‡
            for line in reversed(lines):
                if 'Final validation metrics' in line or 'Best validation' in line:
                    # è§£ææŒ‡æ ‡è¡Œ
                    if 'rel_l2' in line:
                        parts = line.split()
                        for i, part in enumerate(parts):
                            if part == 'rel_l2:' and i + 1 < len(parts):
                                metrics['rel_l2'] = float(parts[i + 1].rstrip(','))
                            elif part == 'mae:' and i + 1 < len(parts):
                                metrics['mae'] = float(parts[i + 1].rstrip(','))
                            elif part == 'psnr:' and i + 1 < len(parts):
                                metrics['psnr'] = float(parts[i + 1].rstrip(','))
                            elif part == 'ssim:' and i + 1 < len(parts):
                                metrics['ssim'] = float(parts[i + 1].rstrip(','))
                    break
                    
        except Exception as e:
            logger.warning(f"è§£ææŒ‡æ ‡å¤±è´¥: {e}")
            
        return metrics
    
    def run_batch_training(self, models: Optional[List[str]] = None) -> Dict[str, Any]:
        """è¿è¡Œæ‰¹é‡è®­ç»ƒ"""
        if models is None:
            models = self.available_models
        
        logger.info(f"å¼€å§‹æ‰¹é‡è®­ç»ƒ {len(models)} ä¸ªæ¨¡å‹: {models}")
        batch_start_time = time.time()
        
        results = {}
        
        for i, model_name in enumerate(models, 1):
            logger.info(f"è¿›åº¦: {i}/{len(models)} - è®­ç»ƒæ¨¡å‹: {model_name}")
            
            try:
                result = self.run_single_model_training(model_name)
                results[model_name] = result
                
                # ä¿å­˜ä¸­é—´ç»“æœ
                self.save_intermediate_results(results)
                
            except Exception as e:
                logger.error(f"æ¨¡å‹ {model_name} è®­ç»ƒå¤±è´¥: {e}")
                results[model_name] = {
                    'model_name': model_name,
                    'status': 'error',
                    'error': str(e)
                }
        
        batch_time = time.time() - batch_start_time
        logger.info(f"æ‰¹é‡è®­ç»ƒå®Œæˆï¼Œæ€»è€—æ—¶: {batch_time:.2f}ç§’")
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        self.training_results = results
        self.save_final_results(results, batch_time)
        
        return results
    
    def save_intermediate_results(self, results: Dict[str, Any]):
        """ä¿å­˜ä¸­é—´ç»“æœ"""
        results_file = self.results_dir / "intermediate_results.json"
        
        try:
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        except Exception as e:
            logger.warning(f"ä¿å­˜ä¸­é—´ç»“æœå¤±è´¥: {e}")
    
    def save_final_results(self, results: Dict[str, Any], batch_time: float):
        """ä¿å­˜æœ€ç»ˆç»“æœ"""
        # ä¿å­˜JSONæ ¼å¼ç»“æœ
        results_file = self.results_dir / "final_results.json"
        final_results = {
            'batch_training_time': batch_time,
            'timestamp': datetime.now().isoformat(),
            'total_models': len(results),
            'successful_models': len([r for r in results.values() if r.get('status') == 'success']),
            'failed_models': len([r for r in results.values() if r.get('status') != 'success']),
            'results': results
        }
        
        try:
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(final_results, f, indent=2, ensure_ascii=False, default=str)
            logger.info(f"ä¿å­˜æœ€ç»ˆç»“æœ: {results_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜æœ€ç»ˆç»“æœå¤±è´¥: {e}")
        
        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        self.generate_summary_report(results, batch_time)
    
    def generate_summary_report(self, results: Dict[str, Any], batch_time: float):
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        report_file = self.results_dir / "batch_training_summary.md"
        
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("# æ‰¹é‡æ¨¡å‹è®­ç»ƒæ±‡æ€»æŠ¥å‘Š\n\n")
                f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"**æ€»è®­ç»ƒæ—¶é—´**: {batch_time:.2f}ç§’ ({batch_time/60:.1f}åˆ†é’Ÿ)\n")
                f.write(f"**è®­ç»ƒæ¨¡å‹æ•°é‡**: {len(results)}\n\n")
                
                # æˆåŠŸ/å¤±è´¥ç»Ÿè®¡
                successful = [r for r in results.values() if r.get('status') == 'success']
                failed = [r for r in results.values() if r.get('status') != 'success']
                
                f.write("## è®­ç»ƒçŠ¶æ€ç»Ÿè®¡\n\n")
                f.write(f"- âœ… **æˆåŠŸ**: {len(successful)} ä¸ªæ¨¡å‹\n")
                f.write(f"- âŒ **å¤±è´¥**: {len(failed)} ä¸ªæ¨¡å‹\n")
                f.write(f"- ğŸ“Š **æˆåŠŸç‡**: {len(successful)/len(results)*100:.1f}%\n\n")
                
                # æˆåŠŸæ¨¡å‹è¯¦æƒ…
                if successful:
                    f.write("## æˆåŠŸè®­ç»ƒçš„æ¨¡å‹\n\n")
                    f.write("| æ¨¡å‹åç§° | è®­ç»ƒæ—¶é—´(s) | Rel-L2 | MAE | PSNR | SSIM |\n")
                    f.write("|---------|------------|--------|-----|------|------|\n")
                    
                    for result in successful:
                        model_name = result['model_name']
                        training_time = result.get('training_time', 0)
                        rel_l2 = result.get('rel_l2', 'N/A')
                        mae = result.get('mae', 'N/A')
                        psnr = result.get('psnr', 'N/A')
                        ssim = result.get('ssim', 'N/A')
                        
                        f.write(f"| {model_name} | {training_time:.1f} | {rel_l2} | {mae} | {psnr} | {ssim} |\n")
                    f.write("\n")
                
                # å¤±è´¥æ¨¡å‹è¯¦æƒ…
                if failed:
                    f.write("## å¤±è´¥çš„æ¨¡å‹\n\n")
                    for result in failed:
                        model_name = result['model_name']
                        error = result.get('error', 'Unknown error')
                        f.write(f"### {model_name}\n")
                        f.write(f"**é”™è¯¯ä¿¡æ¯**: {error}\n\n")
                
                # é…ç½®ä¿¡æ¯
                f.write("## è®­ç»ƒé…ç½®\n\n")
                f.write("åŸºäº `configs/train.yaml` çš„æ ‡å‡†åŒ–é…ç½®:\n\n")
                f.write("- **Epochs**: 200\n")
                f.write("- **ä¼˜åŒ–å™¨**: AdamW (lr=1e-3, wd=1e-4)\n")
                f.write("- **è°ƒåº¦å™¨**: Cosine + 1k warmup\n")
                f.write("- **æŸå¤±å‡½æ•°**: ä¸‰ä»¶å¥— (rec=1.0, spec=0.5, dc=1.0)\n")
                f.write("- **æ‰¹å¤§å°**: 4\n")
                f.write("- **éšæœºç§å­**: 2025\n")
                f.write("- **æ··åˆç²¾åº¦**: å¯ç”¨\n\n")
                
            logger.info(f"ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š: {report_file}")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ‰¹é‡è®­ç»ƒæ‰€æœ‰æ¨¡å‹")
    parser.add_argument(
        "--config", 
        default="configs/train.yaml",
        help="åŸºç¡€é…ç½®æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--models",
        nargs="+",
        help="æŒ‡å®šè¦è®­ç»ƒçš„æ¨¡å‹åˆ—è¡¨"
    )
    parser.add_argument(
        "--output_dir",
        default="runs/batch_training_results",
        help="è¾“å‡ºç›®å½•"
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ‰¹é‡è®­ç»ƒå™¨
    trainer = BatchModelTrainer(args.config)
    
    # å¦‚æœæŒ‡å®šäº†è¾“å‡ºç›®å½•ï¼Œæ›´æ–°ç»“æœç›®å½•
    if args.output_dir:
        trainer.results_dir = Path(args.output_dir)
        trainer.results_dir.mkdir(parents=True, exist_ok=True)
    
    try:
        # è¿è¡Œæ‰¹é‡è®­ç»ƒ
        results = trainer.run_batch_training(args.models)
        
        # è¾“å‡ºç»“æœæ‘˜è¦
        successful = len([r for r in results.values() if r.get('status') == 'success'])
        total = len(results)
        
        print(f"\nğŸ‰ æ‰¹é‡è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“Š æˆåŠŸ: {successful}/{total} ä¸ªæ¨¡å‹")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {trainer.results_dir}")
        print(f"ğŸ“‹ æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š: {trainer.results_dir / 'batch_training_summary.md'}")
        
        if successful < total:
            print(f"âš ï¸  æœ‰ {total - successful} ä¸ªæ¨¡å‹è®­ç»ƒå¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—")
            sys.exit(1)
        else:
            print("âœ… æ‰€æœ‰æ¨¡å‹è®­ç»ƒæˆåŠŸ!")
            
    except Exception as e:
        logger.error(f"æ‰¹é‡è®­ç»ƒå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()